{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-17 14:47:51.031500: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-17 14:47:56.026073: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow import keras\n",
    "from utils import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYTHONHASHSEED\"] = \"0\"\n",
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = './dataset1_3objects'\n",
    "\n",
    "x, y = read_dataset1(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "draw_bar_chart(y)\n",
    "\n",
    "print(np.unique(y))\n",
    "\n",
    "n_classes = len(np.unique(y))\n",
    "\n",
    "print(n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle\n",
    "x, y = shuffle(x, y, random_state=0)\n",
    "\n",
    "# split\n",
    "x_temp, x_test, y_temp, y_test = train_test_split(x, y, test_size=1/5, random_state=0, stratify=y)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_temp, y_temp, test_size=1/4, random_state=0, stratify=y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_bar_chart(y_val)\n",
    "draw_bar_chart(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, dropout=0.2):\n",
    "   # Create a `Sequential` model and add a Dense layer as the first layer.\n",
    "   model = tf.keras.models.Sequential()\n",
    "   model.add(tf.keras.Input(shape=input_shape))\n",
    "   model.add(tf.keras.layers.Conv1D(32, 2, activation='relu'))\n",
    "   model.add(tf.keras.layers.MaxPooling1D(2,1))\n",
    "   model.add(tf.keras.layers.Flatten())\n",
    "   model.add(tf.keras.layers.Dropout(dropout))\n",
    "   model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "   model.add(tf.keras.layers.Dense(n_classes, activation=\"softmax\"))\n",
    "\n",
    "   model.compile(\n",
    "      loss=\"sparse_categorical_crossentropy\",\n",
    "      optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "      metrics=[\"sparse_categorical_accuracy\"]\n",
    "   )\n",
    "   \n",
    "   return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-17 14:48:09.942832: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-17 14:48:10.146956: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-17 14:48:10.147645: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-17 14:48:10.149226: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-17 14:48:10.149861: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-17 14:48:10.150138: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-17 14:48:16.667532: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-17 14:48:16.667843: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-17 14:48:16.668087: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-17 14:48:16.668258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2836 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 960M, pci bus id: 0000:01:00.0, compute capability: 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 20, 32)            224       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 19, 32)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 608)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 608)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                9744      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,019\n",
      "Trainable params: 10,019\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-17 14:48:20.903721: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n",
      "2023-07-17 14:48:23.248269: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fd29000db50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-07-17 14:48:23.248402: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce GTX 960M, Compute Capability 5.0\n",
      "2023-07-17 14:48:23.721833: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-07-17 14:48:25.387260: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - ETA: 0s - loss: 1.0880 - sparse_categorical_accuracy: 0.3858\n",
      "Epoch 1: val_loss improved from inf to 1.06357, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 10s 17ms/step - loss: 1.0880 - sparse_categorical_accuracy: 0.3858 - val_loss: 1.0636 - val_sparse_categorical_accuracy: 0.5000\n",
      "Epoch 2/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 1.0595 - sparse_categorical_accuracy: 0.4375\n",
      "Epoch 2: val_loss improved from 1.06357 to 1.03434, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0615 - sparse_categorical_accuracy: 0.4307 - val_loss: 1.0343 - val_sparse_categorical_accuracy: 0.5169\n",
      "Epoch 3/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 1.0367 - sparse_categorical_accuracy: 0.5000\n",
      "Epoch 3: val_loss improved from 1.03434 to 1.00859, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0343 - sparse_categorical_accuracy: 0.5000 - val_loss: 1.0086 - val_sparse_categorical_accuracy: 0.5225\n",
      "Epoch 4/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 1.0280 - sparse_categorical_accuracy: 0.4833\n",
      "Epoch 4: val_loss improved from 1.00859 to 0.97781, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 1.0248 - sparse_categorical_accuracy: 0.4813 - val_loss: 0.9778 - val_sparse_categorical_accuracy: 0.5225\n",
      "Epoch 5/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.9990 - sparse_categorical_accuracy: 0.5151\n",
      "Epoch 5: val_loss improved from 0.97781 to 0.94682, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.9957 - sparse_categorical_accuracy: 0.5187 - val_loss: 0.9468 - val_sparse_categorical_accuracy: 0.6461\n",
      "Epoch 6/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.9744 - sparse_categorical_accuracy: 0.5560\n",
      "Epoch 6: val_loss improved from 0.94682 to 0.91446, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.9669 - sparse_categorical_accuracy: 0.5581 - val_loss: 0.9145 - val_sparse_categorical_accuracy: 0.5674\n",
      "Epoch 7/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.9580 - sparse_categorical_accuracy: 0.5347\n",
      "Epoch 7: val_loss improved from 0.91446 to 0.88568, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.9495 - sparse_categorical_accuracy: 0.5506 - val_loss: 0.8857 - val_sparse_categorical_accuracy: 0.6629\n",
      "Epoch 8/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.9187 - sparse_categorical_accuracy: 0.5862\n",
      "Epoch 8: val_loss improved from 0.88568 to 0.85462, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.9121 - sparse_categorical_accuracy: 0.5861 - val_loss: 0.8546 - val_sparse_categorical_accuracy: 0.6798\n",
      "Epoch 9/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.8936 - sparse_categorical_accuracy: 0.6094\n",
      "Epoch 9: val_loss improved from 0.85462 to 0.82391, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.8941 - sparse_categorical_accuracy: 0.6124 - val_loss: 0.8239 - val_sparse_categorical_accuracy: 0.7191\n",
      "Epoch 10/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.8710 - sparse_categorical_accuracy: 0.6157\n",
      "Epoch 10: val_loss improved from 0.82391 to 0.79895, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.8582 - sparse_categorical_accuracy: 0.6199 - val_loss: 0.7990 - val_sparse_categorical_accuracy: 0.6910\n",
      "Epoch 11/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.8413 - sparse_categorical_accuracy: 0.6313\n",
      "Epoch 11: val_loss improved from 0.79895 to 0.77674, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.8379 - sparse_categorical_accuracy: 0.6292 - val_loss: 0.7767 - val_sparse_categorical_accuracy: 0.6854\n",
      "Epoch 12/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.8130 - sparse_categorical_accuracy: 0.6208\n",
      "Epoch 12: val_loss improved from 0.77674 to 0.75648, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.8154 - sparse_categorical_accuracy: 0.6217 - val_loss: 0.7565 - val_sparse_categorical_accuracy: 0.7022\n",
      "Epoch 13/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.7839 - sparse_categorical_accuracy: 0.6317\n",
      "Epoch 13: val_loss improved from 0.75648 to 0.73523, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.7951 - sparse_categorical_accuracy: 0.6255 - val_loss: 0.7352 - val_sparse_categorical_accuracy: 0.7079\n",
      "Epoch 14/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.7645 - sparse_categorical_accuracy: 0.6729\n",
      "Epoch 14: val_loss improved from 0.73523 to 0.71450, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.7745 - sparse_categorical_accuracy: 0.6629 - val_loss: 0.7145 - val_sparse_categorical_accuracy: 0.7416\n",
      "Epoch 15/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.7517 - sparse_categorical_accuracy: 0.6714\n",
      "Epoch 15: val_loss improved from 0.71450 to 0.69912, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.7593 - sparse_categorical_accuracy: 0.6685 - val_loss: 0.6991 - val_sparse_categorical_accuracy: 0.7472\n",
      "Epoch 16/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.7363 - sparse_categorical_accuracy: 0.6607\n",
      "Epoch 16: val_loss improved from 0.69912 to 0.68749, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.7362 - sparse_categorical_accuracy: 0.6573 - val_loss: 0.6875 - val_sparse_categorical_accuracy: 0.7360\n",
      "Epoch 17/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.7375 - sparse_categorical_accuracy: 0.6938\n",
      "Epoch 17: val_loss improved from 0.68749 to 0.67384, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.7416 - sparse_categorical_accuracy: 0.6835 - val_loss: 0.6738 - val_sparse_categorical_accuracy: 0.7360\n",
      "Epoch 18/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.7089 - sparse_categorical_accuracy: 0.6918\n",
      "Epoch 18: val_loss improved from 0.67384 to 0.65973, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.7129 - sparse_categorical_accuracy: 0.6873 - val_loss: 0.6597 - val_sparse_categorical_accuracy: 0.7472\n",
      "Epoch 19/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.7016 - sparse_categorical_accuracy: 0.6806\n",
      "Epoch 19: val_loss improved from 0.65973 to 0.65047, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.7056 - sparse_categorical_accuracy: 0.6742 - val_loss: 0.6505 - val_sparse_categorical_accuracy: 0.7303\n",
      "Epoch 20/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.6737 - sparse_categorical_accuracy: 0.7143\n",
      "Epoch 20: val_loss improved from 0.65047 to 0.63730, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6824 - sparse_categorical_accuracy: 0.6985 - val_loss: 0.6373 - val_sparse_categorical_accuracy: 0.7472\n",
      "Epoch 21/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.6685 - sparse_categorical_accuracy: 0.7125\n",
      "Epoch 21: val_loss improved from 0.63730 to 0.62926, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6714 - sparse_categorical_accuracy: 0.7135 - val_loss: 0.6293 - val_sparse_categorical_accuracy: 0.7697\n",
      "Epoch 22/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.6609 - sparse_categorical_accuracy: 0.7222\n",
      "Epoch 22: val_loss improved from 0.62926 to 0.61959, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6588 - sparse_categorical_accuracy: 0.7303 - val_loss: 0.6196 - val_sparse_categorical_accuracy: 0.7640\n",
      "Epoch 23/10000\n",
      "21/34 [=================>............] - ETA: 0s - loss: 0.6403 - sparse_categorical_accuracy: 0.7173\n",
      "Epoch 23: val_loss improved from 0.61959 to 0.61308, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.6560 - sparse_categorical_accuracy: 0.7022 - val_loss: 0.6131 - val_sparse_categorical_accuracy: 0.7753\n",
      "Epoch 24/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.6352 - sparse_categorical_accuracy: 0.7155\n",
      "Epoch 24: val_loss improved from 0.61308 to 0.60361, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.6425 - sparse_categorical_accuracy: 0.7116 - val_loss: 0.6036 - val_sparse_categorical_accuracy: 0.7640\n",
      "Epoch 25/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.6238 - sparse_categorical_accuracy: 0.7431\n",
      "Epoch 25: val_loss improved from 0.60361 to 0.59747, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6361 - sparse_categorical_accuracy: 0.7416 - val_loss: 0.5975 - val_sparse_categorical_accuracy: 0.7865\n",
      "Epoch 26/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.6308 - sparse_categorical_accuracy: 0.7229\n",
      "Epoch 26: val_loss improved from 0.59747 to 0.59007, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 1s 18ms/step - loss: 0.6296 - sparse_categorical_accuracy: 0.7210 - val_loss: 0.5901 - val_sparse_categorical_accuracy: 0.7809\n",
      "Epoch 27/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.6165 - sparse_categorical_accuracy: 0.7319\n",
      "Epoch 27: val_loss improved from 0.59007 to 0.58291, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6232 - sparse_categorical_accuracy: 0.7247 - val_loss: 0.5829 - val_sparse_categorical_accuracy: 0.7640\n",
      "Epoch 28/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.6333 - sparse_categorical_accuracy: 0.7298\n",
      "Epoch 28: val_loss improved from 0.58291 to 0.57701, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6261 - sparse_categorical_accuracy: 0.7303 - val_loss: 0.5770 - val_sparse_categorical_accuracy: 0.7978\n",
      "Epoch 29/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.6256 - sparse_categorical_accuracy: 0.6979\n",
      "Epoch 29: val_loss improved from 0.57701 to 0.57052, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6191 - sparse_categorical_accuracy: 0.7097 - val_loss: 0.5705 - val_sparse_categorical_accuracy: 0.7921\n",
      "Epoch 30/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.6098 - sparse_categorical_accuracy: 0.7299\n",
      "Epoch 30: val_loss improved from 0.57052 to 0.56455, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6142 - sparse_categorical_accuracy: 0.7172 - val_loss: 0.5645 - val_sparse_categorical_accuracy: 0.8034\n",
      "Epoch 31/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.6042 - sparse_categorical_accuracy: 0.7245\n",
      "Epoch 31: val_loss improved from 0.56455 to 0.55785, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6012 - sparse_categorical_accuracy: 0.7228 - val_loss: 0.5578 - val_sparse_categorical_accuracy: 0.7978\n",
      "Epoch 32/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.5938 - sparse_categorical_accuracy: 0.7104\n",
      "Epoch 32: val_loss improved from 0.55785 to 0.55213, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.6012 - sparse_categorical_accuracy: 0.7191 - val_loss: 0.5521 - val_sparse_categorical_accuracy: 0.7978\n",
      "Epoch 33/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.5930 - sparse_categorical_accuracy: 0.7269\n",
      "Epoch 33: val_loss improved from 0.55213 to 0.54658, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5881 - sparse_categorical_accuracy: 0.7322 - val_loss: 0.5466 - val_sparse_categorical_accuracy: 0.7865\n",
      "Epoch 34/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.5917 - sparse_categorical_accuracy: 0.7321\n",
      "Epoch 34: val_loss improved from 0.54658 to 0.54183, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5876 - sparse_categorical_accuracy: 0.7341 - val_loss: 0.5418 - val_sparse_categorical_accuracy: 0.7978\n",
      "Epoch 35/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.5755 - sparse_categorical_accuracy: 0.7271\n",
      "Epoch 35: val_loss improved from 0.54183 to 0.53656, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5732 - sparse_categorical_accuracy: 0.7303 - val_loss: 0.5366 - val_sparse_categorical_accuracy: 0.7865\n",
      "Epoch 36/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.5699 - sparse_categorical_accuracy: 0.7593\n",
      "Epoch 36: val_loss improved from 0.53656 to 0.53199, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5824 - sparse_categorical_accuracy: 0.7528 - val_loss: 0.5320 - val_sparse_categorical_accuracy: 0.7978\n",
      "Epoch 37/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.5625 - sparse_categorical_accuracy: 0.7708\n",
      "Epoch 37: val_loss improved from 0.53199 to 0.52776, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5586 - sparse_categorical_accuracy: 0.7678 - val_loss: 0.5278 - val_sparse_categorical_accuracy: 0.8034\n",
      "Epoch 38/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.5650 - sparse_categorical_accuracy: 0.7457\n",
      "Epoch 38: val_loss improved from 0.52776 to 0.52206, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5776 - sparse_categorical_accuracy: 0.7378 - val_loss: 0.5221 - val_sparse_categorical_accuracy: 0.7978\n",
      "Epoch 39/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.5709 - sparse_categorical_accuracy: 0.7292\n",
      "Epoch 39: val_loss improved from 0.52206 to 0.51928, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5636 - sparse_categorical_accuracy: 0.7416 - val_loss: 0.5193 - val_sparse_categorical_accuracy: 0.7978\n",
      "Epoch 40/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.5469 - sparse_categorical_accuracy: 0.7557\n",
      "Epoch 40: val_loss improved from 0.51928 to 0.51418, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.5459 - sparse_categorical_accuracy: 0.7566 - val_loss: 0.5142 - val_sparse_categorical_accuracy: 0.7921\n",
      "Epoch 41/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.5500 - sparse_categorical_accuracy: 0.7411\n",
      "Epoch 41: val_loss improved from 0.51418 to 0.50996, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5540 - sparse_categorical_accuracy: 0.7360 - val_loss: 0.5100 - val_sparse_categorical_accuracy: 0.7865\n",
      "Epoch 42/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.5502 - sparse_categorical_accuracy: 0.7755\n",
      "Epoch 42: val_loss improved from 0.50996 to 0.50594, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5436 - sparse_categorical_accuracy: 0.7865 - val_loss: 0.5059 - val_sparse_categorical_accuracy: 0.7978\n",
      "Epoch 43/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.5637 - sparse_categorical_accuracy: 0.7500\n",
      "Epoch 43: val_loss improved from 0.50594 to 0.50300, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5522 - sparse_categorical_accuracy: 0.7528 - val_loss: 0.5030 - val_sparse_categorical_accuracy: 0.8202\n",
      "Epoch 44/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.5193 - sparse_categorical_accuracy: 0.7847\n",
      "Epoch 44: val_loss improved from 0.50300 to 0.49936, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5314 - sparse_categorical_accuracy: 0.7640 - val_loss: 0.4994 - val_sparse_categorical_accuracy: 0.7978\n",
      "Epoch 45/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.5254 - sparse_categorical_accuracy: 0.7629\n",
      "Epoch 45: val_loss improved from 0.49936 to 0.49622, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5265 - sparse_categorical_accuracy: 0.7584 - val_loss: 0.4962 - val_sparse_categorical_accuracy: 0.8146\n",
      "Epoch 46/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.5379 - sparse_categorical_accuracy: 0.7608\n",
      "Epoch 46: val_loss improved from 0.49622 to 0.49131, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5310 - sparse_categorical_accuracy: 0.7659 - val_loss: 0.4913 - val_sparse_categorical_accuracy: 0.8034\n",
      "Epoch 47/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.5239 - sparse_categorical_accuracy: 0.7823\n",
      "Epoch 47: val_loss improved from 0.49131 to 0.48462, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5271 - sparse_categorical_accuracy: 0.7734 - val_loss: 0.4846 - val_sparse_categorical_accuracy: 0.8315\n",
      "Epoch 48/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.4998 - sparse_categorical_accuracy: 0.7837\n",
      "Epoch 48: val_loss improved from 0.48462 to 0.48255, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5102 - sparse_categorical_accuracy: 0.7846 - val_loss: 0.4826 - val_sparse_categorical_accuracy: 0.8146\n",
      "Epoch 49/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.5127 - sparse_categorical_accuracy: 0.7672\n",
      "Epoch 49: val_loss improved from 0.48255 to 0.47901, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5119 - sparse_categorical_accuracy: 0.7678 - val_loss: 0.4790 - val_sparse_categorical_accuracy: 0.8034\n",
      "Epoch 50/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.5215 - sparse_categorical_accuracy: 0.7833\n",
      "Epoch 50: val_loss improved from 0.47901 to 0.47694, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5205 - sparse_categorical_accuracy: 0.7790 - val_loss: 0.4769 - val_sparse_categorical_accuracy: 0.8371\n",
      "Epoch 51/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.5129 - sparse_categorical_accuracy: 0.7572\n",
      "Epoch 51: val_loss improved from 0.47694 to 0.47095, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5124 - sparse_categorical_accuracy: 0.7547 - val_loss: 0.4710 - val_sparse_categorical_accuracy: 0.8090\n",
      "Epoch 52/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.5001 - sparse_categorical_accuracy: 0.7731\n",
      "Epoch 52: val_loss improved from 0.47095 to 0.46836, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5145 - sparse_categorical_accuracy: 0.7566 - val_loss: 0.4684 - val_sparse_categorical_accuracy: 0.8202\n",
      "Epoch 53/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.5242 - sparse_categorical_accuracy: 0.7750\n",
      "Epoch 53: val_loss improved from 0.46836 to 0.46587, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5112 - sparse_categorical_accuracy: 0.7828 - val_loss: 0.4659 - val_sparse_categorical_accuracy: 0.8315\n",
      "Epoch 54/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.5009 - sparse_categorical_accuracy: 0.7708\n",
      "Epoch 54: val_loss improved from 0.46587 to 0.46076, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.5036 - sparse_categorical_accuracy: 0.7697 - val_loss: 0.4608 - val_sparse_categorical_accuracy: 0.8258\n",
      "Epoch 55/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.4948 - sparse_categorical_accuracy: 0.7974\n",
      "Epoch 55: val_loss improved from 0.46076 to 0.45699, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.4886 - sparse_categorical_accuracy: 0.8034 - val_loss: 0.4570 - val_sparse_categorical_accuracy: 0.8146\n",
      "Epoch 56/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.5097 - sparse_categorical_accuracy: 0.7917\n",
      "Epoch 56: val_loss improved from 0.45699 to 0.45451, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.5062 - sparse_categorical_accuracy: 0.7903 - val_loss: 0.4545 - val_sparse_categorical_accuracy: 0.8371\n",
      "Epoch 57/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.4819 - sparse_categorical_accuracy: 0.7891\n",
      "Epoch 57: val_loss improved from 0.45451 to 0.45203, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.4828 - sparse_categorical_accuracy: 0.7921 - val_loss: 0.4520 - val_sparse_categorical_accuracy: 0.8315\n",
      "Epoch 58/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.4682 - sparse_categorical_accuracy: 0.7879\n",
      "Epoch 58: val_loss improved from 0.45203 to 0.44781, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.4821 - sparse_categorical_accuracy: 0.7753 - val_loss: 0.4478 - val_sparse_categorical_accuracy: 0.8427\n",
      "Epoch 59/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.4944 - sparse_categorical_accuracy: 0.8013\n",
      "Epoch 59: val_loss improved from 0.44781 to 0.44566, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.4901 - sparse_categorical_accuracy: 0.7996 - val_loss: 0.4457 - val_sparse_categorical_accuracy: 0.8483\n",
      "Epoch 60/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.4857 - sparse_categorical_accuracy: 0.7875\n",
      "Epoch 60: val_loss improved from 0.44566 to 0.44303, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.4788 - sparse_categorical_accuracy: 0.7809 - val_loss: 0.4430 - val_sparse_categorical_accuracy: 0.8539\n",
      "Epoch 61/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.4840 - sparse_categorical_accuracy: 0.7986\n",
      "Epoch 61: val_loss improved from 0.44303 to 0.44190, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.4808 - sparse_categorical_accuracy: 0.7959 - val_loss: 0.4419 - val_sparse_categorical_accuracy: 0.8371\n",
      "Epoch 62/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.4769 - sparse_categorical_accuracy: 0.8009\n",
      "Epoch 62: val_loss improved from 0.44190 to 0.43735, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.4696 - sparse_categorical_accuracy: 0.8052 - val_loss: 0.4373 - val_sparse_categorical_accuracy: 0.8596\n",
      "Epoch 63/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.4565 - sparse_categorical_accuracy: 0.8125\n",
      "Epoch 63: val_loss improved from 0.43735 to 0.43471, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.4660 - sparse_categorical_accuracy: 0.8052 - val_loss: 0.4347 - val_sparse_categorical_accuracy: 0.8427\n",
      "Epoch 64/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.4703 - sparse_categorical_accuracy: 0.8049\n",
      "Epoch 64: val_loss did not improve from 0.43471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.4701 - sparse_categorical_accuracy: 0.8052 - val_loss: 0.4355 - val_sparse_categorical_accuracy: 0.8708\n",
      "Epoch 65/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.4567 - sparse_categorical_accuracy: 0.8024\n",
      "Epoch 65: val_loss improved from 0.43471 to 0.43251, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.4672 - sparse_categorical_accuracy: 0.7940 - val_loss: 0.4325 - val_sparse_categorical_accuracy: 0.8539\n",
      "Epoch 66/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.4613 - sparse_categorical_accuracy: 0.8163\n",
      "Epoch 66: val_loss improved from 0.43251 to 0.42857, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.4589 - sparse_categorical_accuracy: 0.8165 - val_loss: 0.4286 - val_sparse_categorical_accuracy: 0.8427\n",
      "Epoch 67/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.4621 - sparse_categorical_accuracy: 0.7940\n",
      "Epoch 67: val_loss improved from 0.42857 to 0.42626, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.4630 - sparse_categorical_accuracy: 0.7978 - val_loss: 0.4263 - val_sparse_categorical_accuracy: 0.8483\n",
      "Epoch 68/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.4563 - sparse_categorical_accuracy: 0.7902\n",
      "Epoch 68: val_loss improved from 0.42626 to 0.42440, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.4599 - sparse_categorical_accuracy: 0.7959 - val_loss: 0.4244 - val_sparse_categorical_accuracy: 0.8539\n",
      "Epoch 69/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.4592 - sparse_categorical_accuracy: 0.7969\n",
      "Epoch 69: val_loss improved from 0.42440 to 0.42200, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.4607 - sparse_categorical_accuracy: 0.7903 - val_loss: 0.4220 - val_sparse_categorical_accuracy: 0.8596\n",
      "Epoch 70/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.4679 - sparse_categorical_accuracy: 0.7974\n",
      "Epoch 70: val_loss improved from 0.42200 to 0.42142, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.4616 - sparse_categorical_accuracy: 0.7996 - val_loss: 0.4214 - val_sparse_categorical_accuracy: 0.8652\n",
      "Epoch 71/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.4658 - sparse_categorical_accuracy: 0.8029\n",
      "Epoch 71: val_loss improved from 0.42142 to 0.41730, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.4604 - sparse_categorical_accuracy: 0.8071 - val_loss: 0.4173 - val_sparse_categorical_accuracy: 0.8652\n",
      "Epoch 72/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.4604 - sparse_categorical_accuracy: 0.7824\n",
      "Epoch 72: val_loss improved from 0.41730 to 0.41695, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.4637 - sparse_categorical_accuracy: 0.7846 - val_loss: 0.4170 - val_sparse_categorical_accuracy: 0.8652\n",
      "Epoch 73/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.4494 - sparse_categorical_accuracy: 0.8147\n",
      "Epoch 73: val_loss improved from 0.41695 to 0.41179, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.4520 - sparse_categorical_accuracy: 0.8146 - val_loss: 0.4118 - val_sparse_categorical_accuracy: 0.8764\n",
      "Epoch 74/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.4491 - sparse_categorical_accuracy: 0.8125\n",
      "Epoch 74: val_loss improved from 0.41179 to 0.41035, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.4475 - sparse_categorical_accuracy: 0.8146 - val_loss: 0.4104 - val_sparse_categorical_accuracy: 0.8708\n",
      "Epoch 75/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.4428 - sparse_categorical_accuracy: 0.8194\n",
      "Epoch 75: val_loss improved from 0.41035 to 0.40864, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.4482 - sparse_categorical_accuracy: 0.8071 - val_loss: 0.4086 - val_sparse_categorical_accuracy: 0.8652\n",
      "Epoch 76/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.4394 - sparse_categorical_accuracy: 0.8233\n",
      "Epoch 76: val_loss improved from 0.40864 to 0.40696, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.4442 - sparse_categorical_accuracy: 0.8165 - val_loss: 0.4070 - val_sparse_categorical_accuracy: 0.8708\n",
      "Epoch 77/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.4430 - sparse_categorical_accuracy: 0.8036\n",
      "Epoch 77: val_loss improved from 0.40696 to 0.40432, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.4381 - sparse_categorical_accuracy: 0.8146 - val_loss: 0.4043 - val_sparse_categorical_accuracy: 0.8764\n",
      "Epoch 78/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.4286 - sparse_categorical_accuracy: 0.8229\n",
      "Epoch 78: val_loss improved from 0.40432 to 0.40336, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.4400 - sparse_categorical_accuracy: 0.8202 - val_loss: 0.4034 - val_sparse_categorical_accuracy: 0.8708\n",
      "Epoch 79/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.4198 - sparse_categorical_accuracy: 0.8297\n",
      "Epoch 79: val_loss improved from 0.40336 to 0.40105, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.4365 - sparse_categorical_accuracy: 0.8221 - val_loss: 0.4011 - val_sparse_categorical_accuracy: 0.8764\n",
      "Epoch 80/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.4236 - sparse_categorical_accuracy: 0.8354\n",
      "Epoch 80: val_loss improved from 0.40105 to 0.39951, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.4367 - sparse_categorical_accuracy: 0.8202 - val_loss: 0.3995 - val_sparse_categorical_accuracy: 0.8764\n",
      "Epoch 81/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.4222 - sparse_categorical_accuracy: 0.8103\n",
      "Epoch 81: val_loss improved from 0.39951 to 0.39669, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.4362 - sparse_categorical_accuracy: 0.7996 - val_loss: 0.3967 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 82/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.4210 - sparse_categorical_accuracy: 0.8168\n",
      "Epoch 82: val_loss improved from 0.39669 to 0.39615, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.4309 - sparse_categorical_accuracy: 0.8146 - val_loss: 0.3962 - val_sparse_categorical_accuracy: 0.8652\n",
      "Epoch 83/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.4281 - sparse_categorical_accuracy: 0.8264\n",
      "Epoch 83: val_loss improved from 0.39615 to 0.39477, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.4254 - sparse_categorical_accuracy: 0.8352 - val_loss: 0.3948 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 84/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.4378 - sparse_categorical_accuracy: 0.8148\n",
      "Epoch 84: val_loss improved from 0.39477 to 0.39265, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.4307 - sparse_categorical_accuracy: 0.8221 - val_loss: 0.3926 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 85/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.4216 - sparse_categorical_accuracy: 0.8482\n",
      "Epoch 85: val_loss improved from 0.39265 to 0.39171, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.4230 - sparse_categorical_accuracy: 0.8390 - val_loss: 0.3917 - val_sparse_categorical_accuracy: 0.8764\n",
      "Epoch 86/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.4206 - sparse_categorical_accuracy: 0.8415\n",
      "Epoch 86: val_loss improved from 0.39171 to 0.39086, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.4175 - sparse_categorical_accuracy: 0.8352 - val_loss: 0.3909 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 87/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.4365 - sparse_categorical_accuracy: 0.8017\n",
      "Epoch 87: val_loss improved from 0.39086 to 0.38960, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.4296 - sparse_categorical_accuracy: 0.8109 - val_loss: 0.3896 - val_sparse_categorical_accuracy: 0.8708\n",
      "Epoch 88/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.4275 - sparse_categorical_accuracy: 0.8125\n",
      "Epoch 88: val_loss improved from 0.38960 to 0.38723, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.4237 - sparse_categorical_accuracy: 0.8184 - val_loss: 0.3872 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 89/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.4137 - sparse_categorical_accuracy: 0.8233\n",
      "Epoch 89: val_loss improved from 0.38723 to 0.38719, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.4236 - sparse_categorical_accuracy: 0.8146 - val_loss: 0.3872 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 90/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.4224 - sparse_categorical_accuracy: 0.8229\n",
      "Epoch 90: val_loss improved from 0.38719 to 0.38588, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.4217 - sparse_categorical_accuracy: 0.8202 - val_loss: 0.3859 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 91/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.4088 - sparse_categorical_accuracy: 0.8393\n",
      "Epoch 91: val_loss improved from 0.38588 to 0.38394, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.4223 - sparse_categorical_accuracy: 0.8315 - val_loss: 0.3839 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 92/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.4286 - sparse_categorical_accuracy: 0.8079\n",
      "Epoch 92: val_loss did not improve from 0.38394\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.4284 - sparse_categorical_accuracy: 0.8071 - val_loss: 0.3856 - val_sparse_categorical_accuracy: 0.8539\n",
      "Epoch 93/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.4299 - sparse_categorical_accuracy: 0.8056\n",
      "Epoch 93: val_loss improved from 0.38394 to 0.38218, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.4200 - sparse_categorical_accuracy: 0.8071 - val_loss: 0.3822 - val_sparse_categorical_accuracy: 0.8764\n",
      "Epoch 94/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.4325 - sparse_categorical_accuracy: 0.8192\n",
      "Epoch 94: val_loss did not improve from 0.38218\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.4195 - sparse_categorical_accuracy: 0.8240 - val_loss: 0.3835 - val_sparse_categorical_accuracy: 0.8652\n",
      "Epoch 95/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.4036 - sparse_categorical_accuracy: 0.8341\n",
      "Epoch 95: val_loss improved from 0.38218 to 0.37793, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.4030 - sparse_categorical_accuracy: 0.8408 - val_loss: 0.3779 - val_sparse_categorical_accuracy: 0.8652\n",
      "Epoch 96/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.4043 - sparse_categorical_accuracy: 0.8396\n",
      "Epoch 96: val_loss improved from 0.37793 to 0.37657, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.4051 - sparse_categorical_accuracy: 0.8352 - val_loss: 0.3766 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 97/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.4173 - sparse_categorical_accuracy: 0.8125\n",
      "Epoch 97: val_loss improved from 0.37657 to 0.37585, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.4128 - sparse_categorical_accuracy: 0.8184 - val_loss: 0.3759 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 98/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.4369 - sparse_categorical_accuracy: 0.7996\n",
      "Epoch 98: val_loss improved from 0.37585 to 0.37484, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.4250 - sparse_categorical_accuracy: 0.8090 - val_loss: 0.3748 - val_sparse_categorical_accuracy: 0.8708\n",
      "Epoch 99/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.4098 - sparse_categorical_accuracy: 0.8167\n",
      "Epoch 99: val_loss improved from 0.37484 to 0.37339, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.4070 - sparse_categorical_accuracy: 0.8165 - val_loss: 0.3734 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 100/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.3939 - sparse_categorical_accuracy: 0.8438\n",
      "Epoch 100: val_loss improved from 0.37339 to 0.37138, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.4066 - sparse_categorical_accuracy: 0.8333 - val_loss: 0.3714 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 101/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.4111 - sparse_categorical_accuracy: 0.8341\n",
      "Epoch 101: val_loss improved from 0.37138 to 0.36848, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.4053 - sparse_categorical_accuracy: 0.8333 - val_loss: 0.3685 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 102/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.3896 - sparse_categorical_accuracy: 0.8468\n",
      "Epoch 102: val_loss improved from 0.36848 to 0.36846, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.3902 - sparse_categorical_accuracy: 0.8446 - val_loss: 0.3685 - val_sparse_categorical_accuracy: 0.8652\n",
      "Epoch 103/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.3988 - sparse_categorical_accuracy: 0.8384\n",
      "Epoch 103: val_loss improved from 0.36846 to 0.36633, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3934 - sparse_categorical_accuracy: 0.8446 - val_loss: 0.3663 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 104/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3871 - sparse_categorical_accuracy: 0.8438\n",
      "Epoch 104: val_loss improved from 0.36633 to 0.36554, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3908 - sparse_categorical_accuracy: 0.8408 - val_loss: 0.3655 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 105/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.4055 - sparse_categorical_accuracy: 0.8348\n",
      "Epoch 105: val_loss improved from 0.36554 to 0.36464, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.4007 - sparse_categorical_accuracy: 0.8408 - val_loss: 0.3646 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 106/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.3918 - sparse_categorical_accuracy: 0.8405\n",
      "Epoch 106: val_loss improved from 0.36464 to 0.36272, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.4025 - sparse_categorical_accuracy: 0.8371 - val_loss: 0.3627 - val_sparse_categorical_accuracy: 0.8764\n",
      "Epoch 107/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.3912 - sparse_categorical_accuracy: 0.8427\n",
      "Epoch 107: val_loss improved from 0.36272 to 0.36242, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3930 - sparse_categorical_accuracy: 0.8371 - val_loss: 0.3624 - val_sparse_categorical_accuracy: 0.8764\n",
      "Epoch 108/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3901 - sparse_categorical_accuracy: 0.8271\n",
      "Epoch 108: val_loss improved from 0.36242 to 0.36090, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.3842 - sparse_categorical_accuracy: 0.8371 - val_loss: 0.3609 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 109/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3815 - sparse_categorical_accuracy: 0.8521\n",
      "Epoch 109: val_loss improved from 0.36090 to 0.35962, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3891 - sparse_categorical_accuracy: 0.8483 - val_loss: 0.3596 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 110/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.3835 - sparse_categorical_accuracy: 0.8356\n",
      "Epoch 110: val_loss did not improve from 0.35962\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3923 - sparse_categorical_accuracy: 0.8277 - val_loss: 0.3600 - val_sparse_categorical_accuracy: 0.8708\n",
      "Epoch 111/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.3805 - sparse_categorical_accuracy: 0.8470\n",
      "Epoch 111: val_loss improved from 0.35962 to 0.35653, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3833 - sparse_categorical_accuracy: 0.8464 - val_loss: 0.3565 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 112/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.3929 - sparse_categorical_accuracy: 0.8486\n",
      "Epoch 112: val_loss improved from 0.35653 to 0.35639, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.3882 - sparse_categorical_accuracy: 0.8502 - val_loss: 0.3564 - val_sparse_categorical_accuracy: 0.8764\n",
      "Epoch 113/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.3661 - sparse_categorical_accuracy: 0.8657\n",
      "Epoch 113: val_loss improved from 0.35639 to 0.35478, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.3752 - sparse_categorical_accuracy: 0.8539 - val_loss: 0.3548 - val_sparse_categorical_accuracy: 0.8764\n",
      "Epoch 114/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.3833 - sparse_categorical_accuracy: 0.8348\n",
      "Epoch 114: val_loss improved from 0.35478 to 0.35366, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3861 - sparse_categorical_accuracy: 0.8315 - val_loss: 0.3537 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 115/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3761 - sparse_categorical_accuracy: 0.8458\n",
      "Epoch 115: val_loss improved from 0.35366 to 0.35328, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.3772 - sparse_categorical_accuracy: 0.8483 - val_loss: 0.3533 - val_sparse_categorical_accuracy: 0.8764\n",
      "Epoch 116/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3786 - sparse_categorical_accuracy: 0.8292\n",
      "Epoch 116: val_loss improved from 0.35328 to 0.35167, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3834 - sparse_categorical_accuracy: 0.8296 - val_loss: 0.3517 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 117/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.3937 - sparse_categorical_accuracy: 0.8367\n",
      "Epoch 117: val_loss did not improve from 0.35167\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3882 - sparse_categorical_accuracy: 0.8408 - val_loss: 0.3517 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 118/10000\n",
      "22/34 [==================>...........] - ETA: 0s - loss: 0.3791 - sparse_categorical_accuracy: 0.8494\n",
      "Epoch 118: val_loss improved from 0.35167 to 0.34979, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.3757 - sparse_categorical_accuracy: 0.8521 - val_loss: 0.3498 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 119/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.3722 - sparse_categorical_accuracy: 0.8578\n",
      "Epoch 119: val_loss did not improve from 0.34979\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3791 - sparse_categorical_accuracy: 0.8446 - val_loss: 0.3499 - val_sparse_categorical_accuracy: 0.8764\n",
      "Epoch 120/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.3885 - sparse_categorical_accuracy: 0.8428\n",
      "Epoch 120: val_loss improved from 0.34979 to 0.34783, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3867 - sparse_categorical_accuracy: 0.8446 - val_loss: 0.3478 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 121/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.3779 - sparse_categorical_accuracy: 0.8468\n",
      "Epoch 121: val_loss did not improve from 0.34783\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3755 - sparse_categorical_accuracy: 0.8464 - val_loss: 0.3482 - val_sparse_categorical_accuracy: 0.8764\n",
      "Epoch 122/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.3819 - sparse_categorical_accuracy: 0.8352\n",
      "Epoch 122: val_loss improved from 0.34783 to 0.34649, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3823 - sparse_categorical_accuracy: 0.8352 - val_loss: 0.3465 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 123/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.3882 - sparse_categorical_accuracy: 0.8428\n",
      "Epoch 123: val_loss improved from 0.34649 to 0.34502, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3864 - sparse_categorical_accuracy: 0.8446 - val_loss: 0.3450 - val_sparse_categorical_accuracy: 0.8764\n",
      "Epoch 124/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.3744 - sparse_categorical_accuracy: 0.8333\n",
      "Epoch 124: val_loss did not improve from 0.34502\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3756 - sparse_categorical_accuracy: 0.8333 - val_loss: 0.3452 - val_sparse_categorical_accuracy: 0.8764\n",
      "Epoch 125/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.3692 - sparse_categorical_accuracy: 0.8504\n",
      "Epoch 125: val_loss improved from 0.34502 to 0.34328, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3672 - sparse_categorical_accuracy: 0.8521 - val_loss: 0.3433 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 126/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.3656 - sparse_categorical_accuracy: 0.8693\n",
      "Epoch 126: val_loss improved from 0.34328 to 0.34324, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3699 - sparse_categorical_accuracy: 0.8670 - val_loss: 0.3432 - val_sparse_categorical_accuracy: 0.8764\n",
      "Epoch 127/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.3664 - sparse_categorical_accuracy: 0.8693\n",
      "Epoch 127: val_loss improved from 0.34324 to 0.34119, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3644 - sparse_categorical_accuracy: 0.8708 - val_loss: 0.3412 - val_sparse_categorical_accuracy: 0.8764\n",
      "Epoch 128/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.3712 - sparse_categorical_accuracy: 0.8418\n",
      "Epoch 128: val_loss improved from 0.34119 to 0.34064, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3754 - sparse_categorical_accuracy: 0.8390 - val_loss: 0.3406 - val_sparse_categorical_accuracy: 0.8764\n",
      "Epoch 129/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.3774 - sparse_categorical_accuracy: 0.8428\n",
      "Epoch 129: val_loss improved from 0.34064 to 0.33954, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3774 - sparse_categorical_accuracy: 0.8427 - val_loss: 0.3395 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 130/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.3585 - sparse_categorical_accuracy: 0.8629\n",
      "Epoch 130: val_loss improved from 0.33954 to 0.33954, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3547 - sparse_categorical_accuracy: 0.8652 - val_loss: 0.3395 - val_sparse_categorical_accuracy: 0.8764\n",
      "Epoch 131/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.3705 - sparse_categorical_accuracy: 0.8542\n",
      "Epoch 131: val_loss did not improve from 0.33954\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3684 - sparse_categorical_accuracy: 0.8558 - val_loss: 0.3397 - val_sparse_categorical_accuracy: 0.8764\n",
      "Epoch 132/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.3766 - sparse_categorical_accuracy: 0.8390\n",
      "Epoch 132: val_loss improved from 0.33954 to 0.33832, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3746 - sparse_categorical_accuracy: 0.8408 - val_loss: 0.3383 - val_sparse_categorical_accuracy: 0.8764\n",
      "Epoch 133/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.3746 - sparse_categorical_accuracy: 0.8295\n",
      "Epoch 133: val_loss did not improve from 0.33832\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3755 - sparse_categorical_accuracy: 0.8296 - val_loss: 0.3397 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 134/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.3668 - sparse_categorical_accuracy: 0.8320\n",
      "Epoch 134: val_loss improved from 0.33832 to 0.33741, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.3656 - sparse_categorical_accuracy: 0.8333 - val_loss: 0.3374 - val_sparse_categorical_accuracy: 0.8764\n",
      "Epoch 135/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.3693 - sparse_categorical_accuracy: 0.8438\n",
      "Epoch 135: val_loss improved from 0.33741 to 0.33520, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3668 - sparse_categorical_accuracy: 0.8446 - val_loss: 0.3352 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 136/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.3778 - sparse_categorical_accuracy: 0.8447\n",
      "Epoch 136: val_loss improved from 0.33520 to 0.33443, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.3752 - sparse_categorical_accuracy: 0.8464 - val_loss: 0.3344 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 137/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.3431 - sparse_categorical_accuracy: 0.8549\n",
      "Epoch 137: val_loss did not improve from 0.33443\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3498 - sparse_categorical_accuracy: 0.8502 - val_loss: 0.3352 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 138/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.3428 - sparse_categorical_accuracy: 0.8678\n",
      "Epoch 138: val_loss improved from 0.33443 to 0.33247, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.3589 - sparse_categorical_accuracy: 0.8558 - val_loss: 0.3325 - val_sparse_categorical_accuracy: 0.8764\n",
      "Epoch 139/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.3555 - sparse_categorical_accuracy: 0.8636\n",
      "Epoch 139: val_loss improved from 0.33247 to 0.33247, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3546 - sparse_categorical_accuracy: 0.8633 - val_loss: 0.3325 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 140/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3670 - sparse_categorical_accuracy: 0.8375\n",
      "Epoch 140: val_loss improved from 0.33247 to 0.33195, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3551 - sparse_categorical_accuracy: 0.8483 - val_loss: 0.3320 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 141/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.3624 - sparse_categorical_accuracy: 0.8447\n",
      "Epoch 141: val_loss improved from 0.33195 to 0.33128, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3625 - sparse_categorical_accuracy: 0.8464 - val_loss: 0.3313 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 142/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.3602 - sparse_categorical_accuracy: 0.8447\n",
      "Epoch 142: val_loss improved from 0.33128 to 0.33079, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3571 - sparse_categorical_accuracy: 0.8464 - val_loss: 0.3308 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 143/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.3563 - sparse_categorical_accuracy: 0.8578\n",
      "Epoch 143: val_loss improved from 0.33079 to 0.32967, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3512 - sparse_categorical_accuracy: 0.8652 - val_loss: 0.3297 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 144/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3734 - sparse_categorical_accuracy: 0.8408\n",
      "Epoch 144: val_loss improved from 0.32967 to 0.32887, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3734 - sparse_categorical_accuracy: 0.8408 - val_loss: 0.3289 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 145/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3416 - sparse_categorical_accuracy: 0.8875\n",
      "Epoch 145: val_loss improved from 0.32887 to 0.32818, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3503 - sparse_categorical_accuracy: 0.8783 - val_loss: 0.3282 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 146/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.3613 - sparse_categorical_accuracy: 0.8534\n",
      "Epoch 146: val_loss did not improve from 0.32818\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3533 - sparse_categorical_accuracy: 0.8596 - val_loss: 0.3283 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 147/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.3660 - sparse_categorical_accuracy: 0.8448\n",
      "Epoch 147: val_loss improved from 0.32818 to 0.32696, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3586 - sparse_categorical_accuracy: 0.8502 - val_loss: 0.3270 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 148/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3481 - sparse_categorical_accuracy: 0.8604\n",
      "Epoch 148: val_loss did not improve from 0.32696\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3523 - sparse_categorical_accuracy: 0.8577 - val_loss: 0.3280 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 149/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.3812 - sparse_categorical_accuracy: 0.8468\n",
      "Epoch 149: val_loss did not improve from 0.32696\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3698 - sparse_categorical_accuracy: 0.8539 - val_loss: 0.3271 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 150/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.3373 - sparse_categorical_accuracy: 0.8580\n",
      "Epoch 150: val_loss improved from 0.32696 to 0.32569, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3376 - sparse_categorical_accuracy: 0.8577 - val_loss: 0.3257 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 151/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.3461 - sparse_categorical_accuracy: 0.8599\n",
      "Epoch 151: val_loss did not improve from 0.32569\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3415 - sparse_categorical_accuracy: 0.8633 - val_loss: 0.3262 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 152/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.3447 - sparse_categorical_accuracy: 0.8548\n",
      "Epoch 152: val_loss improved from 0.32569 to 0.32403, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3535 - sparse_categorical_accuracy: 0.8502 - val_loss: 0.3240 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 153/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.3346 - sparse_categorical_accuracy: 0.8657\n",
      "Epoch 153: val_loss did not improve from 0.32403\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3400 - sparse_categorical_accuracy: 0.8558 - val_loss: 0.3244 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 154/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.3594 - sparse_categorical_accuracy: 0.8600\n",
      "Epoch 154: val_loss improved from 0.32403 to 0.32272, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.3540 - sparse_categorical_accuracy: 0.8652 - val_loss: 0.3227 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 155/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.3421 - sparse_categorical_accuracy: 0.8611\n",
      "Epoch 155: val_loss improved from 0.32272 to 0.32255, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3431 - sparse_categorical_accuracy: 0.8633 - val_loss: 0.3226 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 156/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3391 - sparse_categorical_accuracy: 0.8625\n",
      "Epoch 156: val_loss did not improve from 0.32255\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3473 - sparse_categorical_accuracy: 0.8539 - val_loss: 0.3237 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 157/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.3499 - sparse_categorical_accuracy: 0.8565\n",
      "Epoch 157: val_loss improved from 0.32255 to 0.32064, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3488 - sparse_categorical_accuracy: 0.8577 - val_loss: 0.3206 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 158/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.3338 - sparse_categorical_accuracy: 0.8571\n",
      "Epoch 158: val_loss improved from 0.32064 to 0.31979, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.3425 - sparse_categorical_accuracy: 0.8483 - val_loss: 0.3198 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 159/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.3352 - sparse_categorical_accuracy: 0.8571\n",
      "Epoch 159: val_loss did not improve from 0.31979\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3471 - sparse_categorical_accuracy: 0.8502 - val_loss: 0.3204 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 160/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.3484 - sparse_categorical_accuracy: 0.8495\n",
      "Epoch 160: val_loss improved from 0.31979 to 0.31820, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3407 - sparse_categorical_accuracy: 0.8502 - val_loss: 0.3182 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 161/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.3430 - sparse_categorical_accuracy: 0.8683\n",
      "Epoch 161: val_loss improved from 0.31820 to 0.31802, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.3425 - sparse_categorical_accuracy: 0.8652 - val_loss: 0.3180 - val_sparse_categorical_accuracy: 0.8764\n",
      "Epoch 162/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.3416 - sparse_categorical_accuracy: 0.8661\n",
      "Epoch 162: val_loss did not improve from 0.31802\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3375 - sparse_categorical_accuracy: 0.8670 - val_loss: 0.3194 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 163/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3382 - sparse_categorical_accuracy: 0.8625\n",
      "Epoch 163: val_loss improved from 0.31802 to 0.31589, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 1s 18ms/step - loss: 0.3426 - sparse_categorical_accuracy: 0.8539 - val_loss: 0.3159 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 164/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.3521 - sparse_categorical_accuracy: 0.8495\n",
      "Epoch 164: val_loss did not improve from 0.31589\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3403 - sparse_categorical_accuracy: 0.8577 - val_loss: 0.3159 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 165/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.3648 - sparse_categorical_accuracy: 0.8449\n",
      "Epoch 165: val_loss improved from 0.31589 to 0.31473, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.3464 - sparse_categorical_accuracy: 0.8558 - val_loss: 0.3147 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 166/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3464 - sparse_categorical_accuracy: 0.8521\n",
      "Epoch 166: val_loss did not improve from 0.31473\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3399 - sparse_categorical_accuracy: 0.8558 - val_loss: 0.3155 - val_sparse_categorical_accuracy: 0.8764\n",
      "Epoch 167/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.3332 - sparse_categorical_accuracy: 0.8669\n",
      "Epoch 167: val_loss did not improve from 0.31473\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3423 - sparse_categorical_accuracy: 0.8614 - val_loss: 0.3162 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 168/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3528 - sparse_categorical_accuracy: 0.8500\n",
      "Epoch 168: val_loss did not improve from 0.31473\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.3424 - sparse_categorical_accuracy: 0.8577 - val_loss: 0.3148 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 169/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.3474 - sparse_categorical_accuracy: 0.8625\n",
      "Epoch 169: val_loss improved from 0.31473 to 0.31316, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.3382 - sparse_categorical_accuracy: 0.8670 - val_loss: 0.3132 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 170/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.3628 - sparse_categorical_accuracy: 0.8470\n",
      "Epoch 170: val_loss did not improve from 0.31316\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3499 - sparse_categorical_accuracy: 0.8596 - val_loss: 0.3142 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 171/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3300 - sparse_categorical_accuracy: 0.8604\n",
      "Epoch 171: val_loss improved from 0.31316 to 0.31191, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3236 - sparse_categorical_accuracy: 0.8652 - val_loss: 0.3119 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 172/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.3341 - sparse_categorical_accuracy: 0.8599\n",
      "Epoch 172: val_loss improved from 0.31191 to 0.31137, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3343 - sparse_categorical_accuracy: 0.8596 - val_loss: 0.3114 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 173/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.3351 - sparse_categorical_accuracy: 0.8621\n",
      "Epoch 173: val_loss improved from 0.31137 to 0.31021, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3289 - sparse_categorical_accuracy: 0.8633 - val_loss: 0.3102 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 174/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.3398 - sparse_categorical_accuracy: 0.8548\n",
      "Epoch 174: val_loss did not improve from 0.31021\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3371 - sparse_categorical_accuracy: 0.8577 - val_loss: 0.3113 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 175/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.3270 - sparse_categorical_accuracy: 0.8616\n",
      "Epoch 175: val_loss improved from 0.31021 to 0.30843, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3333 - sparse_categorical_accuracy: 0.8577 - val_loss: 0.3084 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 176/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.3466 - sparse_categorical_accuracy: 0.8574\n",
      "Epoch 176: val_loss did not improve from 0.30843\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.3402 - sparse_categorical_accuracy: 0.8596 - val_loss: 0.3086 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 177/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.3318 - sparse_categorical_accuracy: 0.8727\n",
      "Epoch 177: val_loss did not improve from 0.30843\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3314 - sparse_categorical_accuracy: 0.8727 - val_loss: 0.3093 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 178/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.3341 - sparse_categorical_accuracy: 0.8669\n",
      "Epoch 178: val_loss improved from 0.30843 to 0.30761, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3314 - sparse_categorical_accuracy: 0.8670 - val_loss: 0.3076 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 179/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.3277 - sparse_categorical_accuracy: 0.8683\n",
      "Epoch 179: val_loss did not improve from 0.30761\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3265 - sparse_categorical_accuracy: 0.8708 - val_loss: 0.3086 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 180/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.3335 - sparse_categorical_accuracy: 0.8534\n",
      "Epoch 180: val_loss did not improve from 0.30761\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3270 - sparse_categorical_accuracy: 0.8614 - val_loss: 0.3083 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 181/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3433 - sparse_categorical_accuracy: 0.8604\n",
      "Epoch 181: val_loss improved from 0.30761 to 0.30637, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3375 - sparse_categorical_accuracy: 0.8670 - val_loss: 0.3064 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 182/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.3344 - sparse_categorical_accuracy: 0.8661\n",
      "Epoch 182: val_loss did not improve from 0.30637\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3271 - sparse_categorical_accuracy: 0.8689 - val_loss: 0.3067 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 183/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.3390 - sparse_categorical_accuracy: 0.8589\n",
      "Epoch 183: val_loss did not improve from 0.30637\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3365 - sparse_categorical_accuracy: 0.8614 - val_loss: 0.3068 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 184/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3195 - sparse_categorical_accuracy: 0.8667\n",
      "Epoch 184: val_loss improved from 0.30637 to 0.30623, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3270 - sparse_categorical_accuracy: 0.8652 - val_loss: 0.3062 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 185/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.3342 - sparse_categorical_accuracy: 0.8730\n",
      "Epoch 185: val_loss improved from 0.30623 to 0.30507, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.3284 - sparse_categorical_accuracy: 0.8745 - val_loss: 0.3051 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 186/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3449 - sparse_categorical_accuracy: 0.8687\n",
      "Epoch 186: val_loss improved from 0.30507 to 0.30487, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3331 - sparse_categorical_accuracy: 0.8708 - val_loss: 0.3049 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 187/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.3159 - sparse_categorical_accuracy: 0.8704\n",
      "Epoch 187: val_loss improved from 0.30487 to 0.30434, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3209 - sparse_categorical_accuracy: 0.8727 - val_loss: 0.3043 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 188/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.3479 - sparse_categorical_accuracy: 0.8468\n",
      "Epoch 188: val_loss improved from 0.30434 to 0.30352, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3437 - sparse_categorical_accuracy: 0.8464 - val_loss: 0.3035 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 189/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3194 - sparse_categorical_accuracy: 0.8729\n",
      "Epoch 189: val_loss improved from 0.30352 to 0.30283, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3198 - sparse_categorical_accuracy: 0.8764 - val_loss: 0.3028 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 190/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.3233 - sparse_categorical_accuracy: 0.8728\n",
      "Epoch 190: val_loss did not improve from 0.30283\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3323 - sparse_categorical_accuracy: 0.8708 - val_loss: 0.3038 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 191/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.3511 - sparse_categorical_accuracy: 0.8556\n",
      "Epoch 191: val_loss did not improve from 0.30283\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3396 - sparse_categorical_accuracy: 0.8652 - val_loss: 0.3029 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 192/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.3111 - sparse_categorical_accuracy: 0.8642\n",
      "Epoch 192: val_loss did not improve from 0.30283\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.3246 - sparse_categorical_accuracy: 0.8614 - val_loss: 0.3029 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 193/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.2936 - sparse_categorical_accuracy: 0.8975\n",
      "Epoch 193: val_loss improved from 0.30283 to 0.30109, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3195 - sparse_categorical_accuracy: 0.8708 - val_loss: 0.3011 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 194/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3150 - sparse_categorical_accuracy: 0.8708\n",
      "Epoch 194: val_loss did not improve from 0.30109\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3242 - sparse_categorical_accuracy: 0.8689 - val_loss: 0.3013 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 195/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3298 - sparse_categorical_accuracy: 0.8562\n",
      "Epoch 195: val_loss did not improve from 0.30109\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3291 - sparse_categorical_accuracy: 0.8596 - val_loss: 0.3017 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 196/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.3194 - sparse_categorical_accuracy: 0.8691\n",
      "Epoch 196: val_loss improved from 0.30109 to 0.30093, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3281 - sparse_categorical_accuracy: 0.8633 - val_loss: 0.3009 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 197/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3103 - sparse_categorical_accuracy: 0.8729\n",
      "Epoch 197: val_loss did not improve from 0.30093\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3162 - sparse_categorical_accuracy: 0.8708 - val_loss: 0.3012 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 198/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.3317 - sparse_categorical_accuracy: 0.8542\n",
      "Epoch 198: val_loss did not improve from 0.30093\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3292 - sparse_categorical_accuracy: 0.8577 - val_loss: 0.3011 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 199/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.3067 - sparse_categorical_accuracy: 0.8750\n",
      "Epoch 199: val_loss improved from 0.30093 to 0.30069, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3252 - sparse_categorical_accuracy: 0.8633 - val_loss: 0.3007 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 200/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3176 - sparse_categorical_accuracy: 0.8652\n",
      "Epoch 200: val_loss did not improve from 0.30069\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3176 - sparse_categorical_accuracy: 0.8652 - val_loss: 0.3023 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 201/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3226 - sparse_categorical_accuracy: 0.8708\n",
      "Epoch 201: val_loss improved from 0.30069 to 0.30046, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3185 - sparse_categorical_accuracy: 0.8727 - val_loss: 0.3005 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 202/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.3072 - sparse_categorical_accuracy: 0.8879\n",
      "Epoch 202: val_loss improved from 0.30046 to 0.29937, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3084 - sparse_categorical_accuracy: 0.8839 - val_loss: 0.2994 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 203/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.3182 - sparse_categorical_accuracy: 0.8685\n",
      "Epoch 203: val_loss improved from 0.29937 to 0.29758, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3124 - sparse_categorical_accuracy: 0.8745 - val_loss: 0.2976 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 204/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.3076 - sparse_categorical_accuracy: 0.8770\n",
      "Epoch 204: val_loss did not improve from 0.29758\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3130 - sparse_categorical_accuracy: 0.8689 - val_loss: 0.2982 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 205/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3163 - sparse_categorical_accuracy: 0.8813\n",
      "Epoch 205: val_loss did not improve from 0.29758\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3247 - sparse_categorical_accuracy: 0.8801 - val_loss: 0.2984 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 206/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.3265 - sparse_categorical_accuracy: 0.8636\n",
      "Epoch 206: val_loss did not improve from 0.29758\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.3313 - sparse_categorical_accuracy: 0.8614 - val_loss: 0.2977 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 207/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.3334 - sparse_categorical_accuracy: 0.8725\n",
      "Epoch 207: val_loss improved from 0.29758 to 0.29693, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.3283 - sparse_categorical_accuracy: 0.8652 - val_loss: 0.2969 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 208/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.3186 - sparse_categorical_accuracy: 0.8728\n",
      "Epoch 208: val_loss did not improve from 0.29693\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3209 - sparse_categorical_accuracy: 0.8652 - val_loss: 0.2981 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 209/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.3297 - sparse_categorical_accuracy: 0.8569\n",
      "Epoch 209: val_loss improved from 0.29693 to 0.29641, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3199 - sparse_categorical_accuracy: 0.8596 - val_loss: 0.2964 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 210/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.3304 - sparse_categorical_accuracy: 0.8774\n",
      "Epoch 210: val_loss improved from 0.29641 to 0.29531, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.3314 - sparse_categorical_accuracy: 0.8670 - val_loss: 0.2953 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 211/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3209 - sparse_categorical_accuracy: 0.8729\n",
      "Epoch 211: val_loss improved from 0.29531 to 0.29482, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3187 - sparse_categorical_accuracy: 0.8745 - val_loss: 0.2948 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 212/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.3079 - sparse_categorical_accuracy: 0.8728\n",
      "Epoch 212: val_loss did not improve from 0.29482\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3144 - sparse_categorical_accuracy: 0.8727 - val_loss: 0.2968 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 213/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.3170 - sparse_categorical_accuracy: 0.8711\n",
      "Epoch 213: val_loss improved from 0.29482 to 0.29395, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3183 - sparse_categorical_accuracy: 0.8708 - val_loss: 0.2939 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 214/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.3248 - sparse_categorical_accuracy: 0.8664\n",
      "Epoch 214: val_loss did not improve from 0.29395\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.3245 - sparse_categorical_accuracy: 0.8708 - val_loss: 0.2947 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 215/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3038 - sparse_categorical_accuracy: 0.8750\n",
      "Epoch 215: val_loss did not improve from 0.29395\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3103 - sparse_categorical_accuracy: 0.8670 - val_loss: 0.2992 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 216/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.3117 - sparse_categorical_accuracy: 0.8683\n",
      "Epoch 216: val_loss did not improve from 0.29395\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3151 - sparse_categorical_accuracy: 0.8633 - val_loss: 0.2964 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 217/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.3227 - sparse_categorical_accuracy: 0.8804\n",
      "Epoch 217: val_loss did not improve from 0.29395\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3214 - sparse_categorical_accuracy: 0.8745 - val_loss: 0.2945 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 218/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.3119 - sparse_categorical_accuracy: 0.8795\n",
      "Epoch 218: val_loss improved from 0.29395 to 0.29340, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3043 - sparse_categorical_accuracy: 0.8858 - val_loss: 0.2934 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 219/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3234 - sparse_categorical_accuracy: 0.8667\n",
      "Epoch 219: val_loss improved from 0.29340 to 0.29311, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3193 - sparse_categorical_accuracy: 0.8708 - val_loss: 0.2931 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 220/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.3018 - sparse_categorical_accuracy: 0.8772\n",
      "Epoch 220: val_loss improved from 0.29311 to 0.29265, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3124 - sparse_categorical_accuracy: 0.8727 - val_loss: 0.2927 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 221/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.3085 - sparse_categorical_accuracy: 0.8730\n",
      "Epoch 221: val_loss improved from 0.29265 to 0.29193, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.3036 - sparse_categorical_accuracy: 0.8764 - val_loss: 0.2919 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 222/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.3253 - sparse_categorical_accuracy: 0.8565\n",
      "Epoch 222: val_loss did not improve from 0.29193\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3070 - sparse_categorical_accuracy: 0.8539 - val_loss: 0.2927 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 223/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.3064 - sparse_categorical_accuracy: 0.8649\n",
      "Epoch 223: val_loss improved from 0.29193 to 0.29166, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3131 - sparse_categorical_accuracy: 0.8633 - val_loss: 0.2917 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 224/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2998 - sparse_categorical_accuracy: 0.8793\n",
      "Epoch 224: val_loss improved from 0.29166 to 0.29147, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3078 - sparse_categorical_accuracy: 0.8783 - val_loss: 0.2915 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 225/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.3279 - sparse_categorical_accuracy: 0.8685\n",
      "Epoch 225: val_loss did not improve from 0.29147\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3203 - sparse_categorical_accuracy: 0.8689 - val_loss: 0.2922 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 226/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3256 - sparse_categorical_accuracy: 0.8542\n",
      "Epoch 226: val_loss did not improve from 0.29147\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3165 - sparse_categorical_accuracy: 0.8577 - val_loss: 0.2930 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 227/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.2797 - sparse_categorical_accuracy: 0.8958\n",
      "Epoch 227: val_loss improved from 0.29147 to 0.28959, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3117 - sparse_categorical_accuracy: 0.8727 - val_loss: 0.2896 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 228/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.3118 - sparse_categorical_accuracy: 0.8731\n",
      "Epoch 228: val_loss improved from 0.28959 to 0.28870, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.3147 - sparse_categorical_accuracy: 0.8708 - val_loss: 0.2887 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 229/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.3142 - sparse_categorical_accuracy: 0.8772\n",
      "Epoch 229: val_loss did not improve from 0.28870\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3120 - sparse_categorical_accuracy: 0.8783 - val_loss: 0.2916 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 230/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3234 - sparse_categorical_accuracy: 0.8708\n",
      "Epoch 230: val_loss did not improve from 0.28870\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3171 - sparse_categorical_accuracy: 0.8745 - val_loss: 0.2914 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 231/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.2831 - sparse_categorical_accuracy: 0.8750\n",
      "Epoch 231: val_loss improved from 0.28870 to 0.28852, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2932 - sparse_categorical_accuracy: 0.8727 - val_loss: 0.2885 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 232/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3269 - sparse_categorical_accuracy: 0.8604\n",
      "Epoch 232: val_loss improved from 0.28852 to 0.28808, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3116 - sparse_categorical_accuracy: 0.8708 - val_loss: 0.2881 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 233/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.3153 - sparse_categorical_accuracy: 0.8652\n",
      "Epoch 233: val_loss did not improve from 0.28808\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3104 - sparse_categorical_accuracy: 0.8670 - val_loss: 0.2893 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 234/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.3052 - sparse_categorical_accuracy: 0.8911\n",
      "Epoch 234: val_loss did not improve from 0.28808\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2996 - sparse_categorical_accuracy: 0.8951 - val_loss: 0.2887 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 235/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3029 - sparse_categorical_accuracy: 0.8708\n",
      "Epoch 235: val_loss improved from 0.28808 to 0.28753, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.3029 - sparse_categorical_accuracy: 0.8708 - val_loss: 0.2875 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 236/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2789 - sparse_categorical_accuracy: 0.8875\n",
      "Epoch 236: val_loss improved from 0.28753 to 0.28686, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 1s 19ms/step - loss: 0.2927 - sparse_categorical_accuracy: 0.8783 - val_loss: 0.2869 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 237/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.3035 - sparse_categorical_accuracy: 0.8809\n",
      "Epoch 237: val_loss did not improve from 0.28686\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3031 - sparse_categorical_accuracy: 0.8801 - val_loss: 0.2878 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 238/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.3251 - sparse_categorical_accuracy: 0.8588\n",
      "Epoch 238: val_loss improved from 0.28686 to 0.28428, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3212 - sparse_categorical_accuracy: 0.8614 - val_loss: 0.2843 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 239/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3196 - sparse_categorical_accuracy: 0.8667\n",
      "Epoch 239: val_loss did not improve from 0.28428\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3191 - sparse_categorical_accuracy: 0.8633 - val_loss: 0.2859 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 240/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.2993 - sparse_categorical_accuracy: 0.8654\n",
      "Epoch 240: val_loss did not improve from 0.28428\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.3094 - sparse_categorical_accuracy: 0.8689 - val_loss: 0.2853 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 241/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.3019 - sparse_categorical_accuracy: 0.8750\n",
      "Epoch 241: val_loss did not improve from 0.28428\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3060 - sparse_categorical_accuracy: 0.8727 - val_loss: 0.2858 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 242/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2928 - sparse_categorical_accuracy: 0.8729\n",
      "Epoch 242: val_loss improved from 0.28428 to 0.28404, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2945 - sparse_categorical_accuracy: 0.8727 - val_loss: 0.2840 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 243/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.2857 - sparse_categorical_accuracy: 0.8894\n",
      "Epoch 243: val_loss did not improve from 0.28404\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2963 - sparse_categorical_accuracy: 0.8764 - val_loss: 0.2852 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 244/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.3036 - sparse_categorical_accuracy: 0.8710\n",
      "Epoch 244: val_loss did not improve from 0.28404\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3004 - sparse_categorical_accuracy: 0.8745 - val_loss: 0.2878 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 245/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3047 - sparse_categorical_accuracy: 0.8792\n",
      "Epoch 245: val_loss did not improve from 0.28404\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3049 - sparse_categorical_accuracy: 0.8764 - val_loss: 0.2857 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 246/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.2973 - sparse_categorical_accuracy: 0.8862\n",
      "Epoch 246: val_loss did not improve from 0.28404\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2945 - sparse_categorical_accuracy: 0.8839 - val_loss: 0.2858 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 247/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.3057 - sparse_categorical_accuracy: 0.8810\n",
      "Epoch 247: val_loss improved from 0.28404 to 0.28226, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3081 - sparse_categorical_accuracy: 0.8745 - val_loss: 0.2823 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 248/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.3006 - sparse_categorical_accuracy: 0.8750\n",
      "Epoch 248: val_loss did not improve from 0.28226\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3010 - sparse_categorical_accuracy: 0.8727 - val_loss: 0.2847 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 249/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.3078 - sparse_categorical_accuracy: 0.8704\n",
      "Epoch 249: val_loss did not improve from 0.28226\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2932 - sparse_categorical_accuracy: 0.8820 - val_loss: 0.2823 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 250/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2999 - sparse_categorical_accuracy: 0.8810\n",
      "Epoch 250: val_loss improved from 0.28226 to 0.28176, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2958 - sparse_categorical_accuracy: 0.8839 - val_loss: 0.2818 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 251/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.2968 - sparse_categorical_accuracy: 0.8846\n",
      "Epoch 251: val_loss did not improve from 0.28176\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2885 - sparse_categorical_accuracy: 0.8876 - val_loss: 0.2831 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 252/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2901 - sparse_categorical_accuracy: 0.8810\n",
      "Epoch 252: val_loss improved from 0.28176 to 0.28099, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2963 - sparse_categorical_accuracy: 0.8783 - val_loss: 0.2810 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 253/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.3011 - sparse_categorical_accuracy: 0.8730\n",
      "Epoch 253: val_loss did not improve from 0.28099\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3009 - sparse_categorical_accuracy: 0.8745 - val_loss: 0.2819 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 254/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3097 - sparse_categorical_accuracy: 0.8727\n",
      "Epoch 254: val_loss improved from 0.28099 to 0.28010, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.3097 - sparse_categorical_accuracy: 0.8727 - val_loss: 0.2801 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 255/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.3108 - sparse_categorical_accuracy: 0.8810\n",
      "Epoch 255: val_loss did not improve from 0.28010\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3032 - sparse_categorical_accuracy: 0.8858 - val_loss: 0.2829 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 256/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.3047 - sparse_categorical_accuracy: 0.8705\n",
      "Epoch 256: val_loss did not improve from 0.28010\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3044 - sparse_categorical_accuracy: 0.8670 - val_loss: 0.2821 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 257/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2835 - sparse_categorical_accuracy: 0.8917\n",
      "Epoch 257: val_loss did not improve from 0.28010\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2987 - sparse_categorical_accuracy: 0.8858 - val_loss: 0.2833 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 258/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.3012 - sparse_categorical_accuracy: 0.8773\n",
      "Epoch 258: val_loss improved from 0.28010 to 0.27906, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.3031 - sparse_categorical_accuracy: 0.8801 - val_loss: 0.2791 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 259/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3057 - sparse_categorical_accuracy: 0.8708\n",
      "Epoch 259: val_loss did not improve from 0.27906\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3038 - sparse_categorical_accuracy: 0.8727 - val_loss: 0.2822 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 260/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.2773 - sparse_categorical_accuracy: 0.9051\n",
      "Epoch 260: val_loss did not improve from 0.27906\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2958 - sparse_categorical_accuracy: 0.8895 - val_loss: 0.2812 - val_sparse_categorical_accuracy: 0.8820\n",
      "Epoch 261/10000\n",
      "22/34 [==================>...........] - ETA: 0s - loss: 0.3213 - sparse_categorical_accuracy: 0.8636\n",
      "Epoch 261: val_loss did not improve from 0.27906\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3093 - sparse_categorical_accuracy: 0.8670 - val_loss: 0.2796 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 262/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.2915 - sparse_categorical_accuracy: 0.8800\n",
      "Epoch 262: val_loss did not improve from 0.27906\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2910 - sparse_categorical_accuracy: 0.8820 - val_loss: 0.2827 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 263/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.3013 - sparse_categorical_accuracy: 0.8625\n",
      "Epoch 263: val_loss did not improve from 0.27906\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2947 - sparse_categorical_accuracy: 0.8745 - val_loss: 0.2793 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 264/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2960 - sparse_categorical_accuracy: 0.8896\n",
      "Epoch 264: val_loss improved from 0.27906 to 0.27904, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2983 - sparse_categorical_accuracy: 0.8858 - val_loss: 0.2790 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 265/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2960 - sparse_categorical_accuracy: 0.8729\n",
      "Epoch 265: val_loss improved from 0.27904 to 0.27748, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.2929 - sparse_categorical_accuracy: 0.8764 - val_loss: 0.2775 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 266/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2959 - sparse_categorical_accuracy: 0.8750\n",
      "Epoch 266: val_loss did not improve from 0.27748\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3003 - sparse_categorical_accuracy: 0.8727 - val_loss: 0.2784 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 267/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3004 - sparse_categorical_accuracy: 0.8764\n",
      "Epoch 267: val_loss did not improve from 0.27748\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.3004 - sparse_categorical_accuracy: 0.8764 - val_loss: 0.2780 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 268/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.3091 - sparse_categorical_accuracy: 0.8707\n",
      "Epoch 268: val_loss did not improve from 0.27748\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2949 - sparse_categorical_accuracy: 0.8801 - val_loss: 0.2792 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 269/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3081 - sparse_categorical_accuracy: 0.8792\n",
      "Epoch 269: val_loss improved from 0.27748 to 0.27660, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3053 - sparse_categorical_accuracy: 0.8783 - val_loss: 0.2766 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 270/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.3208 - sparse_categorical_accuracy: 0.8638\n",
      "Epoch 270: val_loss did not improve from 0.27660\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3019 - sparse_categorical_accuracy: 0.8727 - val_loss: 0.2779 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 271/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3045 - sparse_categorical_accuracy: 0.8854\n",
      "Epoch 271: val_loss did not improve from 0.27660\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2989 - sparse_categorical_accuracy: 0.8914 - val_loss: 0.2780 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 272/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2799 - sparse_categorical_accuracy: 0.8750\n",
      "Epoch 272: val_loss did not improve from 0.27660\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2938 - sparse_categorical_accuracy: 0.8708 - val_loss: 0.2784 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 273/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.3009 - sparse_categorical_accuracy: 0.8750\n",
      "Epoch 273: val_loss improved from 0.27660 to 0.27582, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2997 - sparse_categorical_accuracy: 0.8745 - val_loss: 0.2758 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 274/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2968 - sparse_categorical_accuracy: 0.8854\n",
      "Epoch 274: val_loss did not improve from 0.27582\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2975 - sparse_categorical_accuracy: 0.8876 - val_loss: 0.2764 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 275/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2866 - sparse_categorical_accuracy: 0.8792\n",
      "Epoch 275: val_loss did not improve from 0.27582\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2936 - sparse_categorical_accuracy: 0.8783 - val_loss: 0.2760 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 276/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2946 - sparse_categorical_accuracy: 0.8896\n",
      "Epoch 276: val_loss did not improve from 0.27582\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2945 - sparse_categorical_accuracy: 0.8895 - val_loss: 0.2767 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 277/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.3019 - sparse_categorical_accuracy: 0.8681\n",
      "Epoch 277: val_loss improved from 0.27582 to 0.27374, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2956 - sparse_categorical_accuracy: 0.8689 - val_loss: 0.2737 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 278/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2940 - sparse_categorical_accuracy: 0.8750\n",
      "Epoch 278: val_loss did not improve from 0.27374\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2889 - sparse_categorical_accuracy: 0.8783 - val_loss: 0.2761 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 279/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2799 - sparse_categorical_accuracy: 0.8851\n",
      "Epoch 279: val_loss improved from 0.27374 to 0.27338, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2866 - sparse_categorical_accuracy: 0.8801 - val_loss: 0.2734 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 280/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3004 - sparse_categorical_accuracy: 0.8813\n",
      "Epoch 280: val_loss improved from 0.27338 to 0.27322, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2976 - sparse_categorical_accuracy: 0.8820 - val_loss: 0.2732 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 281/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.2861 - sparse_categorical_accuracy: 0.8750\n",
      "Epoch 281: val_loss did not improve from 0.27322\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2935 - sparse_categorical_accuracy: 0.8783 - val_loss: 0.2757 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 282/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2868 - sparse_categorical_accuracy: 0.8831\n",
      "Epoch 282: val_loss improved from 0.27322 to 0.27278, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2853 - sparse_categorical_accuracy: 0.8820 - val_loss: 0.2728 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 283/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.2861 - sparse_categorical_accuracy: 0.8862\n",
      "Epoch 283: val_loss improved from 0.27278 to 0.27179, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2834 - sparse_categorical_accuracy: 0.8895 - val_loss: 0.2718 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 284/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.3060 - sparse_categorical_accuracy: 0.8582\n",
      "Epoch 284: val_loss did not improve from 0.27179\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2898 - sparse_categorical_accuracy: 0.8708 - val_loss: 0.2728 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 285/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.3001 - sparse_categorical_accuracy: 0.8728\n",
      "Epoch 285: val_loss did not improve from 0.27179\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2934 - sparse_categorical_accuracy: 0.8801 - val_loss: 0.2726 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 286/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2818 - sparse_categorical_accuracy: 0.8729\n",
      "Epoch 286: val_loss did not improve from 0.27179\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2848 - sparse_categorical_accuracy: 0.8708 - val_loss: 0.2721 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 287/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.2864 - sparse_categorical_accuracy: 0.8775\n",
      "Epoch 287: val_loss did not improve from 0.27179\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2773 - sparse_categorical_accuracy: 0.8839 - val_loss: 0.2732 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 288/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2932 - sparse_categorical_accuracy: 0.8685\n",
      "Epoch 288: val_loss did not improve from 0.27179\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2911 - sparse_categorical_accuracy: 0.8745 - val_loss: 0.2726 - val_sparse_categorical_accuracy: 0.8876\n",
      "Epoch 289/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2890 - sparse_categorical_accuracy: 0.8729\n",
      "Epoch 289: val_loss did not improve from 0.27179\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2863 - sparse_categorical_accuracy: 0.8764 - val_loss: 0.2723 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 290/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.3080 - sparse_categorical_accuracy: 0.8798\n",
      "Epoch 290: val_loss improved from 0.27179 to 0.27108, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.3060 - sparse_categorical_accuracy: 0.8764 - val_loss: 0.2711 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 291/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.2907 - sparse_categorical_accuracy: 0.8750\n",
      "Epoch 291: val_loss did not improve from 0.27108\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2975 - sparse_categorical_accuracy: 0.8727 - val_loss: 0.2723 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 292/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.2728 - sparse_categorical_accuracy: 0.8862\n",
      "Epoch 292: val_loss did not improve from 0.27108\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2945 - sparse_categorical_accuracy: 0.8783 - val_loss: 0.2732 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 293/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.2982 - sparse_categorical_accuracy: 0.8638\n",
      "Epoch 293: val_loss did not improve from 0.27108\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2993 - sparse_categorical_accuracy: 0.8689 - val_loss: 0.2719 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 294/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.3031 - sparse_categorical_accuracy: 0.8726\n",
      "Epoch 294: val_loss improved from 0.27108 to 0.26931, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2914 - sparse_categorical_accuracy: 0.8801 - val_loss: 0.2693 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 295/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.2884 - sparse_categorical_accuracy: 0.8843\n",
      "Epoch 295: val_loss did not improve from 0.26931\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2851 - sparse_categorical_accuracy: 0.8839 - val_loss: 0.2712 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 296/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3218 - sparse_categorical_accuracy: 0.8625\n",
      "Epoch 296: val_loss did not improve from 0.26931\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.3053 - sparse_categorical_accuracy: 0.8745 - val_loss: 0.2704 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 297/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2720 - sparse_categorical_accuracy: 0.8922\n",
      "Epoch 297: val_loss did not improve from 0.26931\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2754 - sparse_categorical_accuracy: 0.8970 - val_loss: 0.2694 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 298/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2898 - sparse_categorical_accuracy: 0.8831\n",
      "Epoch 298: val_loss did not improve from 0.26931\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2933 - sparse_categorical_accuracy: 0.8801 - val_loss: 0.2697 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 299/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.3018 - sparse_categorical_accuracy: 0.8625\n",
      "Epoch 299: val_loss did not improve from 0.26931\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2929 - sparse_categorical_accuracy: 0.8708 - val_loss: 0.2710 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 300/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.2853 - sparse_categorical_accuracy: 0.8796\n",
      "Epoch 300: val_loss improved from 0.26931 to 0.26797, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2914 - sparse_categorical_accuracy: 0.8839 - val_loss: 0.2680 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 301/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2781 - sparse_categorical_accuracy: 0.8771\n",
      "Epoch 301: val_loss did not improve from 0.26797\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2764 - sparse_categorical_accuracy: 0.8745 - val_loss: 0.2698 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 302/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2942 - sparse_categorical_accuracy: 0.8708\n",
      "Epoch 302: val_loss did not improve from 0.26797\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2913 - sparse_categorical_accuracy: 0.8745 - val_loss: 0.2686 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 303/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.2918 - sparse_categorical_accuracy: 0.8750\n",
      "Epoch 303: val_loss did not improve from 0.26797\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2811 - sparse_categorical_accuracy: 0.8820 - val_loss: 0.2684 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 304/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.2811 - sparse_categorical_accuracy: 0.8866\n",
      "Epoch 304: val_loss improved from 0.26797 to 0.26750, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2877 - sparse_categorical_accuracy: 0.8745 - val_loss: 0.2675 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 305/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.2999 - sparse_categorical_accuracy: 0.8611\n",
      "Epoch 305: val_loss improved from 0.26750 to 0.26729, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2845 - sparse_categorical_accuracy: 0.8745 - val_loss: 0.2673 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 306/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2839 - sparse_categorical_accuracy: 0.8875\n",
      "Epoch 306: val_loss did not improve from 0.26729\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2840 - sparse_categorical_accuracy: 0.8839 - val_loss: 0.2681 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 307/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2694 - sparse_categorical_accuracy: 0.9021\n",
      "Epoch 307: val_loss did not improve from 0.26729\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2818 - sparse_categorical_accuracy: 0.8914 - val_loss: 0.2688 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 308/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2727 - sparse_categorical_accuracy: 0.8815\n",
      "Epoch 308: val_loss did not improve from 0.26729\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2862 - sparse_categorical_accuracy: 0.8820 - val_loss: 0.2697 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 309/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2856 - sparse_categorical_accuracy: 0.8710\n",
      "Epoch 309: val_loss did not improve from 0.26729\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2885 - sparse_categorical_accuracy: 0.8670 - val_loss: 0.2679 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 310/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2912 - sparse_categorical_accuracy: 0.8770\n",
      "Epoch 310: val_loss improved from 0.26729 to 0.26544, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2842 - sparse_categorical_accuracy: 0.8820 - val_loss: 0.2654 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 311/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.2904 - sparse_categorical_accuracy: 0.8912\n",
      "Epoch 311: val_loss did not improve from 0.26544\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2818 - sparse_categorical_accuracy: 0.8895 - val_loss: 0.2669 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 312/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2773 - sparse_categorical_accuracy: 0.8891\n",
      "Epoch 312: val_loss did not improve from 0.26544\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2865 - sparse_categorical_accuracy: 0.8858 - val_loss: 0.2667 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 313/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.2929 - sparse_categorical_accuracy: 0.8693\n",
      "Epoch 313: val_loss did not improve from 0.26544\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2907 - sparse_categorical_accuracy: 0.8708 - val_loss: 0.2667 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 314/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.2717 - sparse_categorical_accuracy: 0.8996\n",
      "Epoch 314: val_loss improved from 0.26544 to 0.26479, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2732 - sparse_categorical_accuracy: 0.8989 - val_loss: 0.2648 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 315/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2965 - sparse_categorical_accuracy: 0.8729\n",
      "Epoch 315: val_loss did not improve from 0.26479\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2840 - sparse_categorical_accuracy: 0.8820 - val_loss: 0.2657 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 316/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2872 - sparse_categorical_accuracy: 0.8691\n",
      "Epoch 316: val_loss did not improve from 0.26479\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2909 - sparse_categorical_accuracy: 0.8708 - val_loss: 0.2655 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 317/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2760 - sparse_categorical_accuracy: 0.8854\n",
      "Epoch 317: val_loss did not improve from 0.26479\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2728 - sparse_categorical_accuracy: 0.8858 - val_loss: 0.2656 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 318/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2871 - sparse_categorical_accuracy: 0.8815\n",
      "Epoch 318: val_loss did not improve from 0.26479\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2815 - sparse_categorical_accuracy: 0.8820 - val_loss: 0.2672 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 319/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2832 - sparse_categorical_accuracy: 0.8875\n",
      "Epoch 319: val_loss did not improve from 0.26479\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2812 - sparse_categorical_accuracy: 0.8914 - val_loss: 0.2668 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 320/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2776 - sparse_categorical_accuracy: 0.8858\n",
      "Epoch 320: val_loss did not improve from 0.26479\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2795 - sparse_categorical_accuracy: 0.8820 - val_loss: 0.2649 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 321/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.2693 - sparse_categorical_accuracy: 0.8845\n",
      "Epoch 321: val_loss improved from 0.26479 to 0.26386, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.2706 - sparse_categorical_accuracy: 0.8839 - val_loss: 0.2639 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 322/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2799 - sparse_categorical_accuracy: 0.8887\n",
      "Epoch 322: val_loss did not improve from 0.26386\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2804 - sparse_categorical_accuracy: 0.8895 - val_loss: 0.2647 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 323/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2792 - sparse_categorical_accuracy: 0.8652\n",
      "Epoch 323: val_loss did not improve from 0.26386\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2792 - sparse_categorical_accuracy: 0.8652 - val_loss: 0.2646 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 324/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.2715 - sparse_categorical_accuracy: 0.8902\n",
      "Epoch 324: val_loss did not improve from 0.26386\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2729 - sparse_categorical_accuracy: 0.8895 - val_loss: 0.2650 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 325/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2712 - sparse_categorical_accuracy: 0.9009\n",
      "Epoch 325: val_loss improved from 0.26386 to 0.26322, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2813 - sparse_categorical_accuracy: 0.8914 - val_loss: 0.2632 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 326/10000\n",
      "21/34 [=================>............] - ETA: 0s - loss: 0.3026 - sparse_categorical_accuracy: 0.8750\n",
      "Epoch 326: val_loss improved from 0.26322 to 0.26175, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2723 - sparse_categorical_accuracy: 0.8951 - val_loss: 0.2617 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 327/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2874 - sparse_categorical_accuracy: 0.8771\n",
      "Epoch 327: val_loss did not improve from 0.26175\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2869 - sparse_categorical_accuracy: 0.8783 - val_loss: 0.2636 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 328/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2801 - sparse_categorical_accuracy: 0.8750\n",
      "Epoch 328: val_loss did not improve from 0.26175\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2745 - sparse_categorical_accuracy: 0.8783 - val_loss: 0.2635 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 329/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2770 - sparse_categorical_accuracy: 0.8933\n",
      "Epoch 329: val_loss did not improve from 0.26175\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2770 - sparse_categorical_accuracy: 0.8933 - val_loss: 0.2625 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 330/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2749 - sparse_categorical_accuracy: 0.8831\n",
      "Epoch 330: val_loss did not improve from 0.26175\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2666 - sparse_categorical_accuracy: 0.8895 - val_loss: 0.2629 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 331/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2685 - sparse_categorical_accuracy: 0.8984\n",
      "Epoch 331: val_loss did not improve from 0.26175\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2631 - sparse_categorical_accuracy: 0.9026 - val_loss: 0.2619 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 332/10000\n",
      "19/34 [===============>..............] - ETA: 0s - loss: 0.2734 - sparse_categorical_accuracy: 0.8717\n",
      "Epoch 332: val_loss improved from 0.26175 to 0.26112, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2761 - sparse_categorical_accuracy: 0.8801 - val_loss: 0.2611 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 333/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2682 - sparse_categorical_accuracy: 0.8945\n",
      "Epoch 333: val_loss did not improve from 0.26112\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2673 - sparse_categorical_accuracy: 0.8933 - val_loss: 0.2614 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 334/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2741 - sparse_categorical_accuracy: 0.8848\n",
      "Epoch 334: val_loss improved from 0.26112 to 0.25946, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2776 - sparse_categorical_accuracy: 0.8820 - val_loss: 0.2595 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 335/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2797 - sparse_categorical_accuracy: 0.8906\n",
      "Epoch 335: val_loss did not improve from 0.25946\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2772 - sparse_categorical_accuracy: 0.8895 - val_loss: 0.2602 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 336/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2732 - sparse_categorical_accuracy: 0.8848\n",
      "Epoch 336: val_loss did not improve from 0.25946\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2701 - sparse_categorical_accuracy: 0.8876 - val_loss: 0.2607 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 337/10000\n",
      "21/34 [=================>............] - ETA: 0s - loss: 0.2636 - sparse_categorical_accuracy: 0.9018\n",
      "Epoch 337: val_loss did not improve from 0.25946\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2724 - sparse_categorical_accuracy: 0.8970 - val_loss: 0.2608 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 338/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2889 - sparse_categorical_accuracy: 0.8875\n",
      "Epoch 338: val_loss improved from 0.25946 to 0.25943, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2799 - sparse_categorical_accuracy: 0.8951 - val_loss: 0.2594 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 339/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2717 - sparse_categorical_accuracy: 0.8917\n",
      "Epoch 339: val_loss did not improve from 0.25943\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2754 - sparse_categorical_accuracy: 0.8876 - val_loss: 0.2595 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 340/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.2764 - sparse_categorical_accuracy: 0.8807\n",
      "Epoch 340: val_loss improved from 0.25943 to 0.25908, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2754 - sparse_categorical_accuracy: 0.8820 - val_loss: 0.2591 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 341/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2835 - sparse_categorical_accuracy: 0.8828\n",
      "Epoch 341: val_loss did not improve from 0.25908\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2797 - sparse_categorical_accuracy: 0.8876 - val_loss: 0.2594 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 342/10000\n",
      "22/34 [==================>...........] - ETA: 0s - loss: 0.2782 - sparse_categorical_accuracy: 0.8778\n",
      "Epoch 342: val_loss improved from 0.25908 to 0.25890, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2803 - sparse_categorical_accuracy: 0.8858 - val_loss: 0.2589 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 343/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2693 - sparse_categorical_accuracy: 0.8879\n",
      "Epoch 343: val_loss improved from 0.25890 to 0.25809, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2710 - sparse_categorical_accuracy: 0.8858 - val_loss: 0.2581 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 344/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2633 - sparse_categorical_accuracy: 0.8965\n",
      "Epoch 344: val_loss did not improve from 0.25809\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2734 - sparse_categorical_accuracy: 0.8914 - val_loss: 0.2594 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 345/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2617 - sparse_categorical_accuracy: 0.8965\n",
      "Epoch 345: val_loss improved from 0.25809 to 0.25685, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2628 - sparse_categorical_accuracy: 0.8970 - val_loss: 0.2569 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 346/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.2711 - sparse_categorical_accuracy: 0.8996\n",
      "Epoch 346: val_loss did not improve from 0.25685\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2736 - sparse_categorical_accuracy: 0.8989 - val_loss: 0.2570 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 347/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2618 - sparse_categorical_accuracy: 0.8972\n",
      "Epoch 347: val_loss did not improve from 0.25685\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2768 - sparse_categorical_accuracy: 0.8895 - val_loss: 0.2575 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 348/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.2473 - sparse_categorical_accuracy: 0.9022\n",
      "Epoch 348: val_loss did not improve from 0.25685\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2657 - sparse_categorical_accuracy: 0.8858 - val_loss: 0.2571 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 349/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2790 - sparse_categorical_accuracy: 0.8621\n",
      "Epoch 349: val_loss did not improve from 0.25685\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2689 - sparse_categorical_accuracy: 0.8727 - val_loss: 0.2585 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 350/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.2553 - sparse_categorical_accuracy: 0.8958\n",
      "Epoch 350: val_loss improved from 0.25685 to 0.25641, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.2746 - sparse_categorical_accuracy: 0.8858 - val_loss: 0.2564 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 351/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.2766 - sparse_categorical_accuracy: 0.8796\n",
      "Epoch 351: val_loss did not improve from 0.25641\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2744 - sparse_categorical_accuracy: 0.8783 - val_loss: 0.2580 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 352/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2700 - sparse_categorical_accuracy: 0.8914\n",
      "Epoch 352: val_loss did not improve from 0.25641\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2700 - sparse_categorical_accuracy: 0.8914 - val_loss: 0.2579 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 353/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2735 - sparse_categorical_accuracy: 0.8922\n",
      "Epoch 353: val_loss did not improve from 0.25641\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2695 - sparse_categorical_accuracy: 0.8970 - val_loss: 0.2572 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 354/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2863 - sparse_categorical_accuracy: 0.8730\n",
      "Epoch 354: val_loss improved from 0.25641 to 0.25632, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2889 - sparse_categorical_accuracy: 0.8727 - val_loss: 0.2563 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 355/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2675 - sparse_categorical_accuracy: 0.8858\n",
      "Epoch 355: val_loss improved from 0.25632 to 0.25629, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2675 - sparse_categorical_accuracy: 0.8858 - val_loss: 0.2563 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 356/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.2605 - sparse_categorical_accuracy: 0.9015\n",
      "Epoch 356: val_loss improved from 0.25629 to 0.25499, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2635 - sparse_categorical_accuracy: 0.8989 - val_loss: 0.2550 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 357/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2656 - sparse_categorical_accuracy: 0.8848\n",
      "Epoch 357: val_loss improved from 0.25499 to 0.25479, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2644 - sparse_categorical_accuracy: 0.8839 - val_loss: 0.2548 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 358/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.2699 - sparse_categorical_accuracy: 0.8939\n",
      "Epoch 358: val_loss improved from 0.25479 to 0.25400, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2690 - sparse_categorical_accuracy: 0.8951 - val_loss: 0.2540 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 359/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.2644 - sparse_categorical_accuracy: 0.8807\n",
      "Epoch 359: val_loss did not improve from 0.25400\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2650 - sparse_categorical_accuracy: 0.8820 - val_loss: 0.2540 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 360/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.2614 - sparse_categorical_accuracy: 0.8845\n",
      "Epoch 360: val_loss improved from 0.25400 to 0.25336, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2602 - sparse_categorical_accuracy: 0.8858 - val_loss: 0.2534 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 361/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.2800 - sparse_categorical_accuracy: 0.8870\n",
      "Epoch 361: val_loss improved from 0.25336 to 0.25277, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2732 - sparse_categorical_accuracy: 0.8876 - val_loss: 0.2528 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 362/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2769 - sparse_categorical_accuracy: 0.8867\n",
      "Epoch 362: val_loss did not improve from 0.25277\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2755 - sparse_categorical_accuracy: 0.8876 - val_loss: 0.2528 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 363/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.2680 - sparse_categorical_accuracy: 0.8918\n",
      "Epoch 363: val_loss improved from 0.25277 to 0.25239, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2714 - sparse_categorical_accuracy: 0.8858 - val_loss: 0.2524 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 364/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2640 - sparse_categorical_accuracy: 0.8970\n",
      "Epoch 364: val_loss did not improve from 0.25239\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2640 - sparse_categorical_accuracy: 0.8970 - val_loss: 0.2536 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 365/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.2652 - sparse_categorical_accuracy: 0.8883\n",
      "Epoch 365: val_loss did not improve from 0.25239\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2641 - sparse_categorical_accuracy: 0.8895 - val_loss: 0.2536 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 366/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2675 - sparse_categorical_accuracy: 0.8876\n",
      "Epoch 366: val_loss did not improve from 0.25239\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2675 - sparse_categorical_accuracy: 0.8876 - val_loss: 0.2547 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 367/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2628 - sparse_categorical_accuracy: 0.8933\n",
      "Epoch 367: val_loss improved from 0.25239 to 0.25212, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2628 - sparse_categorical_accuracy: 0.8933 - val_loss: 0.2521 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 368/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.2538 - sparse_categorical_accuracy: 0.9085\n",
      "Epoch 368: val_loss improved from 0.25212 to 0.25015, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.2615 - sparse_categorical_accuracy: 0.9007 - val_loss: 0.2501 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 369/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2616 - sparse_categorical_accuracy: 0.8965\n",
      "Epoch 369: val_loss did not improve from 0.25015\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2569 - sparse_categorical_accuracy: 0.8989 - val_loss: 0.2524 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 370/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2512 - sparse_categorical_accuracy: 0.9023\n",
      "Epoch 370: val_loss did not improve from 0.25015\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2596 - sparse_categorical_accuracy: 0.8989 - val_loss: 0.2522 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 371/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2621 - sparse_categorical_accuracy: 0.8891\n",
      "Epoch 371: val_loss did not improve from 0.25015\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2600 - sparse_categorical_accuracy: 0.8933 - val_loss: 0.2522 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 372/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2655 - sparse_categorical_accuracy: 0.9102\n",
      "Epoch 372: val_loss did not improve from 0.25015\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2616 - sparse_categorical_accuracy: 0.9101 - val_loss: 0.2527 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 373/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.2480 - sparse_categorical_accuracy: 0.8967\n",
      "Epoch 373: val_loss improved from 0.25015 to 0.24968, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2589 - sparse_categorical_accuracy: 0.8933 - val_loss: 0.2497 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 374/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2623 - sparse_categorical_accuracy: 0.9121\n",
      "Epoch 374: val_loss did not improve from 0.24968\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2608 - sparse_categorical_accuracy: 0.9101 - val_loss: 0.2507 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 375/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2693 - sparse_categorical_accuracy: 0.8848\n",
      "Epoch 375: val_loss did not improve from 0.24968\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2653 - sparse_categorical_accuracy: 0.8895 - val_loss: 0.2497 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 376/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.2724 - sparse_categorical_accuracy: 0.8845\n",
      "Epoch 376: val_loss did not improve from 0.24968\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2705 - sparse_categorical_accuracy: 0.8858 - val_loss: 0.2515 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 377/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.2487 - sparse_categorical_accuracy: 0.8902\n",
      "Epoch 377: val_loss did not improve from 0.24968\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2483 - sparse_categorical_accuracy: 0.8895 - val_loss: 0.2499 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 378/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.2581 - sparse_categorical_accuracy: 0.8880\n",
      "Epoch 378: val_loss did not improve from 0.24968\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2519 - sparse_categorical_accuracy: 0.8895 - val_loss: 0.2500 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 379/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2506 - sparse_categorical_accuracy: 0.9000\n",
      "Epoch 379: val_loss did not improve from 0.24968\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2572 - sparse_categorical_accuracy: 0.9007 - val_loss: 0.2498 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 380/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2679 - sparse_categorical_accuracy: 0.8917\n",
      "Epoch 380: val_loss did not improve from 0.24968\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2591 - sparse_categorical_accuracy: 0.8970 - val_loss: 0.2512 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 381/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2701 - sparse_categorical_accuracy: 0.8906\n",
      "Epoch 381: val_loss improved from 0.24968 to 0.24963, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2691 - sparse_categorical_accuracy: 0.8914 - val_loss: 0.2496 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 382/10000\n",
      "22/34 [==================>...........] - ETA: 0s - loss: 0.2861 - sparse_categorical_accuracy: 0.8722\n",
      "Epoch 382: val_loss improved from 0.24963 to 0.24864, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2720 - sparse_categorical_accuracy: 0.8820 - val_loss: 0.2486 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 383/10000\n",
      "21/34 [=================>............] - ETA: 0s - loss: 0.2539 - sparse_categorical_accuracy: 0.8869\n",
      "Epoch 383: val_loss improved from 0.24864 to 0.24769, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2629 - sparse_categorical_accuracy: 0.8858 - val_loss: 0.2477 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 384/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.2545 - sparse_categorical_accuracy: 0.9034\n",
      "Epoch 384: val_loss improved from 0.24769 to 0.24560, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2536 - sparse_categorical_accuracy: 0.9045 - val_loss: 0.2456 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 385/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2517 - sparse_categorical_accuracy: 0.8871\n",
      "Epoch 385: val_loss did not improve from 0.24560\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2571 - sparse_categorical_accuracy: 0.8839 - val_loss: 0.2456 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 386/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2668 - sparse_categorical_accuracy: 0.8926\n",
      "Epoch 386: val_loss did not improve from 0.24560\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2617 - sparse_categorical_accuracy: 0.8951 - val_loss: 0.2481 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 387/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.2791 - sparse_categorical_accuracy: 0.8750\n",
      "Epoch 387: val_loss did not improve from 0.24560\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2694 - sparse_categorical_accuracy: 0.8820 - val_loss: 0.2481 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 388/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2729 - sparse_categorical_accuracy: 0.8809\n",
      "Epoch 388: val_loss did not improve from 0.24560\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2676 - sparse_categorical_accuracy: 0.8839 - val_loss: 0.2489 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 389/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2634 - sparse_categorical_accuracy: 0.8926\n",
      "Epoch 389: val_loss did not improve from 0.24560\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2609 - sparse_categorical_accuracy: 0.8933 - val_loss: 0.2486 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 390/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2637 - sparse_categorical_accuracy: 0.8813\n",
      "Epoch 390: val_loss did not improve from 0.24560\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2604 - sparse_categorical_accuracy: 0.8839 - val_loss: 0.2462 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 391/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.2634 - sparse_categorical_accuracy: 0.8995\n",
      "Epoch 391: val_loss did not improve from 0.24560\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2620 - sparse_categorical_accuracy: 0.9007 - val_loss: 0.2473 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 392/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2737 - sparse_categorical_accuracy: 0.8848\n",
      "Epoch 392: val_loss did not improve from 0.24560\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2675 - sparse_categorical_accuracy: 0.8895 - val_loss: 0.2464 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 393/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2485 - sparse_categorical_accuracy: 0.9004\n",
      "Epoch 393: val_loss improved from 0.24560 to 0.24502, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2521 - sparse_categorical_accuracy: 0.8970 - val_loss: 0.2450 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 394/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2671 - sparse_categorical_accuracy: 0.8896\n",
      "Epoch 394: val_loss did not improve from 0.24502\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2678 - sparse_categorical_accuracy: 0.8895 - val_loss: 0.2458 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 395/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2611 - sparse_categorical_accuracy: 0.8917\n",
      "Epoch 395: val_loss did not improve from 0.24502\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2628 - sparse_categorical_accuracy: 0.8876 - val_loss: 0.2469 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 396/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2520 - sparse_categorical_accuracy: 0.8952\n",
      "Epoch 396: val_loss did not improve from 0.24502\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2520 - sparse_categorical_accuracy: 0.8970 - val_loss: 0.2454 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 397/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2595 - sparse_categorical_accuracy: 0.8839\n",
      "Epoch 397: val_loss improved from 0.24502 to 0.24386, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2595 - sparse_categorical_accuracy: 0.8839 - val_loss: 0.2439 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 398/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2651 - sparse_categorical_accuracy: 0.8851\n",
      "Epoch 398: val_loss did not improve from 0.24386\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2599 - sparse_categorical_accuracy: 0.8895 - val_loss: 0.2462 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 399/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.2564 - sparse_categorical_accuracy: 0.8958\n",
      "Epoch 399: val_loss improved from 0.24386 to 0.24366, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 12ms/step - loss: 0.2546 - sparse_categorical_accuracy: 0.8970 - val_loss: 0.2437 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 400/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.2460 - sparse_categorical_accuracy: 0.8883\n",
      "Epoch 400: val_loss improved from 0.24366 to 0.24309, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2461 - sparse_categorical_accuracy: 0.8876 - val_loss: 0.2431 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 401/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.2528 - sparse_categorical_accuracy: 0.9005\n",
      "Epoch 401: val_loss did not improve from 0.24309\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2625 - sparse_categorical_accuracy: 0.8933 - val_loss: 0.2433 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 402/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2609 - sparse_categorical_accuracy: 0.8989\n",
      "Epoch 402: val_loss did not improve from 0.24309\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.2609 - sparse_categorical_accuracy: 0.8989 - val_loss: 0.2468 - val_sparse_categorical_accuracy: 0.8989\n",
      "Epoch 403/10000\n",
      "20/34 [================>.............] - ETA: 0s - loss: 0.2633 - sparse_categorical_accuracy: 0.8969\n",
      "Epoch 403: val_loss improved from 0.24309 to 0.24272, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2658 - sparse_categorical_accuracy: 0.8951 - val_loss: 0.2427 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 404/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.2490 - sparse_categorical_accuracy: 0.8996\n",
      "Epoch 404: val_loss did not improve from 0.24272\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2497 - sparse_categorical_accuracy: 0.9007 - val_loss: 0.2440 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 405/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2629 - sparse_categorical_accuracy: 0.8820\n",
      "Epoch 405: val_loss improved from 0.24272 to 0.24122, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2629 - sparse_categorical_accuracy: 0.8820 - val_loss: 0.2412 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 406/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.2659 - sparse_categorical_accuracy: 0.8906\n",
      "Epoch 406: val_loss improved from 0.24122 to 0.24069, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2676 - sparse_categorical_accuracy: 0.8876 - val_loss: 0.2407 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 407/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2589 - sparse_categorical_accuracy: 0.8854\n",
      "Epoch 407: val_loss did not improve from 0.24069\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2580 - sparse_categorical_accuracy: 0.8876 - val_loss: 0.2409 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 408/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2541 - sparse_categorical_accuracy: 0.8958\n",
      "Epoch 408: val_loss did not improve from 0.24069\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.2526 - sparse_categorical_accuracy: 0.8970 - val_loss: 0.2414 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 409/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.2624 - sparse_categorical_accuracy: 0.8866\n",
      "Epoch 409: val_loss did not improve from 0.24069\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2564 - sparse_categorical_accuracy: 0.8933 - val_loss: 0.2413 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 410/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.2623 - sparse_categorical_accuracy: 0.8920\n",
      "Epoch 410: val_loss did not improve from 0.24069\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2601 - sparse_categorical_accuracy: 0.8933 - val_loss: 0.2417 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 411/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2497 - sparse_categorical_accuracy: 0.8895\n",
      "Epoch 411: val_loss did not improve from 0.24069\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2497 - sparse_categorical_accuracy: 0.8895 - val_loss: 0.2412 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 412/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2494 - sparse_categorical_accuracy: 0.8965\n",
      "Epoch 412: val_loss improved from 0.24069 to 0.23920, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2508 - sparse_categorical_accuracy: 0.8951 - val_loss: 0.2392 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 413/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2586 - sparse_categorical_accuracy: 0.8809\n",
      "Epoch 413: val_loss did not improve from 0.23920\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2563 - sparse_categorical_accuracy: 0.8839 - val_loss: 0.2412 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 414/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2549 - sparse_categorical_accuracy: 0.8848\n",
      "Epoch 414: val_loss did not improve from 0.23920\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2582 - sparse_categorical_accuracy: 0.8858 - val_loss: 0.2408 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 415/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.2521 - sparse_categorical_accuracy: 0.8776\n",
      "Epoch 415: val_loss did not improve from 0.23920\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2538 - sparse_categorical_accuracy: 0.8820 - val_loss: 0.2395 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 416/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2583 - sparse_categorical_accuracy: 0.8839\n",
      "Epoch 416: val_loss did not improve from 0.23920\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2583 - sparse_categorical_accuracy: 0.8839 - val_loss: 0.2418 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 417/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2541 - sparse_categorical_accuracy: 0.9004\n",
      "Epoch 417: val_loss did not improve from 0.23920\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2489 - sparse_categorical_accuracy: 0.9026 - val_loss: 0.2401 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 418/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2398 - sparse_categorical_accuracy: 0.8911\n",
      "Epoch 418: val_loss did not improve from 0.23920\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2510 - sparse_categorical_accuracy: 0.8876 - val_loss: 0.2406 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 419/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.2572 - sparse_categorical_accuracy: 0.8906\n",
      "Epoch 419: val_loss improved from 0.23920 to 0.23677, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2438 - sparse_categorical_accuracy: 0.8970 - val_loss: 0.2368 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 420/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.2506 - sparse_categorical_accuracy: 0.9015\n",
      "Epoch 420: val_loss did not improve from 0.23677\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2483 - sparse_categorical_accuracy: 0.9026 - val_loss: 0.2369 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 421/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.2371 - sparse_categorical_accuracy: 0.8772\n",
      "Epoch 421: val_loss did not improve from 0.23677\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2512 - sparse_categorical_accuracy: 0.8745 - val_loss: 0.2379 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 422/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.2436 - sparse_categorical_accuracy: 0.8920\n",
      "Epoch 422: val_loss did not improve from 0.23677\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2424 - sparse_categorical_accuracy: 0.8933 - val_loss: 0.2375 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 423/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.2496 - sparse_categorical_accuracy: 0.9014\n",
      "Epoch 423: val_loss improved from 0.23677 to 0.23653, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2437 - sparse_categorical_accuracy: 0.9064 - val_loss: 0.2365 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 424/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2231 - sparse_categorical_accuracy: 0.9052\n",
      "Epoch 424: val_loss did not improve from 0.23653\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2360 - sparse_categorical_accuracy: 0.8989 - val_loss: 0.2377 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 425/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.2471 - sparse_categorical_accuracy: 0.9015\n",
      "Epoch 425: val_loss improved from 0.23653 to 0.23566, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2451 - sparse_categorical_accuracy: 0.9026 - val_loss: 0.2357 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 426/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2531 - sparse_categorical_accuracy: 0.8951\n",
      "Epoch 426: val_loss did not improve from 0.23566\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.2531 - sparse_categorical_accuracy: 0.8951 - val_loss: 0.2364 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 427/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.2482 - sparse_categorical_accuracy: 0.8880\n",
      "Epoch 427: val_loss did not improve from 0.23566\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2500 - sparse_categorical_accuracy: 0.8933 - val_loss: 0.2383 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 428/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.2518 - sparse_categorical_accuracy: 0.8883\n",
      "Epoch 428: val_loss did not improve from 0.23566\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2549 - sparse_categorical_accuracy: 0.8858 - val_loss: 0.2360 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 429/10000\n",
      "21/34 [=================>............] - ETA: 0s - loss: 0.2379 - sparse_categorical_accuracy: 0.9018\n",
      "Epoch 429: val_loss did not improve from 0.23566\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2530 - sparse_categorical_accuracy: 0.9007 - val_loss: 0.2358 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 430/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.2048 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 430: val_loss did not improve from 0.23566\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.2430 - sparse_categorical_accuracy: 0.8989 - val_loss: 0.2358 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 431/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1986 - sparse_categorical_accuracy: 0.8993\n",
      "Epoch 431: val_loss did not improve from 0.23566\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.2433 - sparse_categorical_accuracy: 0.8839 - val_loss: 0.2368 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 432/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.2492 - sparse_categorical_accuracy: 0.8950\n",
      "Epoch 432: val_loss improved from 0.23566 to 0.23552, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2474 - sparse_categorical_accuracy: 0.9007 - val_loss: 0.2355 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 433/10000\n",
      "19/34 [===============>..............] - ETA: 0s - loss: 0.2885 - sparse_categorical_accuracy: 0.8717\n",
      "Epoch 433: val_loss did not improve from 0.23552\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.2550 - sparse_categorical_accuracy: 0.8933 - val_loss: 0.2367 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 434/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.2521 - sparse_categorical_accuracy: 0.8785\n",
      "Epoch 434: val_loss improved from 0.23552 to 0.23462, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2519 - sparse_categorical_accuracy: 0.8914 - val_loss: 0.2346 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 435/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.2733 - sparse_categorical_accuracy: 0.8681\n",
      "Epoch 435: val_loss improved from 0.23462 to 0.23366, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2424 - sparse_categorical_accuracy: 0.8951 - val_loss: 0.2337 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 436/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.2457 - sparse_categorical_accuracy: 0.9107\n",
      "Epoch 436: val_loss improved from 0.23366 to 0.23328, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2358 - sparse_categorical_accuracy: 0.9139 - val_loss: 0.2333 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 437/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2400 - sparse_categorical_accuracy: 0.8989\n",
      "Epoch 437: val_loss did not improve from 0.23328\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.2400 - sparse_categorical_accuracy: 0.8989 - val_loss: 0.2345 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 438/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.2301 - sparse_categorical_accuracy: 0.9028\n",
      "Epoch 438: val_loss improved from 0.23328 to 0.23244, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2348 - sparse_categorical_accuracy: 0.9007 - val_loss: 0.2324 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 439/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.2739 - sparse_categorical_accuracy: 0.8750\n",
      "Epoch 439: val_loss did not improve from 0.23244\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.2479 - sparse_categorical_accuracy: 0.8970 - val_loss: 0.2324 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 440/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.2473 - sparse_categorical_accuracy: 0.8993\n",
      "Epoch 440: val_loss improved from 0.23244 to 0.23221, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2459 - sparse_categorical_accuracy: 0.8914 - val_loss: 0.2322 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 441/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.2491 - sparse_categorical_accuracy: 0.8940\n",
      "Epoch 441: val_loss did not improve from 0.23221\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2463 - sparse_categorical_accuracy: 0.8933 - val_loss: 0.2325 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 442/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.2704 - sparse_categorical_accuracy: 0.8924\n",
      "Epoch 442: val_loss did not improve from 0.23221\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.2476 - sparse_categorical_accuracy: 0.8989 - val_loss: 0.2338 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 443/10000\n",
      "17/34 [==============>...............] - ETA: 0s - loss: 0.2321 - sparse_categorical_accuracy: 0.9044\n",
      "Epoch 443: val_loss did not improve from 0.23221\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.2532 - sparse_categorical_accuracy: 0.8895 - val_loss: 0.2329 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 444/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.2298 - sparse_categorical_accuracy: 0.9028\n",
      "Epoch 444: val_loss did not improve from 0.23221\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.2439 - sparse_categorical_accuracy: 0.8970 - val_loss: 0.2324 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 445/10000\n",
      "19/34 [===============>..............] - ETA: 0s - loss: 0.2596 - sparse_categorical_accuracy: 0.8783\n",
      "Epoch 445: val_loss improved from 0.23221 to 0.23181, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2423 - sparse_categorical_accuracy: 0.8989 - val_loss: 0.2318 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 446/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2492 - sparse_categorical_accuracy: 0.9138\n",
      "Epoch 446: val_loss improved from 0.23181 to 0.23035, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.2490 - sparse_categorical_accuracy: 0.9026 - val_loss: 0.2303 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 447/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.2350 - sparse_categorical_accuracy: 0.9005\n",
      "Epoch 447: val_loss did not improve from 0.23035\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2524 - sparse_categorical_accuracy: 0.8914 - val_loss: 0.2304 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 448/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2409 - sparse_categorical_accuracy: 0.9004\n",
      "Epoch 448: val_loss did not improve from 0.23035\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2391 - sparse_categorical_accuracy: 0.9007 - val_loss: 0.2306 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 449/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2256 - sparse_categorical_accuracy: 0.9052\n",
      "Epoch 449: val_loss improved from 0.23035 to 0.23006, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2390 - sparse_categorical_accuracy: 0.8989 - val_loss: 0.2301 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 450/10000\n",
      "21/34 [=================>............] - ETA: 0s - loss: 0.2236 - sparse_categorical_accuracy: 0.9077\n",
      "Epoch 450: val_loss did not improve from 0.23006\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2377 - sparse_categorical_accuracy: 0.8970 - val_loss: 0.2307 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 451/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2392 - sparse_categorical_accuracy: 0.9023\n",
      "Epoch 451: val_loss did not improve from 0.23006\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2411 - sparse_categorical_accuracy: 0.9026 - val_loss: 0.2317 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 452/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.2440 - sparse_categorical_accuracy: 0.8939\n",
      "Epoch 452: val_loss improved from 0.23006 to 0.22862, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2439 - sparse_categorical_accuracy: 0.8951 - val_loss: 0.2286 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 453/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2412 - sparse_categorical_accuracy: 0.9141\n",
      "Epoch 453: val_loss improved from 0.22862 to 0.22799, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2434 - sparse_categorical_accuracy: 0.9101 - val_loss: 0.2280 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 454/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.2377 - sparse_categorical_accuracy: 0.9062\n",
      "Epoch 454: val_loss did not improve from 0.22799\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2423 - sparse_categorical_accuracy: 0.8970 - val_loss: 0.2282 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 455/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2430 - sparse_categorical_accuracy: 0.9032\n",
      "Epoch 455: val_loss did not improve from 0.22799\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2417 - sparse_categorical_accuracy: 0.9045 - val_loss: 0.2288 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 456/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2619 - sparse_categorical_accuracy: 0.8911\n",
      "Epoch 456: val_loss improved from 0.22799 to 0.22669, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2522 - sparse_categorical_accuracy: 0.8970 - val_loss: 0.2267 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 457/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.2458 - sparse_categorical_accuracy: 0.8883\n",
      "Epoch 457: val_loss did not improve from 0.22669\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.2434 - sparse_categorical_accuracy: 0.8895 - val_loss: 0.2278 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 458/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2419 - sparse_categorical_accuracy: 0.9082\n",
      "Epoch 458: val_loss did not improve from 0.22669\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2419 - sparse_categorical_accuracy: 0.9082 - val_loss: 0.2291 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 459/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2459 - sparse_categorical_accuracy: 0.9009\n",
      "Epoch 459: val_loss did not improve from 0.22669\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2512 - sparse_categorical_accuracy: 0.8970 - val_loss: 0.2285 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 460/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2468 - sparse_categorical_accuracy: 0.8911\n",
      "Epoch 460: val_loss did not improve from 0.22669\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2393 - sparse_categorical_accuracy: 0.8951 - val_loss: 0.2276 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 461/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.2454 - sparse_categorical_accuracy: 0.8942\n",
      "Epoch 461: val_loss improved from 0.22669 to 0.22665, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2434 - sparse_categorical_accuracy: 0.8951 - val_loss: 0.2267 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 462/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2436 - sparse_categorical_accuracy: 0.8933\n",
      "Epoch 462: val_loss did not improve from 0.22665\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2436 - sparse_categorical_accuracy: 0.8933 - val_loss: 0.2277 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 463/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2464 - sparse_categorical_accuracy: 0.8944\n",
      "Epoch 463: val_loss did not improve from 0.22665\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2363 - sparse_categorical_accuracy: 0.9007 - val_loss: 0.2278 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 464/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2402 - sparse_categorical_accuracy: 0.9073\n",
      "Epoch 464: val_loss did not improve from 0.22665\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2376 - sparse_categorical_accuracy: 0.9101 - val_loss: 0.2277 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 465/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2231 - sparse_categorical_accuracy: 0.9120\n",
      "Epoch 465: val_loss improved from 0.22665 to 0.22579, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2231 - sparse_categorical_accuracy: 0.9120 - val_loss: 0.2258 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 466/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2329 - sparse_categorical_accuracy: 0.9159\n",
      "Epoch 466: val_loss improved from 0.22579 to 0.22562, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.2403 - sparse_categorical_accuracy: 0.9082 - val_loss: 0.2256 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 467/10000\n",
      "22/34 [==================>...........] - ETA: 0s - loss: 0.2495 - sparse_categorical_accuracy: 0.8977\n",
      "Epoch 467: val_loss improved from 0.22562 to 0.22546, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2473 - sparse_categorical_accuracy: 0.8970 - val_loss: 0.2255 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 468/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.2349 - sparse_categorical_accuracy: 0.9159\n",
      "Epoch 468: val_loss improved from 0.22546 to 0.22526, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2369 - sparse_categorical_accuracy: 0.9045 - val_loss: 0.2253 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 469/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2292 - sparse_categorical_accuracy: 0.9093\n",
      "Epoch 469: val_loss improved from 0.22526 to 0.22461, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2271 - sparse_categorical_accuracy: 0.9120 - val_loss: 0.2246 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 470/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2360 - sparse_categorical_accuracy: 0.9083\n",
      "Epoch 470: val_loss did not improve from 0.22461\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2391 - sparse_categorical_accuracy: 0.9064 - val_loss: 0.2258 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 471/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2446 - sparse_categorical_accuracy: 0.8965\n",
      "Epoch 471: val_loss did not improve from 0.22461\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2402 - sparse_categorical_accuracy: 0.8989 - val_loss: 0.2252 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 472/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.2363 - sparse_categorical_accuracy: 0.9000\n",
      "Epoch 472: val_loss did not improve from 0.22461\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2256 - sparse_categorical_accuracy: 0.9026 - val_loss: 0.2265 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 473/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.2237 - sparse_categorical_accuracy: 0.9125\n",
      "Epoch 473: val_loss improved from 0.22461 to 0.22403, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.2296 - sparse_categorical_accuracy: 0.9101 - val_loss: 0.2240 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 474/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2386 - sparse_categorical_accuracy: 0.8965\n",
      "Epoch 474: val_loss improved from 0.22403 to 0.22327, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2417 - sparse_categorical_accuracy: 0.8951 - val_loss: 0.2233 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 475/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.2459 - sparse_categorical_accuracy: 0.9050\n",
      "Epoch 475: val_loss did not improve from 0.22327\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2335 - sparse_categorical_accuracy: 0.9139 - val_loss: 0.2241 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 476/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.2348 - sparse_categorical_accuracy: 0.9125\n",
      "Epoch 476: val_loss did not improve from 0.22327\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.2418 - sparse_categorical_accuracy: 0.9007 - val_loss: 0.2242 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 477/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2319 - sparse_categorical_accuracy: 0.8922\n",
      "Epoch 477: val_loss did not improve from 0.22327\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2301 - sparse_categorical_accuracy: 0.8933 - val_loss: 0.2242 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 478/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2388 - sparse_categorical_accuracy: 0.8854\n",
      "Epoch 478: val_loss did not improve from 0.22327\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2397 - sparse_categorical_accuracy: 0.8895 - val_loss: 0.2233 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 479/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2367 - sparse_categorical_accuracy: 0.9141\n",
      "Epoch 479: val_loss improved from 0.22327 to 0.22307, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2393 - sparse_categorical_accuracy: 0.9101 - val_loss: 0.2231 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 480/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.2330 - sparse_categorical_accuracy: 0.9097\n",
      "Epoch 480: val_loss did not improve from 0.22307\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.2337 - sparse_categorical_accuracy: 0.8989 - val_loss: 0.2258 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 481/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.2401 - sparse_categorical_accuracy: 0.9028\n",
      "Epoch 481: val_loss improved from 0.22307 to 0.22191, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2345 - sparse_categorical_accuracy: 0.9045 - val_loss: 0.2219 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 482/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.2239 - sparse_categorical_accuracy: 0.9053\n",
      "Epoch 482: val_loss did not improve from 0.22191\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2240 - sparse_categorical_accuracy: 0.9064 - val_loss: 0.2261 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 483/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.2497 - sparse_categorical_accuracy: 0.9062\n",
      "Epoch 483: val_loss did not improve from 0.22191\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.2435 - sparse_categorical_accuracy: 0.9026 - val_loss: 0.2230 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 484/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.2508 - sparse_categorical_accuracy: 0.8866\n",
      "Epoch 484: val_loss did not improve from 0.22191\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2527 - sparse_categorical_accuracy: 0.8858 - val_loss: 0.2225 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 485/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2359 - sparse_categorical_accuracy: 0.9032\n",
      "Epoch 485: val_loss improved from 0.22191 to 0.22174, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2332 - sparse_categorical_accuracy: 0.9026 - val_loss: 0.2217 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 486/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2273 - sparse_categorical_accuracy: 0.9042\n",
      "Epoch 486: val_loss did not improve from 0.22174\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2292 - sparse_categorical_accuracy: 0.9026 - val_loss: 0.2221 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 487/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2028 - sparse_categorical_accuracy: 0.9203\n",
      "Epoch 487: val_loss did not improve from 0.22174\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2117 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.2237 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 488/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2286 - sparse_categorical_accuracy: 0.9073\n",
      "Epoch 488: val_loss did not improve from 0.22174\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2239 - sparse_categorical_accuracy: 0.9101 - val_loss: 0.2228 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 489/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2416 - sparse_categorical_accuracy: 0.9042\n",
      "Epoch 489: val_loss improved from 0.22174 to 0.22165, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2371 - sparse_categorical_accuracy: 0.9026 - val_loss: 0.2217 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 490/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.2446 - sparse_categorical_accuracy: 0.8918\n",
      "Epoch 490: val_loss improved from 0.22165 to 0.22128, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 15ms/step - loss: 0.2344 - sparse_categorical_accuracy: 0.9007 - val_loss: 0.2213 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 491/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.2578 - sparse_categorical_accuracy: 0.8900\n",
      "Epoch 491: val_loss improved from 0.22128 to 0.21939, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2374 - sparse_categorical_accuracy: 0.9007 - val_loss: 0.2194 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 492/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2183 - sparse_categorical_accuracy: 0.9146\n",
      "Epoch 492: val_loss did not improve from 0.21939\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2231 - sparse_categorical_accuracy: 0.9101 - val_loss: 0.2209 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 493/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2288 - sparse_categorical_accuracy: 0.9021\n",
      "Epoch 493: val_loss did not improve from 0.21939\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2317 - sparse_categorical_accuracy: 0.9045 - val_loss: 0.2215 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 494/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2270 - sparse_categorical_accuracy: 0.9073\n",
      "Epoch 494: val_loss improved from 0.21939 to 0.21821, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2235 - sparse_categorical_accuracy: 0.9082 - val_loss: 0.2182 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 495/10000\n",
      "20/34 [================>.............] - ETA: 0s - loss: 0.2370 - sparse_categorical_accuracy: 0.8906\n",
      "Epoch 495: val_loss did not improve from 0.21821\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2347 - sparse_categorical_accuracy: 0.8933 - val_loss: 0.2198 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 496/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2379 - sparse_categorical_accuracy: 0.8972\n",
      "Epoch 496: val_loss did not improve from 0.21821\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2321 - sparse_categorical_accuracy: 0.9007 - val_loss: 0.2187 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 497/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2305 - sparse_categorical_accuracy: 0.8966\n",
      "Epoch 497: val_loss improved from 0.21821 to 0.21796, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2389 - sparse_categorical_accuracy: 0.8933 - val_loss: 0.2180 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 498/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.2249 - sparse_categorical_accuracy: 0.9152\n",
      "Epoch 498: val_loss did not improve from 0.21796\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2192 - sparse_categorical_accuracy: 0.9139 - val_loss: 0.2192 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 499/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2220 - sparse_categorical_accuracy: 0.9125\n",
      "Epoch 499: val_loss did not improve from 0.21796\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2243 - sparse_categorical_accuracy: 0.9139 - val_loss: 0.2202 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 500/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.2008 - sparse_categorical_accuracy: 0.9327\n",
      "Epoch 500: val_loss did not improve from 0.21796\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2200 - sparse_categorical_accuracy: 0.9232 - val_loss: 0.2184 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 501/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2278 - sparse_categorical_accuracy: 0.9012\n",
      "Epoch 501: val_loss did not improve from 0.21796\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2327 - sparse_categorical_accuracy: 0.8970 - val_loss: 0.2195 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 502/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.2375 - sparse_categorical_accuracy: 0.9018\n",
      "Epoch 502: val_loss improved from 0.21796 to 0.21640, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2379 - sparse_categorical_accuracy: 0.9045 - val_loss: 0.2164 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 503/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2352 - sparse_categorical_accuracy: 0.9043\n",
      "Epoch 503: val_loss did not improve from 0.21640\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2344 - sparse_categorical_accuracy: 0.9045 - val_loss: 0.2168 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 504/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2243 - sparse_categorical_accuracy: 0.9073\n",
      "Epoch 504: val_loss did not improve from 0.21640\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2235 - sparse_categorical_accuracy: 0.9082 - val_loss: 0.2167 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 505/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2310 - sparse_categorical_accuracy: 0.9012\n",
      "Epoch 505: val_loss did not improve from 0.21640\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2326 - sparse_categorical_accuracy: 0.9026 - val_loss: 0.2170 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 506/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.2250 - sparse_categorical_accuracy: 0.9144\n",
      "Epoch 506: val_loss improved from 0.21640 to 0.21550, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2351 - sparse_categorical_accuracy: 0.9120 - val_loss: 0.2155 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 507/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2168 - sparse_categorical_accuracy: 0.9104\n",
      "Epoch 507: val_loss improved from 0.21550 to 0.21524, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2175 - sparse_categorical_accuracy: 0.9082 - val_loss: 0.2152 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 508/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.2257 - sparse_categorical_accuracy: 0.8973\n",
      "Epoch 508: val_loss did not improve from 0.21524\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2231 - sparse_categorical_accuracy: 0.9007 - val_loss: 0.2163 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 509/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.2125 - sparse_categorical_accuracy: 0.9144\n",
      "Epoch 509: val_loss improved from 0.21524 to 0.21488, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2158 - sparse_categorical_accuracy: 0.9120 - val_loss: 0.2149 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 510/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2272 - sparse_categorical_accuracy: 0.9095\n",
      "Epoch 510: val_loss did not improve from 0.21488\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2386 - sparse_categorical_accuracy: 0.9045 - val_loss: 0.2161 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 511/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2259 - sparse_categorical_accuracy: 0.8966\n",
      "Epoch 511: val_loss did not improve from 0.21488\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2228 - sparse_categorical_accuracy: 0.8970 - val_loss: 0.2151 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 512/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.2257 - sparse_categorical_accuracy: 0.8996\n",
      "Epoch 512: val_loss did not improve from 0.21488\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2245 - sparse_categorical_accuracy: 0.8989 - val_loss: 0.2151 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 513/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2291 - sparse_categorical_accuracy: 0.9146\n",
      "Epoch 513: val_loss improved from 0.21488 to 0.21443, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2243 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.2144 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 514/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2235 - sparse_categorical_accuracy: 0.9073\n",
      "Epoch 514: val_loss did not improve from 0.21443\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2270 - sparse_categorical_accuracy: 0.9082 - val_loss: 0.2168 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 515/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.2189 - sparse_categorical_accuracy: 0.8935\n",
      "Epoch 515: val_loss improved from 0.21443 to 0.21418, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2194 - sparse_categorical_accuracy: 0.9007 - val_loss: 0.2142 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 516/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2250 - sparse_categorical_accuracy: 0.9194\n",
      "Epoch 516: val_loss improved from 0.21418 to 0.21373, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2252 - sparse_categorical_accuracy: 0.9213 - val_loss: 0.2137 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 517/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.2145 - sparse_categorical_accuracy: 0.9129\n",
      "Epoch 517: val_loss did not improve from 0.21373\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2216 - sparse_categorical_accuracy: 0.9082 - val_loss: 0.2146 - val_sparse_categorical_accuracy: 0.9213\n",
      "Epoch 518/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2355 - sparse_categorical_accuracy: 0.8965\n",
      "Epoch 518: val_loss did not improve from 0.21373\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2387 - sparse_categorical_accuracy: 0.8951 - val_loss: 0.2153 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 519/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2274 - sparse_categorical_accuracy: 0.8906\n",
      "Epoch 519: val_loss did not improve from 0.21373\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2233 - sparse_categorical_accuracy: 0.8951 - val_loss: 0.2149 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 520/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.2236 - sparse_categorical_accuracy: 0.9129\n",
      "Epoch 520: val_loss improved from 0.21373 to 0.21096, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2150 - sparse_categorical_accuracy: 0.9157 - val_loss: 0.2110 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 521/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.2329 - sparse_categorical_accuracy: 0.9135\n",
      "Epoch 521: val_loss did not improve from 0.21096\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2270 - sparse_categorical_accuracy: 0.9139 - val_loss: 0.2116 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 522/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2271 - sparse_categorical_accuracy: 0.8992\n",
      "Epoch 522: val_loss did not improve from 0.21096\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2236 - sparse_categorical_accuracy: 0.9007 - val_loss: 0.2125 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 523/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2165 - sparse_categorical_accuracy: 0.9214\n",
      "Epoch 523: val_loss did not improve from 0.21096\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2121 - sparse_categorical_accuracy: 0.9232 - val_loss: 0.2122 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 524/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2163 - sparse_categorical_accuracy: 0.9064\n",
      "Epoch 524: val_loss improved from 0.21096 to 0.21022, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.2163 - sparse_categorical_accuracy: 0.9064 - val_loss: 0.2102 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 525/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2180 - sparse_categorical_accuracy: 0.9083\n",
      "Epoch 525: val_loss improved from 0.21022 to 0.20983, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2251 - sparse_categorical_accuracy: 0.9064 - val_loss: 0.2098 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 526/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2126 - sparse_categorical_accuracy: 0.9173\n",
      "Epoch 526: val_loss improved from 0.20983 to 0.20963, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2192 - sparse_categorical_accuracy: 0.9139 - val_loss: 0.2096 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 527/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2152 - sparse_categorical_accuracy: 0.9062\n",
      "Epoch 527: val_loss did not improve from 0.20963\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2134 - sparse_categorical_accuracy: 0.9101 - val_loss: 0.2101 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 528/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.2424 - sparse_categorical_accuracy: 0.9040\n",
      "Epoch 528: val_loss did not improve from 0.20963\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2372 - sparse_categorical_accuracy: 0.9064 - val_loss: 0.2112 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 529/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.2261 - sparse_categorical_accuracy: 0.9089\n",
      "Epoch 529: val_loss did not improve from 0.20963\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2182 - sparse_categorical_accuracy: 0.9120 - val_loss: 0.2099 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 530/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2094 - sparse_categorical_accuracy: 0.9153\n",
      "Epoch 530: val_loss did not improve from 0.20963\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2070 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.2120 - val_sparse_categorical_accuracy: 0.9213\n",
      "Epoch 531/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2151 - sparse_categorical_accuracy: 0.8987\n",
      "Epoch 531: val_loss improved from 0.20963 to 0.20828, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2224 - sparse_categorical_accuracy: 0.8895 - val_loss: 0.2083 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 532/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.2326 - sparse_categorical_accuracy: 0.9062\n",
      "Epoch 532: val_loss improved from 0.20828 to 0.20768, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2206 - sparse_categorical_accuracy: 0.9157 - val_loss: 0.2077 - val_sparse_categorical_accuracy: 0.9213\n",
      "Epoch 533/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.2244 - sparse_categorical_accuracy: 0.9089\n",
      "Epoch 533: val_loss did not improve from 0.20768\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2118 - sparse_categorical_accuracy: 0.9139 - val_loss: 0.2084 - val_sparse_categorical_accuracy: 0.9045\n",
      "Epoch 534/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2265 - sparse_categorical_accuracy: 0.9021\n",
      "Epoch 534: val_loss did not improve from 0.20768\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2217 - sparse_categorical_accuracy: 0.9007 - val_loss: 0.2099 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 535/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.2171 - sparse_categorical_accuracy: 0.9159\n",
      "Epoch 535: val_loss did not improve from 0.20768\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2153 - sparse_categorical_accuracy: 0.9120 - val_loss: 0.2112 - val_sparse_categorical_accuracy: 0.9213\n",
      "Epoch 536/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2129 - sparse_categorical_accuracy: 0.9214\n",
      "Epoch 536: val_loss improved from 0.20768 to 0.20736, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2093 - sparse_categorical_accuracy: 0.9232 - val_loss: 0.2074 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 537/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.2138 - sparse_categorical_accuracy: 0.9148\n",
      "Epoch 537: val_loss improved from 0.20736 to 0.20696, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2118 - sparse_categorical_accuracy: 0.9157 - val_loss: 0.2070 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 538/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2233 - sparse_categorical_accuracy: 0.9073\n",
      "Epoch 538: val_loss did not improve from 0.20696\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2246 - sparse_categorical_accuracy: 0.9082 - val_loss: 0.2098 - val_sparse_categorical_accuracy: 0.9213\n",
      "Epoch 539/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2032 - sparse_categorical_accuracy: 0.9021\n",
      "Epoch 539: val_loss did not improve from 0.20696\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2052 - sparse_categorical_accuracy: 0.8989 - val_loss: 0.2097 - val_sparse_categorical_accuracy: 0.9213\n",
      "Epoch 540/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.2095 - sparse_categorical_accuracy: 0.9125\n",
      "Epoch 540: val_loss improved from 0.20696 to 0.20654, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2049 - sparse_categorical_accuracy: 0.9195 - val_loss: 0.2065 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 541/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2271 - sparse_categorical_accuracy: 0.9073\n",
      "Epoch 541: val_loss improved from 0.20654 to 0.20547, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2244 - sparse_categorical_accuracy: 0.9082 - val_loss: 0.2055 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 542/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.2190 - sparse_categorical_accuracy: 0.9085\n",
      "Epoch 542: val_loss did not improve from 0.20547\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2178 - sparse_categorical_accuracy: 0.9101 - val_loss: 0.2071 - val_sparse_categorical_accuracy: 0.9213\n",
      "Epoch 543/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2108 - sparse_categorical_accuracy: 0.9042\n",
      "Epoch 543: val_loss did not improve from 0.20547\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2107 - sparse_categorical_accuracy: 0.9045 - val_loss: 0.2057 - val_sparse_categorical_accuracy: 0.9101\n",
      "Epoch 544/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2178 - sparse_categorical_accuracy: 0.9062\n",
      "Epoch 544: val_loss did not improve from 0.20547\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2159 - sparse_categorical_accuracy: 0.9064 - val_loss: 0.2070 - val_sparse_categorical_accuracy: 0.9213\n",
      "Epoch 545/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2186 - sparse_categorical_accuracy: 0.9208\n",
      "Epoch 545: val_loss improved from 0.20547 to 0.20510, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2168 - sparse_categorical_accuracy: 0.9213 - val_loss: 0.2051 - val_sparse_categorical_accuracy: 0.9213\n",
      "Epoch 546/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2376 - sparse_categorical_accuracy: 0.8966\n",
      "Epoch 546: val_loss did not improve from 0.20510\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2240 - sparse_categorical_accuracy: 0.9064 - val_loss: 0.2060 - val_sparse_categorical_accuracy: 0.9213\n",
      "Epoch 547/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2176 - sparse_categorical_accuracy: 0.9021\n",
      "Epoch 547: val_loss improved from 0.20510 to 0.20386, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2198 - sparse_categorical_accuracy: 0.9026 - val_loss: 0.2039 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 548/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.2152 - sparse_categorical_accuracy: 0.9062\n",
      "Epoch 548: val_loss improved from 0.20386 to 0.20312, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2106 - sparse_categorical_accuracy: 0.9101 - val_loss: 0.2031 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 549/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2093 - sparse_categorical_accuracy: 0.9187\n",
      "Epoch 549: val_loss did not improve from 0.20312\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2082 - sparse_categorical_accuracy: 0.9157 - val_loss: 0.2033 - val_sparse_categorical_accuracy: 0.9213\n",
      "Epoch 550/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2096 - sparse_categorical_accuracy: 0.9214\n",
      "Epoch 550: val_loss did not improve from 0.20312\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2229 - sparse_categorical_accuracy: 0.9139 - val_loss: 0.2079 - val_sparse_categorical_accuracy: 0.9213\n",
      "Epoch 551/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2120 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 551: val_loss improved from 0.20312 to 0.20245, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2102 - sparse_categorical_accuracy: 0.9270 - val_loss: 0.2025 - val_sparse_categorical_accuracy: 0.9270\n",
      "Epoch 552/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1997 - sparse_categorical_accuracy: 0.9199\n",
      "Epoch 552: val_loss did not improve from 0.20245\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2013 - sparse_categorical_accuracy: 0.9195 - val_loss: 0.2035 - val_sparse_categorical_accuracy: 0.9213\n",
      "Epoch 553/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2065 - sparse_categorical_accuracy: 0.9073\n",
      "Epoch 553: val_loss improved from 0.20245 to 0.20203, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2034 - sparse_categorical_accuracy: 0.9120 - val_loss: 0.2020 - val_sparse_categorical_accuracy: 0.9213\n",
      "Epoch 554/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2116 - sparse_categorical_accuracy: 0.9146\n",
      "Epoch 554: val_loss did not improve from 0.20203\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2077 - sparse_categorical_accuracy: 0.9157 - val_loss: 0.2038 - val_sparse_categorical_accuracy: 0.9213\n",
      "Epoch 555/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.2039 - sparse_categorical_accuracy: 0.9271\n",
      "Epoch 555: val_loss improved from 0.20203 to 0.20123, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2082 - sparse_categorical_accuracy: 0.9195 - val_loss: 0.2012 - val_sparse_categorical_accuracy: 0.9213\n",
      "Epoch 556/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2207 - sparse_categorical_accuracy: 0.9052\n",
      "Epoch 556: val_loss did not improve from 0.20123\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2108 - sparse_categorical_accuracy: 0.9101 - val_loss: 0.2027 - val_sparse_categorical_accuracy: 0.9270\n",
      "Epoch 557/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2152 - sparse_categorical_accuracy: 0.9153\n",
      "Epoch 557: val_loss did not improve from 0.20123\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2182 - sparse_categorical_accuracy: 0.9120 - val_loss: 0.2025 - val_sparse_categorical_accuracy: 0.9213\n",
      "Epoch 558/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2036 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 558: val_loss did not improve from 0.20123\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2079 - sparse_categorical_accuracy: 0.9082 - val_loss: 0.2016 - val_sparse_categorical_accuracy: 0.9270\n",
      "Epoch 559/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2246 - sparse_categorical_accuracy: 0.9012\n",
      "Epoch 559: val_loss improved from 0.20123 to 0.20006, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2244 - sparse_categorical_accuracy: 0.9007 - val_loss: 0.2001 - val_sparse_categorical_accuracy: 0.9270\n",
      "Epoch 560/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2055 - sparse_categorical_accuracy: 0.9173\n",
      "Epoch 560: val_loss did not improve from 0.20006\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2015 - sparse_categorical_accuracy: 0.9195 - val_loss: 0.2010 - val_sparse_categorical_accuracy: 0.9270\n",
      "Epoch 561/10000\n",
      "22/34 [==================>...........] - ETA: 0s - loss: 0.2063 - sparse_categorical_accuracy: 0.9062\n",
      "Epoch 561: val_loss did not improve from 0.20006\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2106 - sparse_categorical_accuracy: 0.9064 - val_loss: 0.2009 - val_sparse_categorical_accuracy: 0.9270\n",
      "Epoch 562/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.2135 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 562: val_loss did not improve from 0.20006\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2163 - sparse_categorical_accuracy: 0.9139 - val_loss: 0.2005 - val_sparse_categorical_accuracy: 0.9213\n",
      "Epoch 563/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2154 - sparse_categorical_accuracy: 0.9125\n",
      "Epoch 563: val_loss did not improve from 0.20006\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2156 - sparse_categorical_accuracy: 0.9120 - val_loss: 0.2002 - val_sparse_categorical_accuracy: 0.9326\n",
      "Epoch 564/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2244 - sparse_categorical_accuracy: 0.9073\n",
      "Epoch 564: val_loss did not improve from 0.20006\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2187 - sparse_categorical_accuracy: 0.9120 - val_loss: 0.2013 - val_sparse_categorical_accuracy: 0.9270\n",
      "Epoch 565/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2089 - sparse_categorical_accuracy: 0.9292\n",
      "Epoch 565: val_loss improved from 0.20006 to 0.19991, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2012 - sparse_categorical_accuracy: 0.9326 - val_loss: 0.1999 - val_sparse_categorical_accuracy: 0.9270\n",
      "Epoch 566/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2209 - sparse_categorical_accuracy: 0.9052\n",
      "Epoch 566: val_loss did not improve from 0.19991\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2134 - sparse_categorical_accuracy: 0.9101 - val_loss: 0.2003 - val_sparse_categorical_accuracy: 0.9270\n",
      "Epoch 567/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2014 - sparse_categorical_accuracy: 0.9224\n",
      "Epoch 567: val_loss improved from 0.19991 to 0.19929, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2162 - sparse_categorical_accuracy: 0.9101 - val_loss: 0.1993 - val_sparse_categorical_accuracy: 0.9270\n",
      "Epoch 568/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2140 - sparse_categorical_accuracy: 0.9113\n",
      "Epoch 568: val_loss did not improve from 0.19929\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2070 - sparse_categorical_accuracy: 0.9139 - val_loss: 0.2017 - val_sparse_categorical_accuracy: 0.9326\n",
      "Epoch 569/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2149 - sparse_categorical_accuracy: 0.9116\n",
      "Epoch 569: val_loss improved from 0.19929 to 0.19788, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2132 - sparse_categorical_accuracy: 0.9139 - val_loss: 0.1979 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 570/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2022 - sparse_categorical_accuracy: 0.9125\n",
      "Epoch 570: val_loss did not improve from 0.19788\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2010 - sparse_categorical_accuracy: 0.9157 - val_loss: 0.2020 - val_sparse_categorical_accuracy: 0.9326\n",
      "Epoch 571/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2033 - sparse_categorical_accuracy: 0.9113\n",
      "Epoch 571: val_loss did not improve from 0.19788\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2045 - sparse_categorical_accuracy: 0.9120 - val_loss: 0.1980 - val_sparse_categorical_accuracy: 0.9270\n",
      "Epoch 572/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2201 - sparse_categorical_accuracy: 0.8987\n",
      "Epoch 572: val_loss did not improve from 0.19788\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2213 - sparse_categorical_accuracy: 0.9026 - val_loss: 0.1981 - val_sparse_categorical_accuracy: 0.9326\n",
      "Epoch 573/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2308 - sparse_categorical_accuracy: 0.8951\n",
      "Epoch 573: val_loss improved from 0.19788 to 0.19739, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2308 - sparse_categorical_accuracy: 0.8951 - val_loss: 0.1974 - val_sparse_categorical_accuracy: 0.9270\n",
      "Epoch 574/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2067 - sparse_categorical_accuracy: 0.9116\n",
      "Epoch 574: val_loss improved from 0.19739 to 0.19726, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 1s 19ms/step - loss: 0.2021 - sparse_categorical_accuracy: 0.9139 - val_loss: 0.1973 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 575/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.2155 - sparse_categorical_accuracy: 0.9120\n",
      "Epoch 575: val_loss did not improve from 0.19726\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2068 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.1983 - val_sparse_categorical_accuracy: 0.9326\n",
      "Epoch 576/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1899 - sparse_categorical_accuracy: 0.9229\n",
      "Epoch 576: val_loss improved from 0.19726 to 0.19712, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1975 - sparse_categorical_accuracy: 0.9120 - val_loss: 0.1971 - val_sparse_categorical_accuracy: 0.9326\n",
      "Epoch 577/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2067 - sparse_categorical_accuracy: 0.9181\n",
      "Epoch 577: val_loss did not improve from 0.19712\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2071 - sparse_categorical_accuracy: 0.9157 - val_loss: 0.1998 - val_sparse_categorical_accuracy: 0.9326\n",
      "Epoch 578/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2186 - sparse_categorical_accuracy: 0.9157\n",
      "Epoch 578: val_loss improved from 0.19712 to 0.19448, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.2186 - sparse_categorical_accuracy: 0.9157 - val_loss: 0.1945 - val_sparse_categorical_accuracy: 0.9270\n",
      "Epoch 579/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.2005 - sparse_categorical_accuracy: 0.9159\n",
      "Epoch 579: val_loss did not improve from 0.19448\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2106 - sparse_categorical_accuracy: 0.9064 - val_loss: 0.1965 - val_sparse_categorical_accuracy: 0.9326\n",
      "Epoch 580/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1909 - sparse_categorical_accuracy: 0.9292\n",
      "Epoch 580: val_loss improved from 0.19448 to 0.19375, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1982 - sparse_categorical_accuracy: 0.9232 - val_loss: 0.1938 - val_sparse_categorical_accuracy: 0.9326\n",
      "Epoch 581/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2067 - sparse_categorical_accuracy: 0.9141\n",
      "Epoch 581: val_loss did not improve from 0.19375\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2028 - sparse_categorical_accuracy: 0.9157 - val_loss: 0.1941 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 582/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.2083 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 582: val_loss improved from 0.19375 to 0.19252, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.2104 - sparse_categorical_accuracy: 0.9157 - val_loss: 0.1925 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 583/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1980 - sparse_categorical_accuracy: 0.9116\n",
      "Epoch 583: val_loss did not improve from 0.19252\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1999 - sparse_categorical_accuracy: 0.9157 - val_loss: 0.1949 - val_sparse_categorical_accuracy: 0.9326\n",
      "Epoch 584/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2187 - sparse_categorical_accuracy: 0.9062\n",
      "Epoch 584: val_loss did not improve from 0.19252\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2062 - sparse_categorical_accuracy: 0.9139 - val_loss: 0.1940 - val_sparse_categorical_accuracy: 0.9326\n",
      "Epoch 585/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1886 - sparse_categorical_accuracy: 0.9330\n",
      "Epoch 585: val_loss did not improve from 0.19252\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1992 - sparse_categorical_accuracy: 0.9288 - val_loss: 0.1933 - val_sparse_categorical_accuracy: 0.9326\n",
      "Epoch 586/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2083 - sparse_categorical_accuracy: 0.9159\n",
      "Epoch 586: val_loss did not improve from 0.19252\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2221 - sparse_categorical_accuracy: 0.9064 - val_loss: 0.1951 - val_sparse_categorical_accuracy: 0.9326\n",
      "Epoch 587/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2111 - sparse_categorical_accuracy: 0.9073\n",
      "Epoch 587: val_loss did not improve from 0.19252\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2025 - sparse_categorical_accuracy: 0.9101 - val_loss: 0.1931 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 588/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2010 - sparse_categorical_accuracy: 0.9194\n",
      "Epoch 588: val_loss did not improve from 0.19252\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1982 - sparse_categorical_accuracy: 0.9213 - val_loss: 0.1932 - val_sparse_categorical_accuracy: 0.9326\n",
      "Epoch 589/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.1873 - sparse_categorical_accuracy: 0.9321\n",
      "Epoch 589: val_loss improved from 0.19252 to 0.19175, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1958 - sparse_categorical_accuracy: 0.9270 - val_loss: 0.1918 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 590/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2056 - sparse_categorical_accuracy: 0.9073\n",
      "Epoch 590: val_loss did not improve from 0.19175\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2073 - sparse_categorical_accuracy: 0.9045 - val_loss: 0.1934 - val_sparse_categorical_accuracy: 0.9326\n",
      "Epoch 591/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1954 - sparse_categorical_accuracy: 0.9173\n",
      "Epoch 591: val_loss did not improve from 0.19175\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1940 - sparse_categorical_accuracy: 0.9195 - val_loss: 0.1918 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 592/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.2000 - sparse_categorical_accuracy: 0.9144\n",
      "Epoch 592: val_loss improved from 0.19175 to 0.19149, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.2106 - sparse_categorical_accuracy: 0.9101 - val_loss: 0.1915 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 593/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1894 - sparse_categorical_accuracy: 0.9289\n",
      "Epoch 593: val_loss did not improve from 0.19149\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1871 - sparse_categorical_accuracy: 0.9307 - val_loss: 0.1930 - val_sparse_categorical_accuracy: 0.9326\n",
      "Epoch 594/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.2056 - sparse_categorical_accuracy: 0.9129\n",
      "Epoch 594: val_loss improved from 0.19149 to 0.19047, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2011 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.1905 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 595/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2116 - sparse_categorical_accuracy: 0.9146\n",
      "Epoch 595: val_loss did not improve from 0.19047\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2113 - sparse_categorical_accuracy: 0.9139 - val_loss: 0.1910 - val_sparse_categorical_accuracy: 0.9326\n",
      "Epoch 596/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2046 - sparse_categorical_accuracy: 0.9332\n",
      "Epoch 596: val_loss improved from 0.19047 to 0.19047, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2020 - sparse_categorical_accuracy: 0.9326 - val_loss: 0.1905 - val_sparse_categorical_accuracy: 0.9326\n",
      "Epoch 597/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2189 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 597: val_loss did not improve from 0.19047\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2126 - sparse_categorical_accuracy: 0.9213 - val_loss: 0.1907 - val_sparse_categorical_accuracy: 0.9326\n",
      "Epoch 598/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2064 - sparse_categorical_accuracy: 0.9116\n",
      "Epoch 598: val_loss did not improve from 0.19047\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2000 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.1911 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 599/10000\n",
      "21/34 [=================>............] - ETA: 0s - loss: 0.1891 - sparse_categorical_accuracy: 0.9226\n",
      "Epoch 599: val_loss did not improve from 0.19047\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1949 - sparse_categorical_accuracy: 0.9157 - val_loss: 0.1912 - val_sparse_categorical_accuracy: 0.9326\n",
      "Epoch 600/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2170 - sparse_categorical_accuracy: 0.8979\n",
      "Epoch 600: val_loss did not improve from 0.19047\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2204 - sparse_categorical_accuracy: 0.9007 - val_loss: 0.1932 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 601/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1920 - sparse_categorical_accuracy: 0.9194\n",
      "Epoch 601: val_loss improved from 0.19047 to 0.18843, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1917 - sparse_categorical_accuracy: 0.9213 - val_loss: 0.1884 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 602/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.2054 - sparse_categorical_accuracy: 0.9241\n",
      "Epoch 602: val_loss did not improve from 0.18843\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2026 - sparse_categorical_accuracy: 0.9195 - val_loss: 0.1890 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 603/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1936 - sparse_categorical_accuracy: 0.9271\n",
      "Epoch 603: val_loss did not improve from 0.18843\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1957 - sparse_categorical_accuracy: 0.9251 - val_loss: 0.1910 - val_sparse_categorical_accuracy: 0.9326\n",
      "Epoch 604/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1913 - sparse_categorical_accuracy: 0.9277\n",
      "Epoch 604: val_loss did not improve from 0.18843\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1926 - sparse_categorical_accuracy: 0.9270 - val_loss: 0.1890 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 605/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2030 - sparse_categorical_accuracy: 0.9101\n",
      "Epoch 605: val_loss did not improve from 0.18843\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2030 - sparse_categorical_accuracy: 0.9101 - val_loss: 0.1904 - val_sparse_categorical_accuracy: 0.9326\n",
      "Epoch 606/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1934 - sparse_categorical_accuracy: 0.9203\n",
      "Epoch 606: val_loss improved from 0.18843 to 0.18810, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1917 - sparse_categorical_accuracy: 0.9232 - val_loss: 0.1881 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 607/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2074 - sparse_categorical_accuracy: 0.9294\n",
      "Epoch 607: val_loss did not improve from 0.18810\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2013 - sparse_categorical_accuracy: 0.9326 - val_loss: 0.1930 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 608/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1941 - sparse_categorical_accuracy: 0.9271\n",
      "Epoch 608: val_loss did not improve from 0.18810\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1959 - sparse_categorical_accuracy: 0.9270 - val_loss: 0.1884 - val_sparse_categorical_accuracy: 0.9326\n",
      "Epoch 609/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2013 - sparse_categorical_accuracy: 0.9267\n",
      "Epoch 609: val_loss improved from 0.18810 to 0.18717, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2050 - sparse_categorical_accuracy: 0.9251 - val_loss: 0.1872 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 610/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1949 - sparse_categorical_accuracy: 0.9259\n",
      "Epoch 610: val_loss did not improve from 0.18717\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2002 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.1883 - val_sparse_categorical_accuracy: 0.9326\n",
      "Epoch 611/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1946 - sparse_categorical_accuracy: 0.9246\n",
      "Epoch 611: val_loss did not improve from 0.18717\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.2009 - sparse_categorical_accuracy: 0.9213 - val_loss: 0.1876 - val_sparse_categorical_accuracy: 0.9326\n",
      "Epoch 612/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1978 - sparse_categorical_accuracy: 0.9160\n",
      "Epoch 612: val_loss did not improve from 0.18717\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1987 - sparse_categorical_accuracy: 0.9157 - val_loss: 0.1879 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 613/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1881 - sparse_categorical_accuracy: 0.9219\n",
      "Epoch 613: val_loss improved from 0.18717 to 0.18692, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1973 - sparse_categorical_accuracy: 0.9157 - val_loss: 0.1869 - val_sparse_categorical_accuracy: 0.9326\n",
      "Epoch 614/10000\n",
      "21/34 [=================>............] - ETA: 0s - loss: 0.1905 - sparse_categorical_accuracy: 0.9256\n",
      "Epoch 614: val_loss did not improve from 0.18692\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1904 - sparse_categorical_accuracy: 0.9195 - val_loss: 0.1870 - val_sparse_categorical_accuracy: 0.9326\n",
      "Epoch 615/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2044 - sparse_categorical_accuracy: 0.9271\n",
      "Epoch 615: val_loss did not improve from 0.18692\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2019 - sparse_categorical_accuracy: 0.9288 - val_loss: 0.1893 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 616/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1950 - sparse_categorical_accuracy: 0.9194\n",
      "Epoch 616: val_loss improved from 0.18692 to 0.18551, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1910 - sparse_categorical_accuracy: 0.9213 - val_loss: 0.1855 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 617/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1938 - sparse_categorical_accuracy: 0.9242\n",
      "Epoch 617: val_loss did not improve from 0.18551\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1931 - sparse_categorical_accuracy: 0.9232 - val_loss: 0.1886 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 618/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2039 - sparse_categorical_accuracy: 0.9083\n",
      "Epoch 618: val_loss did not improve from 0.18551\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1985 - sparse_categorical_accuracy: 0.9139 - val_loss: 0.1856 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 619/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2093 - sparse_categorical_accuracy: 0.9181\n",
      "Epoch 619: val_loss did not improve from 0.18551\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2055 - sparse_categorical_accuracy: 0.9195 - val_loss: 0.1864 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 620/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1986 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 620: val_loss did not improve from 0.18551\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2003 - sparse_categorical_accuracy: 0.9157 - val_loss: 0.1871 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 621/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2141 - sparse_categorical_accuracy: 0.8979\n",
      "Epoch 621: val_loss did not improve from 0.18551\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2051 - sparse_categorical_accuracy: 0.9026 - val_loss: 0.1857 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 622/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2031 - sparse_categorical_accuracy: 0.9104\n",
      "Epoch 622: val_loss did not improve from 0.18551\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1973 - sparse_categorical_accuracy: 0.9157 - val_loss: 0.1872 - val_sparse_categorical_accuracy: 0.9326\n",
      "Epoch 623/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1993 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 623: val_loss improved from 0.18551 to 0.18530, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2036 - sparse_categorical_accuracy: 0.9139 - val_loss: 0.1853 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 624/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1693 - sparse_categorical_accuracy: 0.9423\n",
      "Epoch 624: val_loss did not improve from 0.18530\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1803 - sparse_categorical_accuracy: 0.9326 - val_loss: 0.1863 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 625/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1909 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 625: val_loss improved from 0.18530 to 0.18477, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1858 - sparse_categorical_accuracy: 0.9288 - val_loss: 0.1848 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 626/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1890 - sparse_categorical_accuracy: 0.9234\n",
      "Epoch 626: val_loss improved from 0.18477 to 0.18426, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1893 - sparse_categorical_accuracy: 0.9232 - val_loss: 0.1843 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 627/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1952 - sparse_categorical_accuracy: 0.9207\n",
      "Epoch 627: val_loss did not improve from 0.18426\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2038 - sparse_categorical_accuracy: 0.9139 - val_loss: 0.1845 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 628/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1898 - sparse_categorical_accuracy: 0.9229\n",
      "Epoch 628: val_loss improved from 0.18426 to 0.18273, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1975 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.1827 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 629/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2029 - sparse_categorical_accuracy: 0.9173\n",
      "Epoch 629: val_loss did not improve from 0.18273\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1959 - sparse_categorical_accuracy: 0.9232 - val_loss: 0.1848 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 630/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1988 - sparse_categorical_accuracy: 0.9176\n",
      "Epoch 630: val_loss did not improve from 0.18273\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1988 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.1869 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 631/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1847 - sparse_categorical_accuracy: 0.9332\n",
      "Epoch 631: val_loss did not improve from 0.18273\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1871 - sparse_categorical_accuracy: 0.9326 - val_loss: 0.1835 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 632/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1982 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 632: val_loss did not improve from 0.18273\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1964 - sparse_categorical_accuracy: 0.9232 - val_loss: 0.1835 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 633/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2214 - sparse_categorical_accuracy: 0.9073\n",
      "Epoch 633: val_loss did not improve from 0.18273\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2145 - sparse_categorical_accuracy: 0.9101 - val_loss: 0.1832 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 634/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1958 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 634: val_loss did not improve from 0.18273\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1981 - sparse_categorical_accuracy: 0.9157 - val_loss: 0.1847 - val_sparse_categorical_accuracy: 0.9326\n",
      "Epoch 635/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1960 - sparse_categorical_accuracy: 0.9224\n",
      "Epoch 635: val_loss did not improve from 0.18273\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2030 - sparse_categorical_accuracy: 0.9195 - val_loss: 0.1830 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 636/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1744 - sparse_categorical_accuracy: 0.9316\n",
      "Epoch 636: val_loss did not improve from 0.18273\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1748 - sparse_categorical_accuracy: 0.9345 - val_loss: 0.1833 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 637/10000\n",
      "22/34 [==================>...........] - ETA: 0s - loss: 0.1851 - sparse_categorical_accuracy: 0.9205\n",
      "Epoch 637: val_loss improved from 0.18273 to 0.18049, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1884 - sparse_categorical_accuracy: 0.9139 - val_loss: 0.1805 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 638/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1799 - sparse_categorical_accuracy: 0.9353\n",
      "Epoch 638: val_loss did not improve from 0.18049\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1907 - sparse_categorical_accuracy: 0.9288 - val_loss: 0.1812 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 639/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2070 - sparse_categorical_accuracy: 0.9073\n",
      "Epoch 639: val_loss did not improve from 0.18049\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2096 - sparse_categorical_accuracy: 0.9101 - val_loss: 0.1821 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 640/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1621 - sparse_categorical_accuracy: 0.9353\n",
      "Epoch 640: val_loss did not improve from 0.18049\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1721 - sparse_categorical_accuracy: 0.9270 - val_loss: 0.1816 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 641/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1965 - sparse_categorical_accuracy: 0.9040\n",
      "Epoch 641: val_loss did not improve from 0.18049\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2023 - sparse_categorical_accuracy: 0.9045 - val_loss: 0.1816 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 642/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1909 - sparse_categorical_accuracy: 0.9274\n",
      "Epoch 642: val_loss did not improve from 0.18049\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1951 - sparse_categorical_accuracy: 0.9251 - val_loss: 0.1845 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 643/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1926 - sparse_categorical_accuracy: 0.9234\n",
      "Epoch 643: val_loss did not improve from 0.18049\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1906 - sparse_categorical_accuracy: 0.9213 - val_loss: 0.1810 - val_sparse_categorical_accuracy: 0.9326\n",
      "Epoch 644/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1925 - sparse_categorical_accuracy: 0.9289\n",
      "Epoch 644: val_loss did not improve from 0.18049\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1910 - sparse_categorical_accuracy: 0.9251 - val_loss: 0.1812 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 645/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1820 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 645: val_loss improved from 0.18049 to 0.17989, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1840 - sparse_categorical_accuracy: 0.9326 - val_loss: 0.1799 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 646/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1927 - sparse_categorical_accuracy: 0.9159\n",
      "Epoch 646: val_loss improved from 0.17989 to 0.17913, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1945 - sparse_categorical_accuracy: 0.9139 - val_loss: 0.1791 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 647/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1954 - sparse_categorical_accuracy: 0.9267\n",
      "Epoch 647: val_loss did not improve from 0.17913\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1854 - sparse_categorical_accuracy: 0.9307 - val_loss: 0.1793 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 648/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1888 - sparse_categorical_accuracy: 0.9246\n",
      "Epoch 648: val_loss did not improve from 0.17913\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1921 - sparse_categorical_accuracy: 0.9251 - val_loss: 0.1822 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 649/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1798 - sparse_categorical_accuracy: 0.9327\n",
      "Epoch 649: val_loss improved from 0.17913 to 0.17756, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1916 - sparse_categorical_accuracy: 0.9270 - val_loss: 0.1776 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 650/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1942 - sparse_categorical_accuracy: 0.9104\n",
      "Epoch 650: val_loss did not improve from 0.17756\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1899 - sparse_categorical_accuracy: 0.9139 - val_loss: 0.1788 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 651/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1785 - sparse_categorical_accuracy: 0.9254\n",
      "Epoch 651: val_loss did not improve from 0.17756\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1822 - sparse_categorical_accuracy: 0.9195 - val_loss: 0.1806 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 652/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1837 - sparse_categorical_accuracy: 0.9224\n",
      "Epoch 652: val_loss improved from 0.17756 to 0.17684, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1823 - sparse_categorical_accuracy: 0.9251 - val_loss: 0.1768 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 653/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.2005 - sparse_categorical_accuracy: 0.9082\n",
      "Epoch 653: val_loss did not improve from 0.17684\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1980 - sparse_categorical_accuracy: 0.9101 - val_loss: 0.1786 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 654/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1959 - sparse_categorical_accuracy: 0.9085\n",
      "Epoch 654: val_loss did not improve from 0.17684\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1906 - sparse_categorical_accuracy: 0.9157 - val_loss: 0.1777 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 655/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2006 - sparse_categorical_accuracy: 0.9021\n",
      "Epoch 655: val_loss did not improve from 0.17684\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1932 - sparse_categorical_accuracy: 0.9120 - val_loss: 0.1780 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 656/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1957 - sparse_categorical_accuracy: 0.9107\n",
      "Epoch 656: val_loss did not improve from 0.17684\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1961 - sparse_categorical_accuracy: 0.9157 - val_loss: 0.1774 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 657/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1927 - sparse_categorical_accuracy: 0.9116\n",
      "Epoch 657: val_loss did not improve from 0.17684\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1942 - sparse_categorical_accuracy: 0.9157 - val_loss: 0.1808 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 658/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1715 - sparse_categorical_accuracy: 0.9375\n",
      "Epoch 658: val_loss did not improve from 0.17684\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1806 - sparse_categorical_accuracy: 0.9288 - val_loss: 0.1794 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 659/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1948 - sparse_categorical_accuracy: 0.9187\n",
      "Epoch 659: val_loss improved from 0.17684 to 0.17679, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1919 - sparse_categorical_accuracy: 0.9195 - val_loss: 0.1768 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 660/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1846 - sparse_categorical_accuracy: 0.9270\n",
      "Epoch 660: val_loss did not improve from 0.17679\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1846 - sparse_categorical_accuracy: 0.9270 - val_loss: 0.1801 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 661/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1845 - sparse_categorical_accuracy: 0.9153\n",
      "Epoch 661: val_loss improved from 0.17679 to 0.17539, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1828 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.1754 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 662/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1732 - sparse_categorical_accuracy: 0.9354\n",
      "Epoch 662: val_loss improved from 0.17539 to 0.17457, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1781 - sparse_categorical_accuracy: 0.9307 - val_loss: 0.1746 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 663/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1799 - sparse_categorical_accuracy: 0.9327\n",
      "Epoch 663: val_loss did not improve from 0.17457\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1817 - sparse_categorical_accuracy: 0.9270 - val_loss: 0.1814 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 664/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1743 - sparse_categorical_accuracy: 0.9397\n",
      "Epoch 664: val_loss improved from 0.17457 to 0.17354, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1712 - sparse_categorical_accuracy: 0.9382 - val_loss: 0.1735 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 665/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2023 - sparse_categorical_accuracy: 0.9234\n",
      "Epoch 665: val_loss did not improve from 0.17354\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.2007 - sparse_categorical_accuracy: 0.9251 - val_loss: 0.1739 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 666/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1786 - sparse_categorical_accuracy: 0.9353\n",
      "Epoch 666: val_loss did not improve from 0.17354\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1791 - sparse_categorical_accuracy: 0.9363 - val_loss: 0.1783 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 667/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1751 - sparse_categorical_accuracy: 0.9375\n",
      "Epoch 667: val_loss did not improve from 0.17354\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1837 - sparse_categorical_accuracy: 0.9326 - val_loss: 0.1743 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 668/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1794 - sparse_categorical_accuracy: 0.9375\n",
      "Epoch 668: val_loss did not improve from 0.17354\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1825 - sparse_categorical_accuracy: 0.9345 - val_loss: 0.1760 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 669/10000\n",
      "21/34 [=================>............] - ETA: 0s - loss: 0.2025 - sparse_categorical_accuracy: 0.9048\n",
      "Epoch 669: val_loss did not improve from 0.17354\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1960 - sparse_categorical_accuracy: 0.9120 - val_loss: 0.1759 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 670/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2023 - sparse_categorical_accuracy: 0.9208\n",
      "Epoch 670: val_loss improved from 0.17354 to 0.17195, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1955 - sparse_categorical_accuracy: 0.9251 - val_loss: 0.1720 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 671/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.2035 - sparse_categorical_accuracy: 0.9040\n",
      "Epoch 671: val_loss did not improve from 0.17195\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1864 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.1739 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 672/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1916 - sparse_categorical_accuracy: 0.9173\n",
      "Epoch 672: val_loss did not improve from 0.17195\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1964 - sparse_categorical_accuracy: 0.9195 - val_loss: 0.1732 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 673/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1729 - sparse_categorical_accuracy: 0.9375\n",
      "Epoch 673: val_loss did not improve from 0.17195\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1813 - sparse_categorical_accuracy: 0.9288 - val_loss: 0.1756 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 674/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1898 - sparse_categorical_accuracy: 0.9259\n",
      "Epoch 674: val_loss did not improve from 0.17195\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1853 - sparse_categorical_accuracy: 0.9251 - val_loss: 0.1726 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 675/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1786 - sparse_categorical_accuracy: 0.9275\n",
      "Epoch 675: val_loss did not improve from 0.17195\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1853 - sparse_categorical_accuracy: 0.9270 - val_loss: 0.1759 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 676/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1905 - sparse_categorical_accuracy: 0.9195\n",
      "Epoch 676: val_loss improved from 0.17195 to 0.17132, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1905 - sparse_categorical_accuracy: 0.9195 - val_loss: 0.1713 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 677/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1727 - sparse_categorical_accuracy: 0.9316\n",
      "Epoch 677: val_loss did not improve from 0.17132\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1819 - sparse_categorical_accuracy: 0.9288 - val_loss: 0.1714 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 678/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1899 - sparse_categorical_accuracy: 0.9214\n",
      "Epoch 678: val_loss did not improve from 0.17132\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1854 - sparse_categorical_accuracy: 0.9232 - val_loss: 0.1722 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 679/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1838 - sparse_categorical_accuracy: 0.9258\n",
      "Epoch 679: val_loss did not improve from 0.17132\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1847 - sparse_categorical_accuracy: 0.9251 - val_loss: 0.1753 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 680/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1735 - sparse_categorical_accuracy: 0.9310\n",
      "Epoch 680: val_loss did not improve from 0.17132\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1816 - sparse_categorical_accuracy: 0.9251 - val_loss: 0.1722 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 681/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1817 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 681: val_loss did not improve from 0.17132\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1808 - sparse_categorical_accuracy: 0.9251 - val_loss: 0.1733 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 682/10000\n",
      "20/34 [================>.............] - ETA: 0s - loss: 0.1756 - sparse_categorical_accuracy: 0.9375\n",
      "Epoch 682: val_loss did not improve from 0.17132\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1719 - sparse_categorical_accuracy: 0.9401 - val_loss: 0.1752 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 683/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1814 - sparse_categorical_accuracy: 0.9308\n",
      "Epoch 683: val_loss improved from 0.17132 to 0.17080, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1755 - sparse_categorical_accuracy: 0.9345 - val_loss: 0.1708 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 684/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1909 - sparse_categorical_accuracy: 0.9271\n",
      "Epoch 684: val_loss did not improve from 0.17080\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1840 - sparse_categorical_accuracy: 0.9307 - val_loss: 0.1720 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 685/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1717 - sparse_categorical_accuracy: 0.9315\n",
      "Epoch 685: val_loss did not improve from 0.17080\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1742 - sparse_categorical_accuracy: 0.9307 - val_loss: 0.1749 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 686/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1811 - sparse_categorical_accuracy: 0.9229\n",
      "Epoch 686: val_loss improved from 0.17080 to 0.16935, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1811 - sparse_categorical_accuracy: 0.9213 - val_loss: 0.1694 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 687/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1789 - sparse_categorical_accuracy: 0.9375\n",
      "Epoch 687: val_loss did not improve from 0.16935\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1801 - sparse_categorical_accuracy: 0.9307 - val_loss: 0.1709 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 688/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.2096 - sparse_categorical_accuracy: 0.8992\n",
      "Epoch 688: val_loss did not improve from 0.16935\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2032 - sparse_categorical_accuracy: 0.9045 - val_loss: 0.1717 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 689/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1821 - sparse_categorical_accuracy: 0.9335\n",
      "Epoch 689: val_loss did not improve from 0.16935\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1809 - sparse_categorical_accuracy: 0.9345 - val_loss: 0.1694 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 690/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.2014 - sparse_categorical_accuracy: 0.9207\n",
      "Epoch 690: val_loss did not improve from 0.16935\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1931 - sparse_categorical_accuracy: 0.9251 - val_loss: 0.1702 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 691/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1744 - sparse_categorical_accuracy: 0.9375\n",
      "Epoch 691: val_loss did not improve from 0.16935\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1687 - sparse_categorical_accuracy: 0.9401 - val_loss: 0.1697 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 692/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1746 - sparse_categorical_accuracy: 0.9351\n",
      "Epoch 692: val_loss improved from 0.16935 to 0.16833, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1682 - sparse_categorical_accuracy: 0.9438 - val_loss: 0.1683 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 693/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1753 - sparse_categorical_accuracy: 0.9292\n",
      "Epoch 693: val_loss improved from 0.16833 to 0.16769, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1752 - sparse_categorical_accuracy: 0.9288 - val_loss: 0.1677 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 694/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.2093 - sparse_categorical_accuracy: 0.9125\n",
      "Epoch 694: val_loss did not improve from 0.16769\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.2004 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.1691 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 695/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1735 - sparse_categorical_accuracy: 0.9286\n",
      "Epoch 695: val_loss did not improve from 0.16769\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1729 - sparse_categorical_accuracy: 0.9288 - val_loss: 0.1700 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 696/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1718 - sparse_categorical_accuracy: 0.9423\n",
      "Epoch 696: val_loss did not improve from 0.16769\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1690 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.1693 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 697/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1909 - sparse_categorical_accuracy: 0.9229\n",
      "Epoch 697: val_loss improved from 0.16769 to 0.16752, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1937 - sparse_categorical_accuracy: 0.9232 - val_loss: 0.1675 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 698/10000\n",
      "21/34 [=================>............] - ETA: 0s - loss: 0.1517 - sparse_categorical_accuracy: 0.9464\n",
      "Epoch 698: val_loss did not improve from 0.16752\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1825 - sparse_categorical_accuracy: 0.9288 - val_loss: 0.1755 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 699/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1890 - sparse_categorical_accuracy: 0.9174\n",
      "Epoch 699: val_loss did not improve from 0.16752\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1801 - sparse_categorical_accuracy: 0.9251 - val_loss: 0.1684 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 700/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1889 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 700: val_loss did not improve from 0.16752\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1986 - sparse_categorical_accuracy: 0.9195 - val_loss: 0.1701 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 701/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1663 - sparse_categorical_accuracy: 0.9420\n",
      "Epoch 701: val_loss improved from 0.16752 to 0.16597, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1655 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.1660 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 702/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1821 - sparse_categorical_accuracy: 0.9423\n",
      "Epoch 702: val_loss did not improve from 0.16597\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1819 - sparse_categorical_accuracy: 0.9363 - val_loss: 0.1696 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 703/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1750 - sparse_categorical_accuracy: 0.9146\n",
      "Epoch 703: val_loss improved from 0.16597 to 0.16558, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1810 - sparse_categorical_accuracy: 0.9195 - val_loss: 0.1656 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 704/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1908 - sparse_categorical_accuracy: 0.9267\n",
      "Epoch 704: val_loss did not improve from 0.16558\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1840 - sparse_categorical_accuracy: 0.9307 - val_loss: 0.1687 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 705/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1726 - sparse_categorical_accuracy: 0.9323\n",
      "Epoch 705: val_loss did not improve from 0.16558\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1722 - sparse_categorical_accuracy: 0.9326 - val_loss: 0.1665 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 706/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1724 - sparse_categorical_accuracy: 0.9312\n",
      "Epoch 706: val_loss improved from 0.16558 to 0.16420, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1709 - sparse_categorical_accuracy: 0.9345 - val_loss: 0.1642 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 707/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1832 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 707: val_loss did not improve from 0.16420\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1789 - sparse_categorical_accuracy: 0.9288 - val_loss: 0.1652 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 708/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1839 - sparse_categorical_accuracy: 0.9282\n",
      "Epoch 708: val_loss did not improve from 0.16420\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1785 - sparse_categorical_accuracy: 0.9288 - val_loss: 0.1655 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 709/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1738 - sparse_categorical_accuracy: 0.9396\n",
      "Epoch 709: val_loss did not improve from 0.16420\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1735 - sparse_categorical_accuracy: 0.9401 - val_loss: 0.1691 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 710/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1883 - sparse_categorical_accuracy: 0.9174\n",
      "Epoch 710: val_loss did not improve from 0.16420\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1810 - sparse_categorical_accuracy: 0.9232 - val_loss: 0.1654 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 711/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1854 - sparse_categorical_accuracy: 0.9214\n",
      "Epoch 711: val_loss did not improve from 0.16420\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1811 - sparse_categorical_accuracy: 0.9251 - val_loss: 0.1681 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 712/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1595 - sparse_categorical_accuracy: 0.9353\n",
      "Epoch 712: val_loss did not improve from 0.16420\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1690 - sparse_categorical_accuracy: 0.9288 - val_loss: 0.1651 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 713/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1811 - sparse_categorical_accuracy: 0.9250\n",
      "Epoch 713: val_loss did not improve from 0.16420\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1871 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.1674 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 714/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1731 - sparse_categorical_accuracy: 0.9299\n",
      "Epoch 714: val_loss did not improve from 0.16420\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1734 - sparse_categorical_accuracy: 0.9288 - val_loss: 0.1672 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 715/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1870 - sparse_categorical_accuracy: 0.9277\n",
      "Epoch 715: val_loss did not improve from 0.16420\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1841 - sparse_categorical_accuracy: 0.9288 - val_loss: 0.1648 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 716/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.2012 - sparse_categorical_accuracy: 0.9138\n",
      "Epoch 716: val_loss did not improve from 0.16420\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1921 - sparse_categorical_accuracy: 0.9195 - val_loss: 0.1653 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 717/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1756 - sparse_categorical_accuracy: 0.9353\n",
      "Epoch 717: val_loss did not improve from 0.16420\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1745 - sparse_categorical_accuracy: 0.9382 - val_loss: 0.1683 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 718/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1522 - sparse_categorical_accuracy: 0.9458\n",
      "Epoch 718: val_loss did not improve from 0.16420\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1588 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.1644 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 719/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1701 - sparse_categorical_accuracy: 0.9294\n",
      "Epoch 719: val_loss improved from 0.16420 to 0.16289, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1694 - sparse_categorical_accuracy: 0.9288 - val_loss: 0.1629 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 720/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1608 - sparse_categorical_accuracy: 0.9375\n",
      "Epoch 720: val_loss did not improve from 0.16289\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1658 - sparse_categorical_accuracy: 0.9382 - val_loss: 0.1654 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 721/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1834 - sparse_categorical_accuracy: 0.9125\n",
      "Epoch 721: val_loss improved from 0.16289 to 0.16281, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 11ms/step - loss: 0.1806 - sparse_categorical_accuracy: 0.9157 - val_loss: 0.1628 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 722/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1663 - sparse_categorical_accuracy: 0.9413\n",
      "Epoch 722: val_loss improved from 0.16281 to 0.16239, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.1663 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.1624 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 723/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1733 - sparse_categorical_accuracy: 0.9307\n",
      "Epoch 723: val_loss did not improve from 0.16239\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1733 - sparse_categorical_accuracy: 0.9307 - val_loss: 0.1632 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 724/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1572 - sparse_categorical_accuracy: 0.9547\n",
      "Epoch 724: val_loss improved from 0.16239 to 0.16227, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1707 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.1623 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 725/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1791 - sparse_categorical_accuracy: 0.9303\n",
      "Epoch 725: val_loss improved from 0.16227 to 0.16195, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1733 - sparse_categorical_accuracy: 0.9345 - val_loss: 0.1620 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 726/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1570 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 726: val_loss did not improve from 0.16195\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1668 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.1631 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 727/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1636 - sparse_categorical_accuracy: 0.9395\n",
      "Epoch 727: val_loss did not improve from 0.16195\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1728 - sparse_categorical_accuracy: 0.9326 - val_loss: 0.1628 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 728/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1610 - sparse_categorical_accuracy: 0.9475\n",
      "Epoch 728: val_loss did not improve from 0.16195\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1661 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.1628 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 729/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1783 - sparse_categorical_accuracy: 0.9447\n",
      "Epoch 729: val_loss improved from 0.16195 to 0.16004, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1657 - sparse_categorical_accuracy: 0.9494 - val_loss: 0.1600 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 730/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1733 - sparse_categorical_accuracy: 0.9236\n",
      "Epoch 730: val_loss did not improve from 0.16004\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1824 - sparse_categorical_accuracy: 0.9195 - val_loss: 0.1621 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 731/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1789 - sparse_categorical_accuracy: 0.9306\n",
      "Epoch 731: val_loss did not improve from 0.16004\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1766 - sparse_categorical_accuracy: 0.9326 - val_loss: 0.1604 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 732/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1860 - sparse_categorical_accuracy: 0.9167\n",
      "Epoch 732: val_loss did not improve from 0.16004\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1793 - sparse_categorical_accuracy: 0.9251 - val_loss: 0.1605 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 733/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1598 - sparse_categorical_accuracy: 0.9413\n",
      "Epoch 733: val_loss improved from 0.16004 to 0.15915, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.1625 - sparse_categorical_accuracy: 0.9401 - val_loss: 0.1592 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 734/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1855 - sparse_categorical_accuracy: 0.9294\n",
      "Epoch 734: val_loss did not improve from 0.15915\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1824 - sparse_categorical_accuracy: 0.9307 - val_loss: 0.1605 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 735/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1886 - sparse_categorical_accuracy: 0.9153\n",
      "Epoch 735: val_loss did not improve from 0.15915\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1864 - sparse_categorical_accuracy: 0.9195 - val_loss: 0.1605 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 736/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1634 - sparse_categorical_accuracy: 0.9492\n",
      "Epoch 736: val_loss did not improve from 0.15915\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1690 - sparse_categorical_accuracy: 0.9438 - val_loss: 0.1614 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 737/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1776 - sparse_categorical_accuracy: 0.9254\n",
      "Epoch 737: val_loss improved from 0.15915 to 0.15915, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.1738 - sparse_categorical_accuracy: 0.9288 - val_loss: 0.1591 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 738/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1491 - sparse_categorical_accuracy: 0.9543\n",
      "Epoch 738: val_loss improved from 0.15915 to 0.15831, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1695 - sparse_categorical_accuracy: 0.9382 - val_loss: 0.1583 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 739/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1677 - sparse_categorical_accuracy: 0.9355\n",
      "Epoch 739: val_loss did not improve from 0.15831\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1620 - sparse_categorical_accuracy: 0.9401 - val_loss: 0.1612 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 740/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1807 - sparse_categorical_accuracy: 0.9234\n",
      "Epoch 740: val_loss did not improve from 0.15831\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1804 - sparse_categorical_accuracy: 0.9270 - val_loss: 0.1589 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 741/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1626 - sparse_categorical_accuracy: 0.9375\n",
      "Epoch 741: val_loss did not improve from 0.15831\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1635 - sparse_categorical_accuracy: 0.9363 - val_loss: 0.1608 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 742/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1757 - sparse_categorical_accuracy: 0.9354\n",
      "Epoch 742: val_loss did not improve from 0.15831\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1720 - sparse_categorical_accuracy: 0.9382 - val_loss: 0.1599 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 743/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1689 - sparse_categorical_accuracy: 0.9330\n",
      "Epoch 743: val_loss improved from 0.15831 to 0.15747, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1711 - sparse_categorical_accuracy: 0.9345 - val_loss: 0.1575 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 744/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1710 - sparse_categorical_accuracy: 0.9234\n",
      "Epoch 744: val_loss did not improve from 0.15747\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1668 - sparse_categorical_accuracy: 0.9270 - val_loss: 0.1595 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 745/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1835 - sparse_categorical_accuracy: 0.9173\n",
      "Epoch 745: val_loss improved from 0.15747 to 0.15658, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1780 - sparse_categorical_accuracy: 0.9213 - val_loss: 0.1566 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 746/10000\n",
      "22/34 [==================>...........] - ETA: 0s - loss: 0.1730 - sparse_categorical_accuracy: 0.9347\n",
      "Epoch 746: val_loss did not improve from 0.15658\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1703 - sparse_categorical_accuracy: 0.9345 - val_loss: 0.1607 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 747/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1672 - sparse_categorical_accuracy: 0.9375\n",
      "Epoch 747: val_loss did not improve from 0.15658\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1703 - sparse_categorical_accuracy: 0.9326 - val_loss: 0.1581 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 748/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1555 - sparse_categorical_accuracy: 0.9438\n",
      "Epoch 748: val_loss did not improve from 0.15658\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1608 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.1582 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 749/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1639 - sparse_categorical_accuracy: 0.9355\n",
      "Epoch 749: val_loss did not improve from 0.15658\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1705 - sparse_categorical_accuracy: 0.9326 - val_loss: 0.1618 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 750/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1654 - sparse_categorical_accuracy: 0.9435\n",
      "Epoch 750: val_loss improved from 0.15658 to 0.15612, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1699 - sparse_categorical_accuracy: 0.9382 - val_loss: 0.1561 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 751/10000\n",
      "21/34 [=================>............] - ETA: 0s - loss: 0.1801 - sparse_categorical_accuracy: 0.9286\n",
      "Epoch 751: val_loss improved from 0.15612 to 0.15568, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1724 - sparse_categorical_accuracy: 0.9288 - val_loss: 0.1557 - val_sparse_categorical_accuracy: 0.9438\n",
      "Epoch 752/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1614 - sparse_categorical_accuracy: 0.9419\n",
      "Epoch 752: val_loss did not improve from 0.15568\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1614 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.1558 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 753/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1672 - sparse_categorical_accuracy: 0.9288\n",
      "Epoch 753: val_loss did not improve from 0.15568\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1672 - sparse_categorical_accuracy: 0.9288 - val_loss: 0.1583 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 754/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1707 - sparse_categorical_accuracy: 0.9312\n",
      "Epoch 754: val_loss did not improve from 0.15568\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1677 - sparse_categorical_accuracy: 0.9326 - val_loss: 0.1562 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 755/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1691 - sparse_categorical_accuracy: 0.9282\n",
      "Epoch 755: val_loss did not improve from 0.15568\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1728 - sparse_categorical_accuracy: 0.9251 - val_loss: 0.1558 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 756/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1791 - sparse_categorical_accuracy: 0.9315\n",
      "Epoch 756: val_loss did not improve from 0.15568\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1758 - sparse_categorical_accuracy: 0.9345 - val_loss: 0.1559 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 757/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1793 - sparse_categorical_accuracy: 0.9251\n",
      "Epoch 757: val_loss did not improve from 0.15568\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1793 - sparse_categorical_accuracy: 0.9251 - val_loss: 0.1632 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 758/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1769 - sparse_categorical_accuracy: 0.9261\n",
      "Epoch 758: val_loss improved from 0.15568 to 0.15461, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1773 - sparse_categorical_accuracy: 0.9270 - val_loss: 0.1546 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 759/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1732 - sparse_categorical_accuracy: 0.9297\n",
      "Epoch 759: val_loss did not improve from 0.15461\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1703 - sparse_categorical_accuracy: 0.9326 - val_loss: 0.1558 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 760/10000\n",
      "22/34 [==================>...........] - ETA: 0s - loss: 0.1625 - sparse_categorical_accuracy: 0.9375\n",
      "Epoch 760: val_loss improved from 0.15461 to 0.15428, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1685 - sparse_categorical_accuracy: 0.9345 - val_loss: 0.1543 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 761/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1632 - sparse_categorical_accuracy: 0.9395\n",
      "Epoch 761: val_loss did not improve from 0.15428\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1682 - sparse_categorical_accuracy: 0.9363 - val_loss: 0.1557 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 762/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1626 - sparse_categorical_accuracy: 0.9355\n",
      "Epoch 762: val_loss improved from 0.15428 to 0.15333, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1583 - sparse_categorical_accuracy: 0.9401 - val_loss: 0.1533 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 763/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1654 - sparse_categorical_accuracy: 0.9315\n",
      "Epoch 763: val_loss did not improve from 0.15333\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1695 - sparse_categorical_accuracy: 0.9288 - val_loss: 0.1544 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 764/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1616 - sparse_categorical_accuracy: 0.9415\n",
      "Epoch 764: val_loss did not improve from 0.15333\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1583 - sparse_categorical_accuracy: 0.9438 - val_loss: 0.1547 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 765/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1682 - sparse_categorical_accuracy: 0.9413\n",
      "Epoch 765: val_loss did not improve from 0.15333\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1674 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.1562 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 766/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1715 - sparse_categorical_accuracy: 0.9375\n",
      "Epoch 766: val_loss did not improve from 0.15333\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1684 - sparse_categorical_accuracy: 0.9401 - val_loss: 0.1547 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 767/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.1726 - sparse_categorical_accuracy: 0.9402\n",
      "Epoch 767: val_loss did not improve from 0.15333\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1690 - sparse_categorical_accuracy: 0.9382 - val_loss: 0.1544 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 768/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1647 - sparse_categorical_accuracy: 0.9261\n",
      "Epoch 768: val_loss did not improve from 0.15333\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1670 - sparse_categorical_accuracy: 0.9251 - val_loss: 0.1540 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 769/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1571 - sparse_categorical_accuracy: 0.9375\n",
      "Epoch 769: val_loss improved from 0.15333 to 0.15256, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1737 - sparse_categorical_accuracy: 0.9307 - val_loss: 0.1526 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 770/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1636 - sparse_categorical_accuracy: 0.9363\n",
      "Epoch 770: val_loss did not improve from 0.15256\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1636 - sparse_categorical_accuracy: 0.9363 - val_loss: 0.1588 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 771/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1660 - sparse_categorical_accuracy: 0.9395\n",
      "Epoch 771: val_loss did not improve from 0.15256\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1665 - sparse_categorical_accuracy: 0.9401 - val_loss: 0.1535 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 772/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1532 - sparse_categorical_accuracy: 0.9415\n",
      "Epoch 772: val_loss did not improve from 0.15256\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1506 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.1563 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 773/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1648 - sparse_categorical_accuracy: 0.9375\n",
      "Epoch 773: val_loss did not improve from 0.15256\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1674 - sparse_categorical_accuracy: 0.9363 - val_loss: 0.1538 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 774/10000\n",
      "22/34 [==================>...........] - ETA: 0s - loss: 0.1829 - sparse_categorical_accuracy: 0.9205\n",
      "Epoch 774: val_loss improved from 0.15256 to 0.15253, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1754 - sparse_categorical_accuracy: 0.9270 - val_loss: 0.1525 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 775/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1667 - sparse_categorical_accuracy: 0.9435\n",
      "Epoch 775: val_loss did not improve from 0.15253\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1616 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.1547 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 776/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1660 - sparse_categorical_accuracy: 0.9351\n",
      "Epoch 776: val_loss did not improve from 0.15253\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1551 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.1550 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 777/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1605 - sparse_categorical_accuracy: 0.9335\n",
      "Epoch 777: val_loss did not improve from 0.15253\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1611 - sparse_categorical_accuracy: 0.9345 - val_loss: 0.1533 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 778/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1595 - sparse_categorical_accuracy: 0.9438\n",
      "Epoch 778: val_loss improved from 0.15253 to 0.15215, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1595 - sparse_categorical_accuracy: 0.9438 - val_loss: 0.1522 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 779/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.1500 - sparse_categorical_accuracy: 0.9484\n",
      "Epoch 779: val_loss improved from 0.15215 to 0.15063, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1565 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.1506 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 780/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1655 - sparse_categorical_accuracy: 0.9254\n",
      "Epoch 780: val_loss did not improve from 0.15063\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1609 - sparse_categorical_accuracy: 0.9288 - val_loss: 0.1522 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 781/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1595 - sparse_categorical_accuracy: 0.9325\n",
      "Epoch 781: val_loss did not improve from 0.15063\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1604 - sparse_categorical_accuracy: 0.9288 - val_loss: 0.1527 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 782/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1683 - sparse_categorical_accuracy: 0.9395\n",
      "Epoch 782: val_loss did not improve from 0.15063\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1664 - sparse_categorical_accuracy: 0.9401 - val_loss: 0.1532 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 783/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1591 - sparse_categorical_accuracy: 0.9375\n",
      "Epoch 783: val_loss did not improve from 0.15063\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1607 - sparse_categorical_accuracy: 0.9345 - val_loss: 0.1527 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 784/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1605 - sparse_categorical_accuracy: 0.9456\n",
      "Epoch 784: val_loss did not improve from 0.15063\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1646 - sparse_categorical_accuracy: 0.9438 - val_loss: 0.1519 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 785/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1688 - sparse_categorical_accuracy: 0.9419\n",
      "Epoch 785: val_loss did not improve from 0.15063\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1688 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.1539 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 786/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.1865 - sparse_categorical_accuracy: 0.9212\n",
      "Epoch 786: val_loss did not improve from 0.15063\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1685 - sparse_categorical_accuracy: 0.9270 - val_loss: 0.1511 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 787/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1804 - sparse_categorical_accuracy: 0.9263\n",
      "Epoch 787: val_loss improved from 0.15063 to 0.14840, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1769 - sparse_categorical_accuracy: 0.9288 - val_loss: 0.1484 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 788/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1680 - sparse_categorical_accuracy: 0.9396\n",
      "Epoch 788: val_loss did not improve from 0.14840\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1640 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.1495 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 789/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1512 - sparse_categorical_accuracy: 0.9489\n",
      "Epoch 789: val_loss did not improve from 0.14840\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1544 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1518 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 790/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1480 - sparse_categorical_accuracy: 0.9399\n",
      "Epoch 790: val_loss did not improve from 0.14840\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1516 - sparse_categorical_accuracy: 0.9382 - val_loss: 0.1530 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 791/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1723 - sparse_categorical_accuracy: 0.9337\n",
      "Epoch 791: val_loss did not improve from 0.14840\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1724 - sparse_categorical_accuracy: 0.9345 - val_loss: 0.1503 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 792/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.1480 - sparse_categorical_accuracy: 0.9429\n",
      "Epoch 792: val_loss did not improve from 0.14840\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1506 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.1509 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 793/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1619 - sparse_categorical_accuracy: 0.9318\n",
      "Epoch 793: val_loss did not improve from 0.14840\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1608 - sparse_categorical_accuracy: 0.9326 - val_loss: 0.1501 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 794/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1579 - sparse_categorical_accuracy: 0.9487\n",
      "Epoch 794: val_loss did not improve from 0.14840\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.1537 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1488 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 795/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1607 - sparse_categorical_accuracy: 0.9398\n",
      "Epoch 795: val_loss did not improve from 0.14840\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1549 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.1490 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 796/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1612 - sparse_categorical_accuracy: 0.9395\n",
      "Epoch 796: val_loss did not improve from 0.14840\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1611 - sparse_categorical_accuracy: 0.9401 - val_loss: 0.1611 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 797/10000\n",
      "22/34 [==================>...........] - ETA: 0s - loss: 0.1821 - sparse_categorical_accuracy: 0.9318\n",
      "Epoch 797: val_loss did not improve from 0.14840\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1638 - sparse_categorical_accuracy: 0.9363 - val_loss: 0.1493 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 798/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1689 - sparse_categorical_accuracy: 0.9159\n",
      "Epoch 798: val_loss did not improve from 0.14840\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1660 - sparse_categorical_accuracy: 0.9195 - val_loss: 0.1492 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 799/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1645 - sparse_categorical_accuracy: 0.9279\n",
      "Epoch 799: val_loss did not improve from 0.14840\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1620 - sparse_categorical_accuracy: 0.9270 - val_loss: 0.1513 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 800/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1562 - sparse_categorical_accuracy: 0.9438\n",
      "Epoch 800: val_loss improved from 0.14840 to 0.14837, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1595 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.1484 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 801/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1592 - sparse_categorical_accuracy: 0.9394\n",
      "Epoch 801: val_loss did not improve from 0.14837\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1603 - sparse_categorical_accuracy: 0.9382 - val_loss: 0.1495 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 802/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1662 - sparse_categorical_accuracy: 0.9310\n",
      "Epoch 802: val_loss improved from 0.14837 to 0.14769, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1610 - sparse_categorical_accuracy: 0.9363 - val_loss: 0.1477 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 803/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1481 - sparse_categorical_accuracy: 0.9476\n",
      "Epoch 803: val_loss did not improve from 0.14769\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1542 - sparse_categorical_accuracy: 0.9401 - val_loss: 0.1486 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 804/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1818 - sparse_categorical_accuracy: 0.9219\n",
      "Epoch 804: val_loss did not improve from 0.14769\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1661 - sparse_categorical_accuracy: 0.9326 - val_loss: 0.1477 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 805/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1571 - sparse_categorical_accuracy: 0.9333\n",
      "Epoch 805: val_loss did not improve from 0.14769\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1576 - sparse_categorical_accuracy: 0.9382 - val_loss: 0.1506 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 806/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1424 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 806: val_loss did not improve from 0.14769\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1514 - sparse_categorical_accuracy: 0.9438 - val_loss: 0.1490 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 807/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1399 - sparse_categorical_accuracy: 0.9519\n",
      "Epoch 807: val_loss did not improve from 0.14769\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1570 - sparse_categorical_accuracy: 0.9438 - val_loss: 0.1485 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 808/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1546 - sparse_categorical_accuracy: 0.9355\n",
      "Epoch 808: val_loss improved from 0.14769 to 0.14710, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.1528 - sparse_categorical_accuracy: 0.9382 - val_loss: 0.1471 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 809/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1700 - sparse_categorical_accuracy: 0.9329\n",
      "Epoch 809: val_loss did not improve from 0.14710\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1672 - sparse_categorical_accuracy: 0.9307 - val_loss: 0.1495 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 810/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1751 - sparse_categorical_accuracy: 0.9251\n",
      "Epoch 810: val_loss did not improve from 0.14710\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1751 - sparse_categorical_accuracy: 0.9251 - val_loss: 0.1483 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 811/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1624 - sparse_categorical_accuracy: 0.9306\n",
      "Epoch 811: val_loss did not improve from 0.14710\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1492 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.1482 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 812/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1576 - sparse_categorical_accuracy: 0.9310\n",
      "Epoch 812: val_loss improved from 0.14710 to 0.14570, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1555 - sparse_categorical_accuracy: 0.9307 - val_loss: 0.1457 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 813/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1562 - sparse_categorical_accuracy: 0.9509\n",
      "Epoch 813: val_loss did not improve from 0.14570\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1525 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1463 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 814/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1615 - sparse_categorical_accuracy: 0.9274\n",
      "Epoch 814: val_loss did not improve from 0.14570\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1681 - sparse_categorical_accuracy: 0.9251 - val_loss: 0.1486 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 815/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1489 - sparse_categorical_accuracy: 0.9355\n",
      "Epoch 815: val_loss did not improve from 0.14570\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1485 - sparse_categorical_accuracy: 0.9345 - val_loss: 0.1467 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 816/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1705 - sparse_categorical_accuracy: 0.9316\n",
      "Epoch 816: val_loss did not improve from 0.14570\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.1666 - sparse_categorical_accuracy: 0.9345 - val_loss: 0.1498 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 817/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1520 - sparse_categorical_accuracy: 0.9417\n",
      "Epoch 817: val_loss did not improve from 0.14570\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1499 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.1475 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 818/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1662 - sparse_categorical_accuracy: 0.9336\n",
      "Epoch 818: val_loss improved from 0.14570 to 0.14397, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1631 - sparse_categorical_accuracy: 0.9345 - val_loss: 0.1440 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 819/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1643 - sparse_categorical_accuracy: 0.9398\n",
      "Epoch 819: val_loss did not improve from 0.14397\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1580 - sparse_categorical_accuracy: 0.9438 - val_loss: 0.1443 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 820/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1795 - sparse_categorical_accuracy: 0.9196\n",
      "Epoch 820: val_loss did not improve from 0.14397\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1725 - sparse_categorical_accuracy: 0.9251 - val_loss: 0.1467 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 821/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1629 - sparse_categorical_accuracy: 0.9337\n",
      "Epoch 821: val_loss did not improve from 0.14397\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1616 - sparse_categorical_accuracy: 0.9345 - val_loss: 0.1454 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 822/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1654 - sparse_categorical_accuracy: 0.9274\n",
      "Epoch 822: val_loss did not improve from 0.14397\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1607 - sparse_categorical_accuracy: 0.9307 - val_loss: 0.1458 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 823/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1492 - sparse_categorical_accuracy: 0.9495\n",
      "Epoch 823: val_loss did not improve from 0.14397\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1533 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.1460 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 824/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1636 - sparse_categorical_accuracy: 0.9310\n",
      "Epoch 824: val_loss did not improve from 0.14397\n",
      "34/34 [==============================] - 0s 10ms/step - loss: 0.1577 - sparse_categorical_accuracy: 0.9382 - val_loss: 0.1440 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 825/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1477 - sparse_categorical_accuracy: 0.9306\n",
      "Epoch 825: val_loss did not improve from 0.14397\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1521 - sparse_categorical_accuracy: 0.9307 - val_loss: 0.1484 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 826/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1729 - sparse_categorical_accuracy: 0.9279\n",
      "Epoch 826: val_loss did not improve from 0.14397\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.1680 - sparse_categorical_accuracy: 0.9270 - val_loss: 0.1459 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 827/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1670 - sparse_categorical_accuracy: 0.9400\n",
      "Epoch 827: val_loss did not improve from 0.14397\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1602 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.1488 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 828/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1405 - sparse_categorical_accuracy: 0.9563\n",
      "Epoch 828: val_loss did not improve from 0.14397\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.1494 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1462 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 829/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1574 - sparse_categorical_accuracy: 0.9421\n",
      "Epoch 829: val_loss improved from 0.14397 to 0.14268, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.1596 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.1427 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 830/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1560 - sparse_categorical_accuracy: 0.9375\n",
      "Epoch 830: val_loss did not improve from 0.14268\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1574 - sparse_categorical_accuracy: 0.9363 - val_loss: 0.1448 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 831/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1733 - sparse_categorical_accuracy: 0.9375\n",
      "Epoch 831: val_loss did not improve from 0.14268\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1663 - sparse_categorical_accuracy: 0.9382 - val_loss: 0.1438 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 832/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1493 - sparse_categorical_accuracy: 0.9458\n",
      "Epoch 832: val_loss did not improve from 0.14268\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.1490 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.1470 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 833/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1225 - sparse_categorical_accuracy: 0.9609\n",
      "Epoch 833: val_loss did not improve from 0.14268\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1518 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.1449 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 834/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1466 - sparse_categorical_accuracy: 0.9418\n",
      "Epoch 834: val_loss improved from 0.14268 to 0.14084, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.1529 - sparse_categorical_accuracy: 0.9363 - val_loss: 0.1408 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 835/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1540 - sparse_categorical_accuracy: 0.9353\n",
      "Epoch 835: val_loss did not improve from 0.14084\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1539 - sparse_categorical_accuracy: 0.9363 - val_loss: 0.1448 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 836/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1534 - sparse_categorical_accuracy: 0.9456\n",
      "Epoch 836: val_loss did not improve from 0.14084\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1490 - sparse_categorical_accuracy: 0.9494 - val_loss: 0.1468 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 837/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1598 - sparse_categorical_accuracy: 0.9526\n",
      "Epoch 837: val_loss did not improve from 0.14084\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1561 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1435 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 838/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1454 - sparse_categorical_accuracy: 0.9625\n",
      "Epoch 838: val_loss did not improve from 0.14084\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1477 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1414 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 839/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1594 - sparse_categorical_accuracy: 0.9349\n",
      "Epoch 839: val_loss did not improve from 0.14084\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1654 - sparse_categorical_accuracy: 0.9307 - val_loss: 0.1459 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 840/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.1671 - sparse_categorical_accuracy: 0.9402\n",
      "Epoch 840: val_loss did not improve from 0.14084\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1697 - sparse_categorical_accuracy: 0.9307 - val_loss: 0.1428 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 841/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1693 - sparse_categorical_accuracy: 0.9300\n",
      "Epoch 841: val_loss did not improve from 0.14084\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1584 - sparse_categorical_accuracy: 0.9363 - val_loss: 0.1440 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 842/10000\n",
      "20/34 [================>.............] - ETA: 0s - loss: 0.1608 - sparse_categorical_accuracy: 0.9312\n",
      "Epoch 842: val_loss did not improve from 0.14084\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1519 - sparse_categorical_accuracy: 0.9345 - val_loss: 0.1431 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 843/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1531 - sparse_categorical_accuracy: 0.9569\n",
      "Epoch 843: val_loss did not improve from 0.14084\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1535 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.1426 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 844/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1483 - sparse_categorical_accuracy: 0.9483\n",
      "Epoch 844: val_loss improved from 0.14084 to 0.14081, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1442 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1408 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 845/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1663 - sparse_categorical_accuracy: 0.9395\n",
      "Epoch 845: val_loss did not improve from 0.14081\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1649 - sparse_categorical_accuracy: 0.9401 - val_loss: 0.1413 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 846/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1556 - sparse_categorical_accuracy: 0.9375\n",
      "Epoch 846: val_loss did not improve from 0.14081\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1533 - sparse_categorical_accuracy: 0.9382 - val_loss: 0.1470 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 847/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1615 - sparse_categorical_accuracy: 0.9308\n",
      "Epoch 847: val_loss improved from 0.14081 to 0.13977, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1549 - sparse_categorical_accuracy: 0.9382 - val_loss: 0.1398 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 848/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.1545 - sparse_categorical_accuracy: 0.9402\n",
      "Epoch 848: val_loss did not improve from 0.13977\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1548 - sparse_categorical_accuracy: 0.9401 - val_loss: 0.1423 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 849/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1555 - sparse_categorical_accuracy: 0.9375\n",
      "Epoch 849: val_loss did not improve from 0.13977\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1550 - sparse_categorical_accuracy: 0.9401 - val_loss: 0.1399 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 850/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1522 - sparse_categorical_accuracy: 0.9399\n",
      "Epoch 850: val_loss improved from 0.13977 to 0.13977, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1563 - sparse_categorical_accuracy: 0.9363 - val_loss: 0.1398 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 851/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1472 - sparse_categorical_accuracy: 0.9420\n",
      "Epoch 851: val_loss improved from 0.13977 to 0.13972, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1419 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.1397 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 852/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1624 - sparse_categorical_accuracy: 0.9354\n",
      "Epoch 852: val_loss did not improve from 0.13972\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1585 - sparse_categorical_accuracy: 0.9363 - val_loss: 0.1435 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 853/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1542 - sparse_categorical_accuracy: 0.9526\n",
      "Epoch 853: val_loss improved from 0.13972 to 0.13950, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1580 - sparse_categorical_accuracy: 0.9494 - val_loss: 0.1395 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 854/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1637 - sparse_categorical_accuracy: 0.9335\n",
      "Epoch 854: val_loss improved from 0.13950 to 0.13918, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1592 - sparse_categorical_accuracy: 0.9363 - val_loss: 0.1392 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 855/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1519 - sparse_categorical_accuracy: 0.9418\n",
      "Epoch 855: val_loss did not improve from 0.13918\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1525 - sparse_categorical_accuracy: 0.9401 - val_loss: 0.1406 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 856/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1654 - sparse_categorical_accuracy: 0.9289\n",
      "Epoch 856: val_loss did not improve from 0.13918\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.1679 - sparse_categorical_accuracy: 0.9288 - val_loss: 0.1419 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 857/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1454 - sparse_categorical_accuracy: 0.9525\n",
      "Epoch 857: val_loss improved from 0.13918 to 0.13841, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1471 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1384 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 858/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1458 - sparse_categorical_accuracy: 0.9418\n",
      "Epoch 858: val_loss improved from 0.13841 to 0.13722, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.1448 - sparse_categorical_accuracy: 0.9401 - val_loss: 0.1372 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 859/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1342 - sparse_categorical_accuracy: 0.9494\n",
      "Epoch 859: val_loss did not improve from 0.13722\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1342 - sparse_categorical_accuracy: 0.9494 - val_loss: 0.1374 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 860/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1605 - sparse_categorical_accuracy: 0.9375\n",
      "Epoch 860: val_loss did not improve from 0.13722\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.1560 - sparse_categorical_accuracy: 0.9401 - val_loss: 0.1375 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 861/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1438 - sparse_categorical_accuracy: 0.9375\n",
      "Epoch 861: val_loss did not improve from 0.13722\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1356 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.1436 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 862/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1689 - sparse_categorical_accuracy: 0.9261\n",
      "Epoch 862: val_loss did not improve from 0.13722\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.1676 - sparse_categorical_accuracy: 0.9270 - val_loss: 0.1404 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 863/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1622 - sparse_categorical_accuracy: 0.9420\n",
      "Epoch 863: val_loss did not improve from 0.13722\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1633 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.1391 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 864/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1473 - sparse_categorical_accuracy: 0.9491\n",
      "Epoch 864: val_loss did not improve from 0.13722\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.1449 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1374 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 865/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1438 - sparse_categorical_accuracy: 0.9434\n",
      "Epoch 865: val_loss did not improve from 0.13722\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1442 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.1380 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 866/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1761 - sparse_categorical_accuracy: 0.9316\n",
      "Epoch 866: val_loss did not improve from 0.13722\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1736 - sparse_categorical_accuracy: 0.9326 - val_loss: 0.1398 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 867/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1536 - sparse_categorical_accuracy: 0.9327\n",
      "Epoch 867: val_loss did not improve from 0.13722\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1616 - sparse_categorical_accuracy: 0.9232 - val_loss: 0.1376 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 868/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1421 - sparse_categorical_accuracy: 0.9464\n",
      "Epoch 868: val_loss did not improve from 0.13722\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1437 - sparse_categorical_accuracy: 0.9438 - val_loss: 0.1372 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 869/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1466 - sparse_categorical_accuracy: 0.9375\n",
      "Epoch 869: val_loss improved from 0.13722 to 0.13703, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1439 - sparse_categorical_accuracy: 0.9363 - val_loss: 0.1370 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 870/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1451 - sparse_categorical_accuracy: 0.9401\n",
      "Epoch 870: val_loss did not improve from 0.13703\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1451 - sparse_categorical_accuracy: 0.9401 - val_loss: 0.1456 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 871/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1530 - sparse_categorical_accuracy: 0.9456\n",
      "Epoch 871: val_loss did not improve from 0.13703\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1472 - sparse_categorical_accuracy: 0.9494 - val_loss: 0.1383 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 872/10000\n",
      "21/34 [=================>............] - ETA: 0s - loss: 0.1468 - sparse_categorical_accuracy: 0.9286\n",
      "Epoch 872: val_loss improved from 0.13703 to 0.13616, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1505 - sparse_categorical_accuracy: 0.9326 - val_loss: 0.1362 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 873/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1592 - sparse_categorical_accuracy: 0.9254\n",
      "Epoch 873: val_loss did not improve from 0.13616\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1549 - sparse_categorical_accuracy: 0.9288 - val_loss: 0.1392 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 874/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1427 - sparse_categorical_accuracy: 0.9476\n",
      "Epoch 874: val_loss did not improve from 0.13616\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.1427 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1368 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 875/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1490 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 875: val_loss did not improve from 0.13616\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1548 - sparse_categorical_accuracy: 0.9438 - val_loss: 0.1370 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 876/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.1334 - sparse_categorical_accuracy: 0.9484\n",
      "Epoch 876: val_loss did not improve from 0.13616\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1367 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1446 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 877/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1694 - sparse_categorical_accuracy: 0.9299\n",
      "Epoch 877: val_loss did not improve from 0.13616\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1676 - sparse_categorical_accuracy: 0.9307 - val_loss: 0.1378 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 878/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1324 - sparse_categorical_accuracy: 0.9551\n",
      "Epoch 878: val_loss did not improve from 0.13616\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1373 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1370 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 879/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1398 - sparse_categorical_accuracy: 0.9473\n",
      "Epoch 879: val_loss did not improve from 0.13616\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1402 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1385 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 880/10000\n",
      "22/34 [==================>...........] - ETA: 0s - loss: 0.1716 - sparse_categorical_accuracy: 0.9432\n",
      "Epoch 880: val_loss improved from 0.13616 to 0.13449, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1440 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1345 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 881/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1419 - sparse_categorical_accuracy: 0.9496\n",
      "Epoch 881: val_loss did not improve from 0.13449\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1488 - sparse_categorical_accuracy: 0.9438 - val_loss: 0.1350 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 882/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1526 - sparse_categorical_accuracy: 0.9450\n",
      "Epoch 882: val_loss did not improve from 0.13449\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1513 - sparse_categorical_accuracy: 0.9401 - val_loss: 0.1361 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 883/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1550 - sparse_categorical_accuracy: 0.9532\n",
      "Epoch 883: val_loss did not improve from 0.13449\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1550 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1360 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 884/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1288 - sparse_categorical_accuracy: 0.9531\n",
      "Epoch 884: val_loss did not improve from 0.13449\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1421 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1401 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 885/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1536 - sparse_categorical_accuracy: 0.9476\n",
      "Epoch 885: val_loss did not improve from 0.13449\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1536 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1352 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 886/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1425 - sparse_categorical_accuracy: 0.9351\n",
      "Epoch 886: val_loss did not improve from 0.13449\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1459 - sparse_categorical_accuracy: 0.9345 - val_loss: 0.1412 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 887/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1327 - sparse_categorical_accuracy: 0.9551\n",
      "Epoch 887: val_loss did not improve from 0.13449\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1305 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1358 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 888/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1485 - sparse_categorical_accuracy: 0.9375\n",
      "Epoch 888: val_loss did not improve from 0.13449\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.1465 - sparse_categorical_accuracy: 0.9363 - val_loss: 0.1364 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 889/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1474 - sparse_categorical_accuracy: 0.9471\n",
      "Epoch 889: val_loss did not improve from 0.13449\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1454 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1356 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 890/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1525 - sparse_categorical_accuracy: 0.9461\n",
      "Epoch 890: val_loss did not improve from 0.13449\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1503 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.1382 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 891/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1528 - sparse_categorical_accuracy: 0.9457\n",
      "Epoch 891: val_loss did not improve from 0.13449\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1528 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.1364 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 892/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1524 - sparse_categorical_accuracy: 0.9303\n",
      "Epoch 892: val_loss did not improve from 0.13449\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1456 - sparse_categorical_accuracy: 0.9345 - val_loss: 0.1364 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 893/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1406 - sparse_categorical_accuracy: 0.9476\n",
      "Epoch 893: val_loss improved from 0.13449 to 0.13397, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1350 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1340 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 894/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1332 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 894: val_loss did not improve from 0.13397\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1358 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1344 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 895/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1418 - sparse_categorical_accuracy: 0.9457\n",
      "Epoch 895: val_loss did not improve from 0.13397\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1418 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.1343 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 896/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1502 - sparse_categorical_accuracy: 0.9425\n",
      "Epoch 896: val_loss did not improve from 0.13397\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1402 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.1399 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 897/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1437 - sparse_categorical_accuracy: 0.9434\n",
      "Epoch 897: val_loss did not improve from 0.13397\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1406 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.1348 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 898/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1380 - sparse_categorical_accuracy: 0.9453\n",
      "Epoch 898: val_loss improved from 0.13397 to 0.13300, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1398 - sparse_categorical_accuracy: 0.9438 - val_loss: 0.1330 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 899/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1394 - sparse_categorical_accuracy: 0.9423\n",
      "Epoch 899: val_loss did not improve from 0.13300\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1340 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.1349 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 900/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1427 - sparse_categorical_accuracy: 0.9468\n",
      "Epoch 900: val_loss improved from 0.13300 to 0.13165, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1433 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.1316 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 901/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1434 - sparse_categorical_accuracy: 0.9494\n",
      "Epoch 901: val_loss did not improve from 0.13165\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1434 - sparse_categorical_accuracy: 0.9494 - val_loss: 0.1328 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 902/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1716 - sparse_categorical_accuracy: 0.9519\n",
      "Epoch 902: val_loss did not improve from 0.13165\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1610 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1369 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 903/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1313 - sparse_categorical_accuracy: 0.9575\n",
      "Epoch 903: val_loss did not improve from 0.13165\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1358 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.1367 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 904/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1320 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 904: val_loss did not improve from 0.13165\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1372 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.1330 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 905/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1476 - sparse_categorical_accuracy: 0.9419\n",
      "Epoch 905: val_loss did not improve from 0.13165\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1476 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.1333 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 906/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1487 - sparse_categorical_accuracy: 0.9432\n",
      "Epoch 906: val_loss did not improve from 0.13165\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1532 - sparse_categorical_accuracy: 0.9401 - val_loss: 0.1400 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 907/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1603 - sparse_categorical_accuracy: 0.9335\n",
      "Epoch 907: val_loss did not improve from 0.13165\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1560 - sparse_categorical_accuracy: 0.9363 - val_loss: 0.1370 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 908/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1525 - sparse_categorical_accuracy: 0.9418\n",
      "Epoch 908: val_loss did not improve from 0.13165\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1476 - sparse_categorical_accuracy: 0.9438 - val_loss: 0.1325 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 909/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1475 - sparse_categorical_accuracy: 0.9508\n",
      "Epoch 909: val_loss did not improve from 0.13165\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1463 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1363 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 910/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1555 - sparse_categorical_accuracy: 0.9419\n",
      "Epoch 910: val_loss did not improve from 0.13165\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1555 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.1329 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 911/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1404 - sparse_categorical_accuracy: 0.9577\n",
      "Epoch 911: val_loss did not improve from 0.13165\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1367 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1319 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 912/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1399 - sparse_categorical_accuracy: 0.9375\n",
      "Epoch 912: val_loss did not improve from 0.13165\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1488 - sparse_categorical_accuracy: 0.9382 - val_loss: 0.1331 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 913/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1251 - sparse_categorical_accuracy: 0.9531\n",
      "Epoch 913: val_loss did not improve from 0.13165\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1265 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1318 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 914/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1437 - sparse_categorical_accuracy: 0.9512\n",
      "Epoch 914: val_loss improved from 0.13165 to 0.13065, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1429 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1306 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 915/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1473 - sparse_categorical_accuracy: 0.9435\n",
      "Epoch 915: val_loss did not improve from 0.13065\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1436 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.1436 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 916/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1538 - sparse_categorical_accuracy: 0.9420\n",
      "Epoch 916: val_loss improved from 0.13065 to 0.12950, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1453 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1295 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 917/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1582 - sparse_categorical_accuracy: 0.9246\n",
      "Epoch 917: val_loss did not improve from 0.12950\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1527 - sparse_categorical_accuracy: 0.9270 - val_loss: 0.1323 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 918/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1403 - sparse_categorical_accuracy: 0.9521\n",
      "Epoch 918: val_loss did not improve from 0.12950\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1392 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1322 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 919/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1382 - sparse_categorical_accuracy: 0.9532\n",
      "Epoch 919: val_loss did not improve from 0.12950\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1382 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1306 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 920/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1567 - sparse_categorical_accuracy: 0.9382\n",
      "Epoch 920: val_loss improved from 0.12950 to 0.12931, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1567 - sparse_categorical_accuracy: 0.9382 - val_loss: 0.1293 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 921/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1366 - sparse_categorical_accuracy: 0.9554\n",
      "Epoch 921: val_loss did not improve from 0.12931\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1432 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1308 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 922/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1338 - sparse_categorical_accuracy: 0.9526\n",
      "Epoch 922: val_loss did not improve from 0.12931\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1316 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.1357 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 923/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1433 - sparse_categorical_accuracy: 0.9423\n",
      "Epoch 923: val_loss did not improve from 0.12931\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1437 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.1309 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 924/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1350 - sparse_categorical_accuracy: 0.9618\n",
      "Epoch 924: val_loss improved from 0.12931 to 0.12922, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1431 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1292 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 925/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1355 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 925: val_loss did not improve from 0.12922\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1397 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1351 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 926/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1388 - sparse_categorical_accuracy: 0.9419\n",
      "Epoch 926: val_loss did not improve from 0.12922\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1388 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.1307 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 927/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1222 - sparse_categorical_accuracy: 0.9609\n",
      "Epoch 927: val_loss did not improve from 0.12922\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1350 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1296 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 928/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1426 - sparse_categorical_accuracy: 0.9458\n",
      "Epoch 928: val_loss did not improve from 0.12922\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1488 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.1356 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 929/10000\n",
      "19/34 [===============>..............] - ETA: 0s - loss: 0.1121 - sparse_categorical_accuracy: 0.9704\n",
      "Epoch 929: val_loss improved from 0.12922 to 0.12890, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1241 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.1289 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 930/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1408 - sparse_categorical_accuracy: 0.9554\n",
      "Epoch 930: val_loss improved from 0.12890 to 0.12725, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1494 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1272 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 931/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1422 - sparse_categorical_accuracy: 0.9531\n",
      "Epoch 931: val_loss did not improve from 0.12725\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1435 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1371 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 932/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1465 - sparse_categorical_accuracy: 0.9491\n",
      "Epoch 932: val_loss did not improve from 0.12725\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1511 - sparse_categorical_accuracy: 0.9438 - val_loss: 0.1305 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 933/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1447 - sparse_categorical_accuracy: 0.9415\n",
      "Epoch 933: val_loss did not improve from 0.12725\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1452 - sparse_categorical_accuracy: 0.9438 - val_loss: 0.1326 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 934/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1394 - sparse_categorical_accuracy: 0.9516\n",
      "Epoch 934: val_loss did not improve from 0.12725\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1415 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.1293 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 935/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1404 - sparse_categorical_accuracy: 0.9483\n",
      "Epoch 935: val_loss did not improve from 0.12725\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1384 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1365 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 936/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1381 - sparse_categorical_accuracy: 0.9479\n",
      "Epoch 936: val_loss improved from 0.12725 to 0.12666, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1268 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1267 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 937/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1427 - sparse_categorical_accuracy: 0.9375\n",
      "Epoch 937: val_loss did not improve from 0.12666\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1485 - sparse_categorical_accuracy: 0.9326 - val_loss: 0.1326 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 938/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1542 - sparse_categorical_accuracy: 0.9492\n",
      "Epoch 938: val_loss did not improve from 0.12666\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1531 - sparse_categorical_accuracy: 0.9494 - val_loss: 0.1295 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 939/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1398 - sparse_categorical_accuracy: 0.9554\n",
      "Epoch 939: val_loss did not improve from 0.12666\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1354 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1275 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 940/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1300 - sparse_categorical_accuracy: 0.9569\n",
      "Epoch 940: val_loss did not improve from 0.12666\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1300 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1407 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 941/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1279 - sparse_categorical_accuracy: 0.9527\n",
      "Epoch 941: val_loss did not improve from 0.12666\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1302 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1295 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 942/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1498 - sparse_categorical_accuracy: 0.9440\n",
      "Epoch 942: val_loss did not improve from 0.12666\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1506 - sparse_categorical_accuracy: 0.9438 - val_loss: 0.1287 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 943/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1370 - sparse_categorical_accuracy: 0.9576\n",
      "Epoch 943: val_loss did not improve from 0.12666\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1400 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1337 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 944/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1419 - sparse_categorical_accuracy: 0.9577\n",
      "Epoch 944: val_loss did not improve from 0.12666\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1387 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1282 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 945/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1393 - sparse_categorical_accuracy: 0.9337\n",
      "Epoch 945: val_loss did not improve from 0.12666\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1392 - sparse_categorical_accuracy: 0.9345 - val_loss: 0.1289 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 946/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1285 - sparse_categorical_accuracy: 0.9525\n",
      "Epoch 946: val_loss did not improve from 0.12666\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1299 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1282 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 947/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1605 - sparse_categorical_accuracy: 0.9375\n",
      "Epoch 947: val_loss improved from 0.12666 to 0.12535, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1365 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1254 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 948/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1370 - sparse_categorical_accuracy: 0.9487\n",
      "Epoch 948: val_loss did not improve from 0.12535\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1391 - sparse_categorical_accuracy: 0.9438 - val_loss: 0.1280 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 949/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1494 - sparse_categorical_accuracy: 0.9375\n",
      "Epoch 949: val_loss did not improve from 0.12535\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1473 - sparse_categorical_accuracy: 0.9363 - val_loss: 0.1268 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 950/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1278 - sparse_categorical_accuracy: 0.9476\n",
      "Epoch 950: val_loss did not improve from 0.12535\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1265 - sparse_categorical_accuracy: 0.9494 - val_loss: 0.1269 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 951/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1319 - sparse_categorical_accuracy: 0.9532\n",
      "Epoch 951: val_loss improved from 0.12535 to 0.12508, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.1319 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1251 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 952/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1503 - sparse_categorical_accuracy: 0.9494\n",
      "Epoch 952: val_loss did not improve from 0.12508\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1503 - sparse_categorical_accuracy: 0.9494 - val_loss: 0.1315 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 953/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1252 - sparse_categorical_accuracy: 0.9531\n",
      "Epoch 953: val_loss improved from 0.12508 to 0.12402, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 14ms/step - loss: 0.1286 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1240 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 954/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1413 - sparse_categorical_accuracy: 0.9375\n",
      "Epoch 954: val_loss did not improve from 0.12402\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1398 - sparse_categorical_accuracy: 0.9382 - val_loss: 0.1245 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 955/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1344 - sparse_categorical_accuracy: 0.9451\n",
      "Epoch 955: val_loss did not improve from 0.12402\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1348 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.1264 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 956/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1388 - sparse_categorical_accuracy: 0.9399\n",
      "Epoch 956: val_loss did not improve from 0.12402\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1374 - sparse_categorical_accuracy: 0.9438 - val_loss: 0.1245 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 957/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1356 - sparse_categorical_accuracy: 0.9453\n",
      "Epoch 957: val_loss did not improve from 0.12402\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1338 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1255 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 958/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1416 - sparse_categorical_accuracy: 0.9483\n",
      "Epoch 958: val_loss did not improve from 0.12402\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1470 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.1270 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 959/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1301 - sparse_categorical_accuracy: 0.9494\n",
      "Epoch 959: val_loss improved from 0.12402 to 0.12322, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1301 - sparse_categorical_accuracy: 0.9494 - val_loss: 0.1232 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 960/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1383 - sparse_categorical_accuracy: 0.9458\n",
      "Epoch 960: val_loss did not improve from 0.12322\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.1315 - sparse_categorical_accuracy: 0.9494 - val_loss: 0.1250 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 961/10000\n",
      "22/34 [==================>...........] - ETA: 0s - loss: 0.1370 - sparse_categorical_accuracy: 0.9375\n",
      "Epoch 961: val_loss did not improve from 0.12322\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1316 - sparse_categorical_accuracy: 0.9382 - val_loss: 0.1290 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 962/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1297 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 962: val_loss did not improve from 0.12322\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1415 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1268 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 963/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.1400 - sparse_categorical_accuracy: 0.9565\n",
      "Epoch 963: val_loss did not improve from 0.12322\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1385 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1241 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 964/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1355 - sparse_categorical_accuracy: 0.9551\n",
      "Epoch 964: val_loss improved from 0.12322 to 0.12319, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1312 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1232 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 965/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1335 - sparse_categorical_accuracy: 0.9427\n",
      "Epoch 965: val_loss improved from 0.12319 to 0.12291, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1271 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1229 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 966/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1449 - sparse_categorical_accuracy: 0.9513\n",
      "Epoch 966: val_loss did not improve from 0.12291\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1449 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1235 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 967/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1514 - sparse_categorical_accuracy: 0.9419\n",
      "Epoch 967: val_loss did not improve from 0.12291\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1514 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.1292 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 968/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1474 - sparse_categorical_accuracy: 0.9238\n",
      "Epoch 968: val_loss improved from 0.12291 to 0.12175, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1475 - sparse_categorical_accuracy: 0.9251 - val_loss: 0.1218 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 969/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1374 - sparse_categorical_accuracy: 0.9504\n",
      "Epoch 969: val_loss did not improve from 0.12175\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1350 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1240 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 970/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1570 - sparse_categorical_accuracy: 0.9420\n",
      "Epoch 970: val_loss did not improve from 0.12175\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1474 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1259 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 971/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1357 - sparse_categorical_accuracy: 0.9476\n",
      "Epoch 971: val_loss did not improve from 0.12175\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1357 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1218 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 972/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1319 - sparse_categorical_accuracy: 0.9508\n",
      "Epoch 972: val_loss did not improve from 0.12175\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1314 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1246 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 973/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1390 - sparse_categorical_accuracy: 0.9516\n",
      "Epoch 973: val_loss did not improve from 0.12175\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1379 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1234 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 974/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1370 - sparse_categorical_accuracy: 0.9570\n",
      "Epoch 974: val_loss did not improve from 0.12175\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1381 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1218 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 975/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1449 - sparse_categorical_accuracy: 0.9495\n",
      "Epoch 975: val_loss did not improve from 0.12175\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1361 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1253 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 976/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1297 - sparse_categorical_accuracy: 0.9606\n",
      "Epoch 976: val_loss did not improve from 0.12175\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1293 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1218 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 977/10000\n",
      "21/34 [=================>............] - ETA: 0s - loss: 0.1272 - sparse_categorical_accuracy: 0.9494\n",
      "Epoch 977: val_loss did not improve from 0.12175\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1292 - sparse_categorical_accuracy: 0.9494 - val_loss: 0.1334 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 978/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1512 - sparse_categorical_accuracy: 0.9419\n",
      "Epoch 978: val_loss did not improve from 0.12175\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1512 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.1254 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 979/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1336 - sparse_categorical_accuracy: 0.9525\n",
      "Epoch 979: val_loss did not improve from 0.12175\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1319 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1220 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 980/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1298 - sparse_categorical_accuracy: 0.9471\n",
      "Epoch 980: val_loss did not improve from 0.12175\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1315 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.1304 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 981/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1442 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 981: val_loss did not improve from 0.12175\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1370 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1241 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 982/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1332 - sparse_categorical_accuracy: 0.9644\n",
      "Epoch 982: val_loss did not improve from 0.12175\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1332 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1255 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 983/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.1218 - sparse_categorical_accuracy: 0.9565\n",
      "Epoch 983: val_loss improved from 0.12175 to 0.12111, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1364 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1211 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 984/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1499 - sparse_categorical_accuracy: 0.9399\n",
      "Epoch 984: val_loss did not improve from 0.12111\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1511 - sparse_categorical_accuracy: 0.9382 - val_loss: 0.1214 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 985/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.1335 - sparse_categorical_accuracy: 0.9511\n",
      "Epoch 985: val_loss improved from 0.12111 to 0.12064, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1326 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.1206 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 986/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1226 - sparse_categorical_accuracy: 0.9618\n",
      "Epoch 986: val_loss did not improve from 0.12064\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1310 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1213 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 987/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1422 - sparse_categorical_accuracy: 0.9476\n",
      "Epoch 987: val_loss improved from 0.12064 to 0.12016, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1342 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1202 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 988/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1427 - sparse_categorical_accuracy: 0.9508\n",
      "Epoch 988: val_loss did not improve from 0.12016\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1420 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1284 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 989/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1217 - sparse_categorical_accuracy: 0.9625\n",
      "Epoch 989: val_loss did not improve from 0.12016\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1217 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.1232 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 990/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1488 - sparse_categorical_accuracy: 0.9352\n",
      "Epoch 990: val_loss did not improve from 0.12016\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1368 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.1236 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 991/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1381 - sparse_categorical_accuracy: 0.9457\n",
      "Epoch 991: val_loss did not improve from 0.12016\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1381 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.1247 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 992/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1179 - sparse_categorical_accuracy: 0.9688\n",
      "Epoch 992: val_loss did not improve from 0.12016\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1226 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1248 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 993/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1435 - sparse_categorical_accuracy: 0.9432\n",
      "Epoch 993: val_loss improved from 0.12016 to 0.11955, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1421 - sparse_categorical_accuracy: 0.9438 - val_loss: 0.1195 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 994/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1222 - sparse_categorical_accuracy: 0.9618\n",
      "Epoch 994: val_loss did not improve from 0.11955\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1333 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1241 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 995/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1118 - sparse_categorical_accuracy: 0.9639\n",
      "Epoch 995: val_loss did not improve from 0.11955\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1252 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1260 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 996/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1312 - sparse_categorical_accuracy: 0.9444\n",
      "Epoch 996: val_loss did not improve from 0.11955\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1271 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1267 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 997/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1297 - sparse_categorical_accuracy: 0.9531\n",
      "Epoch 997: val_loss did not improve from 0.11955\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1270 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.1216 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 998/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1579 - sparse_categorical_accuracy: 0.9491\n",
      "Epoch 998: val_loss did not improve from 0.11955\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1454 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.1266 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 999/10000\n",
      "22/34 [==================>...........] - ETA: 0s - loss: 0.1202 - sparse_categorical_accuracy: 0.9659\n",
      "Epoch 999: val_loss did not improve from 0.11955\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1256 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.1204 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1000/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1386 - sparse_categorical_accuracy: 0.9549\n",
      "Epoch 1000: val_loss improved from 0.11955 to 0.11908, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1352 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.1191 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1001/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1398 - sparse_categorical_accuracy: 0.9525\n",
      "Epoch 1001: val_loss improved from 0.11908 to 0.11889, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1328 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.1189 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1002/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1393 - sparse_categorical_accuracy: 0.9487\n",
      "Epoch 1002: val_loss did not improve from 0.11889\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1331 - sparse_categorical_accuracy: 0.9494 - val_loss: 0.1255 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1003/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1356 - sparse_categorical_accuracy: 0.9525\n",
      "Epoch 1003: val_loss did not improve from 0.11889\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1371 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1277 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1004/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1412 - sparse_categorical_accuracy: 0.9527\n",
      "Epoch 1004: val_loss did not improve from 0.11889\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1410 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1210 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1005/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1179 - sparse_categorical_accuracy: 0.9531\n",
      "Epoch 1005: val_loss did not improve from 0.11889\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1287 - sparse_categorical_accuracy: 0.9494 - val_loss: 0.1218 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1006/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1369 - sparse_categorical_accuracy: 0.9375\n",
      "Epoch 1006: val_loss did not improve from 0.11889\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1286 - sparse_categorical_accuracy: 0.9494 - val_loss: 0.1219 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1007/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1333 - sparse_categorical_accuracy: 0.9551\n",
      "Epoch 1007: val_loss improved from 0.11889 to 0.11873, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1333 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.1187 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1008/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1442 - sparse_categorical_accuracy: 0.9336\n",
      "Epoch 1008: val_loss did not improve from 0.11873\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1420 - sparse_categorical_accuracy: 0.9363 - val_loss: 0.1235 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1009/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1404 - sparse_categorical_accuracy: 0.9444\n",
      "Epoch 1009: val_loss did not improve from 0.11873\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1364 - sparse_categorical_accuracy: 0.9494 - val_loss: 0.1247 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1010/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1355 - sparse_categorical_accuracy: 0.9514\n",
      "Epoch 1010: val_loss did not improve from 0.11873\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1417 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1204 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1011/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1285 - sparse_categorical_accuracy: 0.9551\n",
      "Epoch 1011: val_loss did not improve from 0.11873\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1285 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.1214 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1012/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1362 - sparse_categorical_accuracy: 0.9444\n",
      "Epoch 1012: val_loss did not improve from 0.11873\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1287 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1283 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 1013/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1290 - sparse_categorical_accuracy: 0.9509\n",
      "Epoch 1013: val_loss did not improve from 0.11873\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1356 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1190 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1014/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1433 - sparse_categorical_accuracy: 0.9479\n",
      "Epoch 1014: val_loss did not improve from 0.11873\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1401 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.1210 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1015/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1224 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 1015: val_loss improved from 0.11873 to 0.11649, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1216 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.1165 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1016/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1292 - sparse_categorical_accuracy: 0.9609\n",
      "Epoch 1016: val_loss did not improve from 0.11649\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1464 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.1234 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1017/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1321 - sparse_categorical_accuracy: 0.9494\n",
      "Epoch 1017: val_loss did not improve from 0.11649\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1321 - sparse_categorical_accuracy: 0.9494 - val_loss: 0.1182 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1018/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1315 - sparse_categorical_accuracy: 0.9521\n",
      "Epoch 1018: val_loss did not improve from 0.11649\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1392 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.1207 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1019/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1380 - sparse_categorical_accuracy: 0.9476\n",
      "Epoch 1019: val_loss did not improve from 0.11649\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1339 - sparse_categorical_accuracy: 0.9494 - val_loss: 0.1241 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 1020/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1172 - sparse_categorical_accuracy: 0.9659\n",
      "Epoch 1020: val_loss improved from 0.11649 to 0.11620, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1169 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.1162 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1021/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1261 - sparse_categorical_accuracy: 0.9682\n",
      "Epoch 1021: val_loss did not improve from 0.11620\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1261 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1237 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1022/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1231 - sparse_categorical_accuracy: 0.9513\n",
      "Epoch 1022: val_loss did not improve from 0.11620\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1231 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1220 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1023/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1198 - sparse_categorical_accuracy: 0.9542\n",
      "Epoch 1023: val_loss did not improve from 0.11620\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1295 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1178 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1024/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1249 - sparse_categorical_accuracy: 0.9532\n",
      "Epoch 1024: val_loss did not improve from 0.11620\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1249 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1212 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1025/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1212 - sparse_categorical_accuracy: 0.9569\n",
      "Epoch 1025: val_loss did not improve from 0.11620\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1212 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1206 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1026/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1286 - sparse_categorical_accuracy: 0.9464\n",
      "Epoch 1026: val_loss did not improve from 0.11620\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1238 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1211 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1027/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1188 - sparse_categorical_accuracy: 0.9618\n",
      "Epoch 1027: val_loss did not improve from 0.11620\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1279 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.1172 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1028/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1390 - sparse_categorical_accuracy: 0.9397\n",
      "Epoch 1028: val_loss did not improve from 0.11620\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1339 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.1209 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1029/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1440 - sparse_categorical_accuracy: 0.9413\n",
      "Epoch 1029: val_loss did not improve from 0.11620\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1435 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.1180 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1030/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1238 - sparse_categorical_accuracy: 0.9519\n",
      "Epoch 1030: val_loss did not improve from 0.11620\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1342 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1176 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1031/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1235 - sparse_categorical_accuracy: 0.9509\n",
      "Epoch 1031: val_loss did not improve from 0.11620\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1261 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.1221 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1032/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1333 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 1032: val_loss did not improve from 0.11620\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1279 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.1192 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1033/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1178 - sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1033: val_loss did not improve from 0.11620\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1174 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.1175 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1034/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1204 - sparse_categorical_accuracy: 0.9453\n",
      "Epoch 1034: val_loss did not improve from 0.11620\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1246 - sparse_categorical_accuracy: 0.9494 - val_loss: 0.1257 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 1035/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1177 - sparse_categorical_accuracy: 0.9606\n",
      "Epoch 1035: val_loss did not improve from 0.11620\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1188 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1178 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1036/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1492 - sparse_categorical_accuracy: 0.9300\n",
      "Epoch 1036: val_loss did not improve from 0.11620\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1350 - sparse_categorical_accuracy: 0.9345 - val_loss: 0.1236 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1037/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1303 - sparse_categorical_accuracy: 0.9492\n",
      "Epoch 1037: val_loss improved from 0.11620 to 0.11611, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1298 - sparse_categorical_accuracy: 0.9494 - val_loss: 0.1161 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1038/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.1249 - sparse_categorical_accuracy: 0.9457\n",
      "Epoch 1038: val_loss did not improve from 0.11611\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1282 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.1283 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 1039/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1344 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 1039: val_loss improved from 0.11611 to 0.11546, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1251 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.1155 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1040/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1095 - sparse_categorical_accuracy: 0.9615\n",
      "Epoch 1040: val_loss did not improve from 0.11546\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1149 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.1194 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1041/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1393 - sparse_categorical_accuracy: 0.9494\n",
      "Epoch 1041: val_loss did not improve from 0.11546\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1393 - sparse_categorical_accuracy: 0.9494 - val_loss: 0.1223 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1042/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1200 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 1042: val_loss did not improve from 0.11546\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1255 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1190 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1043/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1402 - sparse_categorical_accuracy: 0.9479\n",
      "Epoch 1043: val_loss did not improve from 0.11546\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1241 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1165 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1044/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1271 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 1044: val_loss did not improve from 0.11546\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1325 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1183 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1045/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1397 - sparse_categorical_accuracy: 0.9470\n",
      "Epoch 1045: val_loss did not improve from 0.11546\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1393 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1170 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1046/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1217 - sparse_categorical_accuracy: 0.9712\n",
      "Epoch 1046: val_loss did not improve from 0.11546\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1106 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.1218 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1047/10000\n",
      "17/34 [==============>...............] - ETA: 0s - loss: 0.1431 - sparse_categorical_accuracy: 0.9522\n",
      "Epoch 1047: val_loss did not improve from 0.11546\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1405 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.1167 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1048/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1172 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 1048: val_loss did not improve from 0.11546\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1352 - sparse_categorical_accuracy: 0.9401 - val_loss: 0.1208 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1049/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1221 - sparse_categorical_accuracy: 0.9444\n",
      "Epoch 1049: val_loss did not improve from 0.11546\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1237 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1215 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1050/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1206 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 1050: val_loss did not improve from 0.11546\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1252 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.1170 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1051/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1222 - sparse_categorical_accuracy: 0.9513\n",
      "Epoch 1051: val_loss did not improve from 0.11546\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1222 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1231 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1052/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1177 - sparse_categorical_accuracy: 0.9609\n",
      "Epoch 1052: val_loss did not improve from 0.11546\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1168 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.1287 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 1053/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1277 - sparse_categorical_accuracy: 0.9655\n",
      "Epoch 1053: val_loss did not improve from 0.11546\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1246 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1194 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1054/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1185 - sparse_categorical_accuracy: 0.9525\n",
      "Epoch 1054: val_loss did not improve from 0.11546\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1144 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.1158 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1055/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1403 - sparse_categorical_accuracy: 0.9468\n",
      "Epoch 1055: val_loss improved from 0.11546 to 0.11434, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1336 - sparse_categorical_accuracy: 0.9494 - val_loss: 0.1143 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1056/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.1374 - sparse_categorical_accuracy: 0.9429\n",
      "Epoch 1056: val_loss did not improve from 0.11434\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1334 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1154 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1057/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1195 - sparse_categorical_accuracy: 0.9602\n",
      "Epoch 1057: val_loss did not improve from 0.11434\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1186 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1147 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1058/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1314 - sparse_categorical_accuracy: 0.9473\n",
      "Epoch 1058: val_loss did not improve from 0.11434\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1289 - sparse_categorical_accuracy: 0.9494 - val_loss: 0.1156 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1059/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1359 - sparse_categorical_accuracy: 0.9532\n",
      "Epoch 1059: val_loss did not improve from 0.11434\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1359 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1218 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1060/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1229 - sparse_categorical_accuracy: 0.9494\n",
      "Epoch 1060: val_loss did not improve from 0.11434\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1229 - sparse_categorical_accuracy: 0.9494 - val_loss: 0.1155 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1061/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1083 - sparse_categorical_accuracy: 0.9643\n",
      "Epoch 1061: val_loss did not improve from 0.11434\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1167 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1173 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1062/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1135 - sparse_categorical_accuracy: 0.9513\n",
      "Epoch 1062: val_loss did not improve from 0.11434\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1135 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1145 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1063/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1121 - sparse_categorical_accuracy: 0.9648\n",
      "Epoch 1063: val_loss did not improve from 0.11434\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1132 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1257 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 1064/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1457 - sparse_categorical_accuracy: 0.9353\n",
      "Epoch 1064: val_loss did not improve from 0.11434\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1382 - sparse_categorical_accuracy: 0.9382 - val_loss: 0.1185 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1065/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1159 - sparse_categorical_accuracy: 0.9635\n",
      "Epoch 1065: val_loss did not improve from 0.11434\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1219 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.1181 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1066/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1253 - sparse_categorical_accuracy: 0.9479\n",
      "Epoch 1066: val_loss did not improve from 0.11434\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1314 - sparse_categorical_accuracy: 0.9494 - val_loss: 0.1223 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 1067/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1275 - sparse_categorical_accuracy: 0.9505\n",
      "Epoch 1067: val_loss did not improve from 0.11434\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1255 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1225 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1068/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1269 - sparse_categorical_accuracy: 0.9531\n",
      "Epoch 1068: val_loss did not improve from 0.11434\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1254 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1176 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1069/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1169 - sparse_categorical_accuracy: 0.9604\n",
      "Epoch 1069: val_loss did not improve from 0.11434\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1192 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1182 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1070/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1250 - sparse_categorical_accuracy: 0.9564\n",
      "Epoch 1070: val_loss did not improve from 0.11434\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1248 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1147 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1071/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1089 - sparse_categorical_accuracy: 0.9547\n",
      "Epoch 1071: val_loss did not improve from 0.11434\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1125 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1166 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1072/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1270 - sparse_categorical_accuracy: 0.9489\n",
      "Epoch 1072: val_loss improved from 0.11434 to 0.11281, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1258 - sparse_categorical_accuracy: 0.9494 - val_loss: 0.1128 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1073/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1137 - sparse_categorical_accuracy: 0.9588\n",
      "Epoch 1073: val_loss did not improve from 0.11281\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1137 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.1149 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1074/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1253 - sparse_categorical_accuracy: 0.9542\n",
      "Epoch 1074: val_loss did not improve from 0.11281\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1282 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1142 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1075/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1313 - sparse_categorical_accuracy: 0.9401\n",
      "Epoch 1075: val_loss did not improve from 0.11281\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1313 - sparse_categorical_accuracy: 0.9401 - val_loss: 0.1143 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1076/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1203 - sparse_categorical_accuracy: 0.9621\n",
      "Epoch 1076: val_loss did not improve from 0.11281\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1194 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.1141 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1077/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.1284 - sparse_categorical_accuracy: 0.9511\n",
      "Epoch 1077: val_loss did not improve from 0.11281\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1223 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1204 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 1078/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1366 - sparse_categorical_accuracy: 0.9444\n",
      "Epoch 1078: val_loss improved from 0.11281 to 0.11255, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1311 - sparse_categorical_accuracy: 0.9494 - val_loss: 0.1126 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1079/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1298 - sparse_categorical_accuracy: 0.9476\n",
      "Epoch 1079: val_loss did not improve from 0.11255\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1298 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1147 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1080/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1324 - sparse_categorical_accuracy: 0.9494\n",
      "Epoch 1080: val_loss did not improve from 0.11255\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1324 - sparse_categorical_accuracy: 0.9494 - val_loss: 0.1308 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 1081/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1303 - sparse_categorical_accuracy: 0.9560\n",
      "Epoch 1081: val_loss did not improve from 0.11255\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1275 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1130 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1082/10000\n",
      "19/34 [===============>..............] - ETA: 0s - loss: 0.1356 - sparse_categorical_accuracy: 0.9441\n",
      "Epoch 1082: val_loss did not improve from 0.11255\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1331 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1135 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1083/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1245 - sparse_categorical_accuracy: 0.9588\n",
      "Epoch 1083: val_loss did not improve from 0.11255\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1245 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.1171 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1084/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1208 - sparse_categorical_accuracy: 0.9588\n",
      "Epoch 1084: val_loss did not improve from 0.11255\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1208 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.1217 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 1085/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1183 - sparse_categorical_accuracy: 0.9537\n",
      "Epoch 1085: val_loss did not improve from 0.11255\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1275 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1174 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1086/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1245 - sparse_categorical_accuracy: 0.9621\n",
      "Epoch 1086: val_loss improved from 0.11255 to 0.11246, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1241 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.1125 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1087/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1273 - sparse_categorical_accuracy: 0.9567\n",
      "Epoch 1087: val_loss did not improve from 0.11246\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1275 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1127 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1088/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1047 - sparse_categorical_accuracy: 0.9625\n",
      "Epoch 1088: val_loss did not improve from 0.11246\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1127 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.1141 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1089/10000\n",
      "21/34 [=================>............] - ETA: 0s - loss: 0.1264 - sparse_categorical_accuracy: 0.9464\n",
      "Epoch 1089: val_loss did not improve from 0.11246\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1298 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1130 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1090/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1223 - sparse_categorical_accuracy: 0.9598\n",
      "Epoch 1090: val_loss did not improve from 0.11246\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1177 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1163 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1091/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1276 - sparse_categorical_accuracy: 0.9519\n",
      "Epoch 1091: val_loss did not improve from 0.11246\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1288 - sparse_categorical_accuracy: 0.9438 - val_loss: 0.1138 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1092/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1192 - sparse_categorical_accuracy: 0.9513\n",
      "Epoch 1092: val_loss did not improve from 0.11246\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1192 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1158 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1093/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.1361 - sparse_categorical_accuracy: 0.9538\n",
      "Epoch 1093: val_loss did not improve from 0.11246\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1287 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1128 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1094/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1275 - sparse_categorical_accuracy: 0.9444\n",
      "Epoch 1094: val_loss did not improve from 0.11246\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1312 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.1126 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1095/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1126 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 1095: val_loss improved from 0.11246 to 0.11086, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1183 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1109 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1096/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1360 - sparse_categorical_accuracy: 0.9421\n",
      "Epoch 1096: val_loss did not improve from 0.11086\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1333 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.1142 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1097/10000\n",
      "20/34 [================>.............] - ETA: 0s - loss: 0.1075 - sparse_categorical_accuracy: 0.9563\n",
      "Epoch 1097: val_loss did not improve from 0.11086\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1198 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.1127 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1098/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1346 - sparse_categorical_accuracy: 0.9470\n",
      "Epoch 1098: val_loss did not improve from 0.11086\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1337 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1134 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1099/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1155 - sparse_categorical_accuracy: 0.9569\n",
      "Epoch 1099: val_loss did not improve from 0.11086\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1155 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1197 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1100/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1277 - sparse_categorical_accuracy: 0.9547\n",
      "Epoch 1100: val_loss did not improve from 0.11086\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1226 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1135 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1101/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1211 - sparse_categorical_accuracy: 0.9551\n",
      "Epoch 1101: val_loss did not improve from 0.11086\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1211 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.1142 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1102/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1189 - sparse_categorical_accuracy: 0.9567\n",
      "Epoch 1102: val_loss did not improve from 0.11086\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1176 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1243 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 1103/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1153 - sparse_categorical_accuracy: 0.9618\n",
      "Epoch 1103: val_loss did not improve from 0.11086\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1123 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.1116 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1104/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1194 - sparse_categorical_accuracy: 0.9468\n",
      "Epoch 1104: val_loss did not improve from 0.11086\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1225 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1301 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 1105/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1479 - sparse_categorical_accuracy: 0.9444\n",
      "Epoch 1105: val_loss did not improve from 0.11086\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1242 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.1156 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1106/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1170 - sparse_categorical_accuracy: 0.9653\n",
      "Epoch 1106: val_loss did not improve from 0.11086\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1161 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.1124 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1107/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1235 - sparse_categorical_accuracy: 0.9444\n",
      "Epoch 1107: val_loss did not improve from 0.11086\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1078 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.1123 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1108/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1049 - sparse_categorical_accuracy: 0.9630\n",
      "Epoch 1108: val_loss did not improve from 0.11086\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1073 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.1141 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1109/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1233 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 1109: val_loss did not improve from 0.11086\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1252 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1130 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1110/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1364 - sparse_categorical_accuracy: 0.9447\n",
      "Epoch 1110: val_loss did not improve from 0.11086\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1250 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1121 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1111/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1193 - sparse_categorical_accuracy: 0.9551\n",
      "Epoch 1111: val_loss did not improve from 0.11086\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1193 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.1118 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1112/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.1200 - sparse_categorical_accuracy: 0.9620\n",
      "Epoch 1112: val_loss did not improve from 0.11086\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1195 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.1121 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1113/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1261 - sparse_categorical_accuracy: 0.9513\n",
      "Epoch 1113: val_loss did not improve from 0.11086\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1261 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1210 - val_sparse_categorical_accuracy: 0.9494\n",
      "Epoch 1114/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1224 - sparse_categorical_accuracy: 0.9505\n",
      "Epoch 1114: val_loss improved from 0.11086 to 0.11085, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1227 - sparse_categorical_accuracy: 0.9494 - val_loss: 0.1108 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1115/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1288 - sparse_categorical_accuracy: 0.9487\n",
      "Epoch 1115: val_loss did not improve from 0.11085\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1318 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1113 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1116/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1311 - sparse_categorical_accuracy: 0.9492\n",
      "Epoch 1116: val_loss did not improve from 0.11085\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1281 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1109 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1117/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1214 - sparse_categorical_accuracy: 0.9537\n",
      "Epoch 1117: val_loss did not improve from 0.11085\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1268 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.1178 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1118/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1234 - sparse_categorical_accuracy: 0.9531\n",
      "Epoch 1118: val_loss did not improve from 0.11085\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1215 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.1154 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1119/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.1182 - sparse_categorical_accuracy: 0.9592\n",
      "Epoch 1119: val_loss improved from 0.11085 to 0.10993, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1161 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.1099 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1120/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1379 - sparse_categorical_accuracy: 0.9569\n",
      "Epoch 1120: val_loss did not improve from 0.10993\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1379 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1167 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1121/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1154 - sparse_categorical_accuracy: 0.9598\n",
      "Epoch 1121: val_loss did not improve from 0.10993\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1176 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1154 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1122/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1091 - sparse_categorical_accuracy: 0.9602\n",
      "Epoch 1122: val_loss did not improve from 0.10993\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1098 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1111 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1123/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1159 - sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1123: val_loss did not improve from 0.10993\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1159 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1156 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1124/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1085 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 1124: val_loss did not improve from 0.10993\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1020 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1129 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1125/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1123 - sparse_categorical_accuracy: 0.9569\n",
      "Epoch 1125: val_loss did not improve from 0.10993\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1123 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1106 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1126/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1370 - sparse_categorical_accuracy: 0.9531\n",
      "Epoch 1126: val_loss did not improve from 0.10993\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1232 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1137 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1127/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1439 - sparse_categorical_accuracy: 0.9470\n",
      "Epoch 1127: val_loss did not improve from 0.10993\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1434 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1138 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1128/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1197 - sparse_categorical_accuracy: 0.9615\n",
      "Epoch 1128: val_loss did not improve from 0.10993\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1276 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1124 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1129/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1322 - sparse_categorical_accuracy: 0.9397\n",
      "Epoch 1129: val_loss improved from 0.10993 to 0.10940, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 0.1272 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.1094 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1130/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1278 - sparse_categorical_accuracy: 0.9560\n",
      "Epoch 1130: val_loss did not improve from 0.10940\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1240 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1116 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1131/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1102 - sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1131: val_loss improved from 0.10940 to 0.10921, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1102 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.1092 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1132/10000\n",
      "22/34 [==================>...........] - ETA: 0s - loss: 0.1092 - sparse_categorical_accuracy: 0.9716\n",
      "Epoch 1132: val_loss did not improve from 0.10921\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1207 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1133 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1133/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1102 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 1133: val_loss improved from 0.10921 to 0.10877, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1162 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1088 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1134/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1087 - sparse_categorical_accuracy: 0.9577\n",
      "Epoch 1134: val_loss improved from 0.10877 to 0.10870, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1047 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1087 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1135/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1061 - sparse_categorical_accuracy: 0.9648\n",
      "Epoch 1135: val_loss improved from 0.10870 to 0.10828, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1079 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1083 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1136/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1278 - sparse_categorical_accuracy: 0.9575\n",
      "Epoch 1136: val_loss did not improve from 0.10828\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1182 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1111 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1137/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1006 - sparse_categorical_accuracy: 0.9639\n",
      "Epoch 1137: val_loss improved from 0.10828 to 0.10698, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1166 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1070 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1138/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1127 - sparse_categorical_accuracy: 0.9514\n",
      "Epoch 1138: val_loss did not improve from 0.10698\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1162 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.1077 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1139/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1092 - sparse_categorical_accuracy: 0.9550\n",
      "Epoch 1139: val_loss did not improve from 0.10698\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1105 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1122 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1140/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1245 - sparse_categorical_accuracy: 0.9494\n",
      "Epoch 1140: val_loss did not improve from 0.10698\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1245 - sparse_categorical_accuracy: 0.9494 - val_loss: 0.1248 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 1141/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1185 - sparse_categorical_accuracy: 0.9564\n",
      "Epoch 1141: val_loss did not improve from 0.10698\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1174 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1105 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1142/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.0924 - sparse_categorical_accuracy: 0.9661\n",
      "Epoch 1142: val_loss did not improve from 0.10698\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0965 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1086 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1143/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1400 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 1143: val_loss did not improve from 0.10698\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1397 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.1083 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1144/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1213 - sparse_categorical_accuracy: 0.9551\n",
      "Epoch 1144: val_loss did not improve from 0.10698\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1213 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.1076 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1145/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1097 - sparse_categorical_accuracy: 0.9557\n",
      "Epoch 1145: val_loss did not improve from 0.10698\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1133 - sparse_categorical_accuracy: 0.9494 - val_loss: 0.1101 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1146/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1166 - sparse_categorical_accuracy: 0.9569\n",
      "Epoch 1146: val_loss did not improve from 0.10698\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1166 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1097 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1147/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1309 - sparse_categorical_accuracy: 0.9494\n",
      "Epoch 1147: val_loss did not improve from 0.10698\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1309 - sparse_categorical_accuracy: 0.9494 - val_loss: 0.1073 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1148/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1146 - sparse_categorical_accuracy: 0.9525\n",
      "Epoch 1148: val_loss did not improve from 0.10698\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1102 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1121 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1149/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1293 - sparse_categorical_accuracy: 0.9419\n",
      "Epoch 1149: val_loss did not improve from 0.10698\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1293 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.1143 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1150/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1141 - sparse_categorical_accuracy: 0.9648\n",
      "Epoch 1150: val_loss did not improve from 0.10698\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1150 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.1075 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1151/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1047 - sparse_categorical_accuracy: 0.9675\n",
      "Epoch 1151: val_loss did not improve from 0.10698\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1147 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1079 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1152/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.0991 - sparse_categorical_accuracy: 0.9688\n",
      "Epoch 1152: val_loss did not improve from 0.10698\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1153 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1106 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1153/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1343 - sparse_categorical_accuracy: 0.9600\n",
      "Epoch 1153: val_loss did not improve from 0.10698\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1165 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1091 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1154/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1172 - sparse_categorical_accuracy: 0.9550\n",
      "Epoch 1154: val_loss did not improve from 0.10698\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1168 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.1074 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1155/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1235 - sparse_categorical_accuracy: 0.9527\n",
      "Epoch 1155: val_loss did not improve from 0.10698\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1249 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1157 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1156/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1167 - sparse_categorical_accuracy: 0.9560\n",
      "Epoch 1156: val_loss did not improve from 0.10698\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1098 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1077 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1157/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1064 - sparse_categorical_accuracy: 0.9621\n",
      "Epoch 1157: val_loss did not improve from 0.10698\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1177 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.1073 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1158/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1156 - sparse_categorical_accuracy: 0.9549\n",
      "Epoch 1158: val_loss did not improve from 0.10698\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1161 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1076 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1159/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1324 - sparse_categorical_accuracy: 0.9450\n",
      "Epoch 1159: val_loss did not improve from 0.10698\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1307 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1104 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1160/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1177 - sparse_categorical_accuracy: 0.9551\n",
      "Epoch 1160: val_loss did not improve from 0.10698\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1177 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.1111 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1161/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1098 - sparse_categorical_accuracy: 0.9545\n",
      "Epoch 1161: val_loss improved from 0.10698 to 0.10583, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1087 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.1058 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1162/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1053 - sparse_categorical_accuracy: 0.9625\n",
      "Epoch 1162: val_loss did not improve from 0.10583\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1159 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.1086 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1163/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1158 - sparse_categorical_accuracy: 0.9644\n",
      "Epoch 1163: val_loss did not improve from 0.10583\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1158 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1079 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1164/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1184 - sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1164: val_loss did not improve from 0.10583\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1184 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1075 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1165/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.1337 - sparse_categorical_accuracy: 0.9429\n",
      "Epoch 1165: val_loss did not improve from 0.10583\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1175 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1200 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 1166/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.0957 - sparse_categorical_accuracy: 0.9722\n",
      "Epoch 1166: val_loss did not improve from 0.10583\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1289 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1102 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1167/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.1272 - sparse_categorical_accuracy: 0.9565\n",
      "Epoch 1167: val_loss did not improve from 0.10583\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1106 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1123 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1168/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1169 - sparse_categorical_accuracy: 0.9644\n",
      "Epoch 1168: val_loss did not improve from 0.10583\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1169 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1060 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1169/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1102 - sparse_categorical_accuracy: 0.9525\n",
      "Epoch 1169: val_loss did not improve from 0.10583\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1162 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1093 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1170/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1235 - sparse_categorical_accuracy: 0.9618\n",
      "Epoch 1170: val_loss did not improve from 0.10583\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1197 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1066 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1171/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1170 - sparse_categorical_accuracy: 0.9557\n",
      "Epoch 1171: val_loss improved from 0.10583 to 0.10463, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1198 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1046 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1172/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1068 - sparse_categorical_accuracy: 0.9688\n",
      "Epoch 1172: val_loss did not improve from 0.10463\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1211 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1118 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1173/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1113 - sparse_categorical_accuracy: 0.9644\n",
      "Epoch 1173: val_loss did not improve from 0.10463\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1113 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1093 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1174/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1114 - sparse_categorical_accuracy: 0.9557\n",
      "Epoch 1174: val_loss did not improve from 0.10463\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1053 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.1122 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1175/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1171 - sparse_categorical_accuracy: 0.9537\n",
      "Epoch 1175: val_loss did not improve from 0.10463\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1167 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1074 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1176/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1111 - sparse_categorical_accuracy: 0.9532\n",
      "Epoch 1176: val_loss did not improve from 0.10463\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1111 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1109 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1177/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.1350 - sparse_categorical_accuracy: 0.9511\n",
      "Epoch 1177: val_loss did not improve from 0.10463\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1245 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1063 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1178/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1097 - sparse_categorical_accuracy: 0.9591\n",
      "Epoch 1178: val_loss did not improve from 0.10463\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1133 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1132 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1179/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1061 - sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1179: val_loss did not improve from 0.10463\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1061 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.1170 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1180/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1160 - sparse_categorical_accuracy: 0.9600\n",
      "Epoch 1180: val_loss did not improve from 0.10463\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1209 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.1086 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1181/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1143 - sparse_categorical_accuracy: 0.9560\n",
      "Epoch 1181: val_loss did not improve from 0.10463\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1098 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.1086 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1182/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1038 - sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1182: val_loss did not improve from 0.10463\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1038 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.1088 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1183/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1174 - sparse_categorical_accuracy: 0.9591\n",
      "Epoch 1183: val_loss did not improve from 0.10463\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1116 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1157 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 1184/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1197 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 1184: val_loss did not improve from 0.10463\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1165 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1058 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1185/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1132 - sparse_categorical_accuracy: 0.9532\n",
      "Epoch 1185: val_loss did not improve from 0.10463\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1132 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1097 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1186/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.1011 - sparse_categorical_accuracy: 0.9674\n",
      "Epoch 1186: val_loss did not improve from 0.10463\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1108 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1060 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1187/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1325 - sparse_categorical_accuracy: 0.9495\n",
      "Epoch 1187: val_loss did not improve from 0.10463\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1296 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1051 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1188/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1159 - sparse_categorical_accuracy: 0.9621\n",
      "Epoch 1188: val_loss improved from 0.10463 to 0.10367, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1162 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1037 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1189/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1024 - sparse_categorical_accuracy: 0.9661\n",
      "Epoch 1189: val_loss did not improve from 0.10367\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1069 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.1065 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1190/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1183 - sparse_categorical_accuracy: 0.9606\n",
      "Epoch 1190: val_loss did not improve from 0.10367\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1178 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1074 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1191/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1197 - sparse_categorical_accuracy: 0.9609\n",
      "Epoch 1191: val_loss did not improve from 0.10367\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1182 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1078 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1192/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.0867 - sparse_categorical_accuracy: 0.9740\n",
      "Epoch 1192: val_loss did not improve from 0.10367\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0995 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1060 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1193/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1236 - sparse_categorical_accuracy: 0.9509\n",
      "Epoch 1193: val_loss did not improve from 0.10367\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1195 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1048 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1194/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0987 - sparse_categorical_accuracy: 0.9697\n",
      "Epoch 1194: val_loss did not improve from 0.10367\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0982 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.1124 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1195/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.0957 - sparse_categorical_accuracy: 0.9754\n",
      "Epoch 1195: val_loss did not improve from 0.10367\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1028 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.1116 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1196/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1334 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 1196: val_loss did not improve from 0.10367\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1112 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1061 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1197/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.0959 - sparse_categorical_accuracy: 0.9675\n",
      "Epoch 1197: val_loss did not improve from 0.10367\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1035 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.1047 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1198/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1306 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 1198: val_loss did not improve from 0.10367\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1090 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.1105 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1199/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1222 - sparse_categorical_accuracy: 0.9505\n",
      "Epoch 1199: val_loss did not improve from 0.10367\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1227 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1132 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1200/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1020 - sparse_categorical_accuracy: 0.9688\n",
      "Epoch 1200: val_loss did not improve from 0.10367\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1097 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1053 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1201/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1205 - sparse_categorical_accuracy: 0.9527\n",
      "Epoch 1201: val_loss did not improve from 0.10367\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1210 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1088 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1202/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1106 - sparse_categorical_accuracy: 0.9675\n",
      "Epoch 1202: val_loss did not improve from 0.10367\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1048 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.1041 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1203/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1194 - sparse_categorical_accuracy: 0.9591\n",
      "Epoch 1203: val_loss improved from 0.10367 to 0.10344, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1132 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1034 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1204/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1297 - sparse_categorical_accuracy: 0.9653\n",
      "Epoch 1204: val_loss did not improve from 0.10344\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1240 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.1113 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1205/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1223 - sparse_categorical_accuracy: 0.9543\n",
      "Epoch 1205: val_loss improved from 0.10344 to 0.10284, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1192 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1028 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1206/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1044 - sparse_categorical_accuracy: 0.9618\n",
      "Epoch 1206: val_loss did not improve from 0.10284\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1085 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1063 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1207/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1017 - sparse_categorical_accuracy: 0.9675\n",
      "Epoch 1207: val_loss improved from 0.10284 to 0.10196, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1058 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1020 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1208/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1023 - sparse_categorical_accuracy: 0.9688\n",
      "Epoch 1208: val_loss did not improve from 0.10196\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1019 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1025 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1209/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1215 - sparse_categorical_accuracy: 0.9514\n",
      "Epoch 1209: val_loss did not improve from 0.10196\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1124 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.1079 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1210/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.0954 - sparse_categorical_accuracy: 0.9766\n",
      "Epoch 1210: val_loss did not improve from 0.10196\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0993 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.1086 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1211/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1134 - sparse_categorical_accuracy: 0.9588\n",
      "Epoch 1211: val_loss did not improve from 0.10196\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1134 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.1083 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1212/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1134 - sparse_categorical_accuracy: 0.9564\n",
      "Epoch 1212: val_loss did not improve from 0.10196\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1127 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1064 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1213/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1072 - sparse_categorical_accuracy: 0.9615\n",
      "Epoch 1213: val_loss did not improve from 0.10196\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1237 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.1083 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1214/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1287 - sparse_categorical_accuracy: 0.9432\n",
      "Epoch 1214: val_loss did not improve from 0.10196\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1275 - sparse_categorical_accuracy: 0.9438 - val_loss: 0.1083 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1215/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1152 - sparse_categorical_accuracy: 0.9644\n",
      "Epoch 1215: val_loss did not improve from 0.10196\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1152 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1061 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1216/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1050 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 1216: val_loss did not improve from 0.10196\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1127 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1045 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1217/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1066 - sparse_categorical_accuracy: 0.9700\n",
      "Epoch 1217: val_loss did not improve from 0.10196\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1066 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.1029 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1218/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.1225 - sparse_categorical_accuracy: 0.9484\n",
      "Epoch 1218: val_loss did not improve from 0.10196\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1096 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1075 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1219/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1082 - sparse_categorical_accuracy: 0.9643\n",
      "Epoch 1219: val_loss improved from 0.10196 to 0.10120, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1063 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.1012 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1220/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1147 - sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1220: val_loss did not improve from 0.10120\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1147 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1022 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1221/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1303 - sparse_categorical_accuracy: 0.9423\n",
      "Epoch 1221: val_loss improved from 0.10120 to 0.10057, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 15ms/step - loss: 0.1242 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.1006 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1222/10000\n",
      "22/34 [==================>...........] - ETA: 0s - loss: 0.1067 - sparse_categorical_accuracy: 0.9517\n",
      "Epoch 1222: val_loss did not improve from 0.10057\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1156 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1077 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1223/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1087 - sparse_categorical_accuracy: 0.9668\n",
      "Epoch 1223: val_loss did not improve from 0.10057\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1071 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.1006 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1224/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.0983 - sparse_categorical_accuracy: 0.9609\n",
      "Epoch 1224: val_loss did not improve from 0.10057\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1015 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1011 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1225/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1079 - sparse_categorical_accuracy: 0.9563\n",
      "Epoch 1225: val_loss did not improve from 0.10057\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1054 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1014 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1226/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1072 - sparse_categorical_accuracy: 0.9508\n",
      "Epoch 1226: val_loss improved from 0.10057 to 0.10043, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1079 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1004 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1227/10000\n",
      "22/34 [==================>...........] - ETA: 0s - loss: 0.1084 - sparse_categorical_accuracy: 0.9659\n",
      "Epoch 1227: val_loss did not improve from 0.10043\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1096 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.1077 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1228/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1108 - sparse_categorical_accuracy: 0.9653\n",
      "Epoch 1228: val_loss did not improve from 0.10043\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1141 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.1022 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1229/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1005 - sparse_categorical_accuracy: 0.9678\n",
      "Epoch 1229: val_loss did not improve from 0.10043\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1073 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.1023 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1230/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1039 - sparse_categorical_accuracy: 0.9630\n",
      "Epoch 1230: val_loss did not improve from 0.10043\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1068 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.1007 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1231/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1186 - sparse_categorical_accuracy: 0.9554\n",
      "Epoch 1231: val_loss did not improve from 0.10043\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1156 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.1059 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1232/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0985 - sparse_categorical_accuracy: 0.9700\n",
      "Epoch 1232: val_loss did not improve from 0.10043\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0985 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.1012 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1233/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1143 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 1233: val_loss did not improve from 0.10043\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1129 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.1023 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1234/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1229 - sparse_categorical_accuracy: 0.9519\n",
      "Epoch 1234: val_loss did not improve from 0.10043\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1170 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1053 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1235/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1063 - sparse_categorical_accuracy: 0.9644\n",
      "Epoch 1235: val_loss did not improve from 0.10043\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1063 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1057 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1236/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1128 - sparse_categorical_accuracy: 0.9650\n",
      "Epoch 1236: val_loss did not improve from 0.10043\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1114 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1029 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1237/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.0868 - sparse_categorical_accuracy: 0.9688\n",
      "Epoch 1237: val_loss did not improve from 0.10043\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0953 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.1033 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1238/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1005 - sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1238: val_loss did not improve from 0.10043\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1005 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.1029 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1239/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1156 - sparse_categorical_accuracy: 0.9557\n",
      "Epoch 1239: val_loss did not improve from 0.10043\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1094 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1060 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1240/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1045 - sparse_categorical_accuracy: 0.9567\n",
      "Epoch 1240: val_loss did not improve from 0.10043\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1005 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.1040 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1241/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1187 - sparse_categorical_accuracy: 0.9688\n",
      "Epoch 1241: val_loss did not improve from 0.10043\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1152 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.1013 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1242/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1073 - sparse_categorical_accuracy: 0.9635\n",
      "Epoch 1242: val_loss did not improve from 0.10043\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1088 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.1026 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1243/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0964 - sparse_categorical_accuracy: 0.9688\n",
      "Epoch 1243: val_loss did not improve from 0.10043\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1001 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1010 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1244/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0972 - sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1244: val_loss did not improve from 0.10043\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0972 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1175 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 1245/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1220 - sparse_categorical_accuracy: 0.9423\n",
      "Epoch 1245: val_loss did not improve from 0.10043\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1168 - sparse_categorical_accuracy: 0.9494 - val_loss: 0.1027 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1246/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1059 - sparse_categorical_accuracy: 0.9602\n",
      "Epoch 1246: val_loss did not improve from 0.10043\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1053 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1047 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1247/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1064 - sparse_categorical_accuracy: 0.9532\n",
      "Epoch 1247: val_loss did not improve from 0.10043\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1064 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1004 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1248/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1125 - sparse_categorical_accuracy: 0.9560\n",
      "Epoch 1248: val_loss did not improve from 0.10043\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1088 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1047 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1249/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1222 - sparse_categorical_accuracy: 0.9569\n",
      "Epoch 1249: val_loss did not improve from 0.10043\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1222 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1029 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1250/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1086 - sparse_categorical_accuracy: 0.9500\n",
      "Epoch 1250: val_loss did not improve from 0.10043\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1113 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1026 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1251/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1226 - sparse_categorical_accuracy: 0.9526\n",
      "Epoch 1251: val_loss did not improve from 0.10043\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1159 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1117 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1252/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1207 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 1252: val_loss improved from 0.10043 to 0.10038, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1080 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.1004 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1253/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1047 - sparse_categorical_accuracy: 0.9591\n",
      "Epoch 1253: val_loss did not improve from 0.10038\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1046 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1004 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1254/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0969 - sparse_categorical_accuracy: 0.9700\n",
      "Epoch 1254: val_loss improved from 0.10038 to 0.09988, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0969 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0999 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1255/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1233 - sparse_categorical_accuracy: 0.9508\n",
      "Epoch 1255: val_loss did not improve from 0.09988\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1229 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1092 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1256/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1208 - sparse_categorical_accuracy: 0.9550\n",
      "Epoch 1256: val_loss improved from 0.09988 to 0.09939, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1133 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.0994 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1257/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.0788 - sparse_categorical_accuracy: 0.9792\n",
      "Epoch 1257: val_loss did not improve from 0.09939\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1147 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.1016 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1258/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1089 - sparse_categorical_accuracy: 0.9591\n",
      "Epoch 1258: val_loss did not improve from 0.09939\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1043 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1014 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1259/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1131 - sparse_categorical_accuracy: 0.9564\n",
      "Epoch 1259: val_loss did not improve from 0.09939\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1121 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1068 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1260/10000\n",
      "20/34 [================>.............] - ETA: 0s - loss: 0.1328 - sparse_categorical_accuracy: 0.9594\n",
      "Epoch 1260: val_loss did not improve from 0.09939\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1270 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1053 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1261/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0933 - sparse_categorical_accuracy: 0.9735\n",
      "Epoch 1261: val_loss did not improve from 0.09939\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0935 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.1026 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1262/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1135 - sparse_categorical_accuracy: 0.9475\n",
      "Epoch 1262: val_loss did not improve from 0.09939\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1028 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.1005 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1263/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.0957 - sparse_categorical_accuracy: 0.9615\n",
      "Epoch 1263: val_loss did not improve from 0.09939\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0941 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.1057 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1264/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1041 - sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1264: val_loss did not improve from 0.09939\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1041 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.1005 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1265/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1107 - sparse_categorical_accuracy: 0.9625\n",
      "Epoch 1265: val_loss did not improve from 0.09939\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1143 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1027 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1266/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1097 - sparse_categorical_accuracy: 0.9634\n",
      "Epoch 1266: val_loss did not improve from 0.09939\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1093 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.1011 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1267/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.0915 - sparse_categorical_accuracy: 0.9760\n",
      "Epoch 1267: val_loss did not improve from 0.09939\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0968 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.1010 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1268/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1098 - sparse_categorical_accuracy: 0.9531\n",
      "Epoch 1268: val_loss did not improve from 0.09939\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1043 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1007 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1269/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1153 - sparse_categorical_accuracy: 0.9630\n",
      "Epoch 1269: val_loss improved from 0.09939 to 0.09932, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1176 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0993 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1270/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1013 - sparse_categorical_accuracy: 0.9754\n",
      "Epoch 1270: val_loss improved from 0.09932 to 0.09772, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0999 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0977 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1271/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1033 - sparse_categorical_accuracy: 0.9688\n",
      "Epoch 1271: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1010 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.1036 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1272/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0983 - sparse_categorical_accuracy: 0.9629\n",
      "Epoch 1272: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1050 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1005 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1273/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.0972 - sparse_categorical_accuracy: 0.9620\n",
      "Epoch 1273: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1108 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.1054 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1274/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0899 - sparse_categorical_accuracy: 0.9741\n",
      "Epoch 1274: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0964 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0981 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1275/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1103 - sparse_categorical_accuracy: 0.9646\n",
      "Epoch 1275: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1065 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.1002 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1276/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1018 - sparse_categorical_accuracy: 0.9630\n",
      "Epoch 1276: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1061 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.1065 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1277/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1055 - sparse_categorical_accuracy: 0.9644\n",
      "Epoch 1277: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1055 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1039 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1278/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.0956 - sparse_categorical_accuracy: 0.9625\n",
      "Epoch 1278: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1060 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.1074 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1279/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1136 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 1279: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1132 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.1075 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1280/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1149 - sparse_categorical_accuracy: 0.9637\n",
      "Epoch 1280: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1096 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0989 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1281/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1114 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 1281: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1108 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.1020 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1282/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1073 - sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1282: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1073 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.1033 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1283/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0940 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 1283: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1061 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.0984 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1284/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1005 - sparse_categorical_accuracy: 0.9688\n",
      "Epoch 1284: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1040 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.1058 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1285/10000\n",
      "20/34 [================>.............] - ETA: 0s - loss: 0.1062 - sparse_categorical_accuracy: 0.9750\n",
      "Epoch 1285: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1026 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0990 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1286/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1074 - sparse_categorical_accuracy: 0.9618\n",
      "Epoch 1286: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1062 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0983 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1287/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1108 - sparse_categorical_accuracy: 0.9625\n",
      "Epoch 1287: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1062 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.1008 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1288/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.0904 - sparse_categorical_accuracy: 0.9792\n",
      "Epoch 1288: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1052 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1041 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1289/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1082 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 1289: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1034 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1061 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1290/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0903 - sparse_categorical_accuracy: 0.9741\n",
      "Epoch 1290: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1004 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0997 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1291/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1065 - sparse_categorical_accuracy: 0.9629\n",
      "Epoch 1291: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1032 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0999 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1292/10000\n",
      "22/34 [==================>...........] - ETA: 0s - loss: 0.1131 - sparse_categorical_accuracy: 0.9688\n",
      "Epoch 1292: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1168 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1069 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1293/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1112 - sparse_categorical_accuracy: 0.9618\n",
      "Epoch 1293: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1017 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1015 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1294/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1093 - sparse_categorical_accuracy: 0.9635\n",
      "Epoch 1294: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0998 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0992 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1295/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1076 - sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1295: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1076 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.1017 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1296/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1075 - sparse_categorical_accuracy: 0.9575\n",
      "Epoch 1296: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1056 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1025 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1297/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1055 - sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1297: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1055 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.1013 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1298/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1087 - sparse_categorical_accuracy: 0.9564\n",
      "Epoch 1298: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1075 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.0986 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1299/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.0970 - sparse_categorical_accuracy: 0.9615\n",
      "Epoch 1299: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0951 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1004 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1300/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1160 - sparse_categorical_accuracy: 0.9527\n",
      "Epoch 1300: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1148 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1038 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1301/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1130 - sparse_categorical_accuracy: 0.9618\n",
      "Epoch 1301: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1065 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1012 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1302/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1067 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 1302: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1099 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.0993 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1303/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1316 - sparse_categorical_accuracy: 0.9514\n",
      "Epoch 1303: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1165 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0988 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1304/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1081 - sparse_categorical_accuracy: 0.9537\n",
      "Epoch 1304: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1096 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.0995 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1305/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1000 - sparse_categorical_accuracy: 0.9698\n",
      "Epoch 1305: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0993 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0994 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1306/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0973 - sparse_categorical_accuracy: 0.9668\n",
      "Epoch 1306: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0973 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.1025 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1307/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1002 - sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1307: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1008 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1006 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1308/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1213 - sparse_categorical_accuracy: 0.9630\n",
      "Epoch 1308: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1118 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.1122 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1309/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1047 - sparse_categorical_accuracy: 0.9639\n",
      "Epoch 1309: val_loss did not improve from 0.09772\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0991 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.1038 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1310/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1017 - sparse_categorical_accuracy: 0.9644\n",
      "Epoch 1310: val_loss improved from 0.09772 to 0.09770, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.1017 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0977 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1311/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1114 - sparse_categorical_accuracy: 0.9532\n",
      "Epoch 1311: val_loss did not improve from 0.09770\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1114 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.1006 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1312/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0899 - sparse_categorical_accuracy: 0.9745\n",
      "Epoch 1312: val_loss did not improve from 0.09770\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0858 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.1083 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1313/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1001 - sparse_categorical_accuracy: 0.9718\n",
      "Epoch 1313: val_loss did not improve from 0.09770\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1019 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1066 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1314/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1158 - sparse_categorical_accuracy: 0.9489\n",
      "Epoch 1314: val_loss did not improve from 0.09770\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1157 - sparse_categorical_accuracy: 0.9494 - val_loss: 0.0989 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1315/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0871 - sparse_categorical_accuracy: 0.9729\n",
      "Epoch 1315: val_loss did not improve from 0.09770\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0870 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.1007 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1316/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1221 - sparse_categorical_accuracy: 0.9640\n",
      "Epoch 1316: val_loss did not improve from 0.09770\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1209 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0991 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1317/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0913 - sparse_categorical_accuracy: 0.9741\n",
      "Epoch 1317: val_loss did not improve from 0.09770\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0922 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.1043 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1318/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1010 - sparse_categorical_accuracy: 0.9653\n",
      "Epoch 1318: val_loss did not improve from 0.09770\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0993 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1019 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1319/10000\n",
      "20/34 [================>.............] - ETA: 0s - loss: 0.1075 - sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1319: val_loss did not improve from 0.09770\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1145 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.1247 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1320/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1060 - sparse_categorical_accuracy: 0.9655\n",
      "Epoch 1320: val_loss did not improve from 0.09770\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1072 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0981 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1321/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1052 - sparse_categorical_accuracy: 0.9648\n",
      "Epoch 1321: val_loss did not improve from 0.09770\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1026 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.1039 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1322/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.0846 - sparse_categorical_accuracy: 0.9750\n",
      "Epoch 1322: val_loss did not improve from 0.09770\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0915 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0989 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1323/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0952 - sparse_categorical_accuracy: 0.9653\n",
      "Epoch 1323: val_loss did not improve from 0.09770\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0945 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0981 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1324/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0911 - sparse_categorical_accuracy: 0.9738\n",
      "Epoch 1324: val_loss improved from 0.09770 to 0.09673, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0898 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0967 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1325/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0984 - sparse_categorical_accuracy: 0.9716\n",
      "Epoch 1325: val_loss did not improve from 0.09673\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0974 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0992 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1326/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0904 - sparse_categorical_accuracy: 0.9758\n",
      "Epoch 1326: val_loss did not improve from 0.09673\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0939 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.1073 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1327/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1177 - sparse_categorical_accuracy: 0.9450\n",
      "Epoch 1327: val_loss did not improve from 0.09673\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1140 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.0970 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1328/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1038 - sparse_categorical_accuracy: 0.9697\n",
      "Epoch 1328: val_loss did not improve from 0.09673\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1027 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0991 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1329/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1031 - sparse_categorical_accuracy: 0.9700\n",
      "Epoch 1329: val_loss did not improve from 0.09673\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1031 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0969 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1330/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1030 - sparse_categorical_accuracy: 0.9575\n",
      "Epoch 1330: val_loss did not improve from 0.09673\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0969 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0973 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1331/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1074 - sparse_categorical_accuracy: 0.9678\n",
      "Epoch 1331: val_loss did not improve from 0.09673\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1067 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1081 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1332/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1082 - sparse_categorical_accuracy: 0.9602\n",
      "Epoch 1332: val_loss did not improve from 0.09673\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1077 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.0970 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1333/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.0928 - sparse_categorical_accuracy: 0.9736\n",
      "Epoch 1333: val_loss did not improve from 0.09673\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1008 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1004 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1334/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0922 - sparse_categorical_accuracy: 0.9668\n",
      "Epoch 1334: val_loss did not improve from 0.09673\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0956 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.1024 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1335/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1086 - sparse_categorical_accuracy: 0.9637\n",
      "Epoch 1335: val_loss did not improve from 0.09673\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1072 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1017 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1336/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1007 - sparse_categorical_accuracy: 0.9597\n",
      "Epoch 1336: val_loss did not improve from 0.09673\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1016 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1037 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1337/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0955 - sparse_categorical_accuracy: 0.9648\n",
      "Epoch 1337: val_loss did not improve from 0.09673\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0943 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0992 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1338/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1032 - sparse_categorical_accuracy: 0.9630\n",
      "Epoch 1338: val_loss did not improve from 0.09673\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0971 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0977 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1339/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0996 - sparse_categorical_accuracy: 0.9625\n",
      "Epoch 1339: val_loss did not improve from 0.09673\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0996 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.1037 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1340/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0982 - sparse_categorical_accuracy: 0.9591\n",
      "Epoch 1340: val_loss did not improve from 0.09673\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1050 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.1000 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1341/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1013 - sparse_categorical_accuracy: 0.9606\n",
      "Epoch 1341: val_loss did not improve from 0.09673\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0986 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1029 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1342/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1169 - sparse_categorical_accuracy: 0.9537\n",
      "Epoch 1342: val_loss did not improve from 0.09673\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1093 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.0975 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1343/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1051 - sparse_categorical_accuracy: 0.9714\n",
      "Epoch 1343: val_loss did not improve from 0.09673\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0911 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.1039 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1344/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1157 - sparse_categorical_accuracy: 0.9577\n",
      "Epoch 1344: val_loss did not improve from 0.09673\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1111 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1079 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1345/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0993 - sparse_categorical_accuracy: 0.9621\n",
      "Epoch 1345: val_loss did not improve from 0.09673\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0982 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.1012 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1346/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0966 - sparse_categorical_accuracy: 0.9699\n",
      "Epoch 1346: val_loss improved from 0.09673 to 0.09667, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1021 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0967 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1347/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0930 - sparse_categorical_accuracy: 0.9597\n",
      "Epoch 1347: val_loss did not improve from 0.09667\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0984 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1015 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1348/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1024 - sparse_categorical_accuracy: 0.9591\n",
      "Epoch 1348: val_loss did not improve from 0.09667\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0946 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.1007 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1349/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0972 - sparse_categorical_accuracy: 0.9699\n",
      "Epoch 1349: val_loss did not improve from 0.09667\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0912 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0969 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1350/10000\n",
      "20/34 [================>.............] - ETA: 0s - loss: 0.0905 - sparse_categorical_accuracy: 0.9563\n",
      "Epoch 1350: val_loss did not improve from 0.09667\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0993 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.0974 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1351/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1047 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 1351: val_loss did not improve from 0.09667\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1075 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0968 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1352/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1077 - sparse_categorical_accuracy: 0.9542\n",
      "Epoch 1352: val_loss did not improve from 0.09667\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1054 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.0979 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1353/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1092 - sparse_categorical_accuracy: 0.9609\n",
      "Epoch 1353: val_loss did not improve from 0.09667\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0940 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0980 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1354/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0773 - sparse_categorical_accuracy: 0.9792\n",
      "Epoch 1354: val_loss did not improve from 0.09667\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0828 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.1009 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1355/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0882 - sparse_categorical_accuracy: 0.9741\n",
      "Epoch 1355: val_loss did not improve from 0.09667\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0968 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1014 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1356/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0894 - sparse_categorical_accuracy: 0.9708\n",
      "Epoch 1356: val_loss did not improve from 0.09667\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0967 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1004 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1357/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1010 - sparse_categorical_accuracy: 0.9646\n",
      "Epoch 1357: val_loss did not improve from 0.09667\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1034 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.1006 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1358/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1076 - sparse_categorical_accuracy: 0.9560\n",
      "Epoch 1358: val_loss improved from 0.09667 to 0.09615, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1050 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.0962 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1359/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1158 - sparse_categorical_accuracy: 0.9600\n",
      "Epoch 1359: val_loss did not improve from 0.09615\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1049 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0976 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1360/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1010 - sparse_categorical_accuracy: 0.9722\n",
      "Epoch 1360: val_loss improved from 0.09615 to 0.09598, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1001 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0960 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1361/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0963 - sparse_categorical_accuracy: 0.9629\n",
      "Epoch 1361: val_loss did not improve from 0.09598\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.1010 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1362/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.0908 - sparse_categorical_accuracy: 0.9783\n",
      "Epoch 1362: val_loss did not improve from 0.09598\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0925 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0975 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1363/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1136 - sparse_categorical_accuracy: 0.9688\n",
      "Epoch 1363: val_loss did not improve from 0.09598\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1113 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0989 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1364/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0909 - sparse_categorical_accuracy: 0.9678\n",
      "Epoch 1364: val_loss did not improve from 0.09598\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0908 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1030 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1365/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0959 - sparse_categorical_accuracy: 0.9606\n",
      "Epoch 1365: val_loss did not improve from 0.09598\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0930 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0974 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1366/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1000 - sparse_categorical_accuracy: 0.9640\n",
      "Epoch 1366: val_loss did not improve from 0.09598\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1049 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0976 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1367/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1081 - sparse_categorical_accuracy: 0.9496\n",
      "Epoch 1367: val_loss did not improve from 0.09598\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1060 - sparse_categorical_accuracy: 0.9494 - val_loss: 0.1036 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1368/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.0981 - sparse_categorical_accuracy: 0.9722\n",
      "Epoch 1368: val_loss did not improve from 0.09598\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0952 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0975 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1369/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.0952 - sparse_categorical_accuracy: 0.9783\n",
      "Epoch 1369: val_loss did not improve from 0.09598\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0877 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.1005 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1370/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0945 - sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1370: val_loss did not improve from 0.09598\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0945 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.1004 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1371/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1016 - sparse_categorical_accuracy: 0.9754\n",
      "Epoch 1371: val_loss did not improve from 0.09598\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1005 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0979 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1372/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.0908 - sparse_categorical_accuracy: 0.9650\n",
      "Epoch 1372: val_loss improved from 0.09598 to 0.09595, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0986 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0959 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1373/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1052 - sparse_categorical_accuracy: 0.9598\n",
      "Epoch 1373: val_loss did not improve from 0.09595\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0991 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0986 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1374/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1080 - sparse_categorical_accuracy: 0.9716\n",
      "Epoch 1374: val_loss did not improve from 0.09595\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.1073 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0992 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1375/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.0920 - sparse_categorical_accuracy: 0.9760\n",
      "Epoch 1375: val_loss did not improve from 0.09595\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0943 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0988 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1376/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0964 - sparse_categorical_accuracy: 0.9604\n",
      "Epoch 1376: val_loss improved from 0.09595 to 0.09563, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0942 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0956 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1377/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0921 - sparse_categorical_accuracy: 0.9699\n",
      "Epoch 1377: val_loss improved from 0.09563 to 0.09387, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 1s 20ms/step - loss: 0.0923 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0939 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1378/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.0811 - sparse_categorical_accuracy: 0.9700\n",
      "Epoch 1378: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0880 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0980 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1379/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1019 - sparse_categorical_accuracy: 0.9659\n",
      "Epoch 1379: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1012 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0959 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1380/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1090 - sparse_categorical_accuracy: 0.9590\n",
      "Epoch 1380: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1110 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.0943 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1381/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1054 - sparse_categorical_accuracy: 0.9588\n",
      "Epoch 1381: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1054 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.1040 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1382/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0960 - sparse_categorical_accuracy: 0.9722\n",
      "Epoch 1382: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0977 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0983 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1383/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0946 - sparse_categorical_accuracy: 0.9659\n",
      "Epoch 1383: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0959 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0991 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1384/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1018 - sparse_categorical_accuracy: 0.9661\n",
      "Epoch 1384: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1079 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1033 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1385/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0950 - sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1385: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0950 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0968 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1386/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1004 - sparse_categorical_accuracy: 0.9735\n",
      "Epoch 1386: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1014 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.1034 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1387/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1173 - sparse_categorical_accuracy: 0.9525\n",
      "Epoch 1387: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1037 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1125 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1388/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1095 - sparse_categorical_accuracy: 0.9729\n",
      "Epoch 1388: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1077 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.1006 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1389/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0888 - sparse_categorical_accuracy: 0.9644\n",
      "Epoch 1389: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0888 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1010 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1390/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.0903 - sparse_categorical_accuracy: 0.9725\n",
      "Epoch 1390: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0919 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0982 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1391/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0997 - sparse_categorical_accuracy: 0.9646\n",
      "Epoch 1391: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0995 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1054 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1392/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0883 - sparse_categorical_accuracy: 0.9830\n",
      "Epoch 1392: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0873 - sparse_categorical_accuracy: 0.9831 - val_loss: 0.0947 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1393/10000\n",
      "22/34 [==================>...........] - ETA: 0s - loss: 0.1055 - sparse_categorical_accuracy: 0.9602\n",
      "Epoch 1393: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0935 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1040 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1394/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0978 - sparse_categorical_accuracy: 0.9604\n",
      "Epoch 1394: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1004 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1019 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1395/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1029 - sparse_categorical_accuracy: 0.9697\n",
      "Epoch 1395: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1020 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0966 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1396/10000\n",
      "21/34 [=================>............] - ETA: 0s - loss: 0.0929 - sparse_categorical_accuracy: 0.9643\n",
      "Epoch 1396: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1053 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.1035 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1397/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0956 - sparse_categorical_accuracy: 0.9720\n",
      "Epoch 1397: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1040 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1009 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1398/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1015 - sparse_categorical_accuracy: 0.9640\n",
      "Epoch 1398: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1021 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0960 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1399/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0989 - sparse_categorical_accuracy: 0.9653\n",
      "Epoch 1399: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0979 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0949 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1400/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0848 - sparse_categorical_accuracy: 0.9778\n",
      "Epoch 1400: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0833 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.0955 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1401/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1044 - sparse_categorical_accuracy: 0.9629\n",
      "Epoch 1401: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1025 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0956 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1402/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0976 - sparse_categorical_accuracy: 0.9754\n",
      "Epoch 1402: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0966 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0962 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1403/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0825 - sparse_categorical_accuracy: 0.9722\n",
      "Epoch 1403: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0887 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.1007 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1404/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0934 - sparse_categorical_accuracy: 0.9727\n",
      "Epoch 1404: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0943 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.1011 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1405/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.0896 - sparse_categorical_accuracy: 0.9792\n",
      "Epoch 1405: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0892 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0954 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1406/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.0860 - sparse_categorical_accuracy: 0.9712\n",
      "Epoch 1406: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0860 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0950 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1407/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1064 - sparse_categorical_accuracy: 0.9653\n",
      "Epoch 1407: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0862 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0944 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1408/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.0894 - sparse_categorical_accuracy: 0.9755\n",
      "Epoch 1408: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1054 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1096 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1409/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1038 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 1409: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1078 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0941 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1410/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0983 - sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1410: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0983 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1071 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1411/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.0959 - sparse_categorical_accuracy: 0.9620\n",
      "Epoch 1411: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1013 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.0967 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1412/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0950 - sparse_categorical_accuracy: 0.9653\n",
      "Epoch 1412: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0970 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1000 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1413/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1049 - sparse_categorical_accuracy: 0.9564\n",
      "Epoch 1413: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1038 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.0992 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1414/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.0901 - sparse_categorical_accuracy: 0.9700\n",
      "Epoch 1414: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0889 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0939 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1415/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0933 - sparse_categorical_accuracy: 0.9735\n",
      "Epoch 1415: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0940 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.1027 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1416/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.0960 - sparse_categorical_accuracy: 0.9665\n",
      "Epoch 1416: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1069 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0939 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1417/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1022 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 1417: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0939 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1013 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1418/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0963 - sparse_categorical_accuracy: 0.9625\n",
      "Epoch 1418: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0932 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0988 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1419/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1052 - sparse_categorical_accuracy: 0.9591\n",
      "Epoch 1419: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0935 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.1001 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1420/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.0973 - sparse_categorical_accuracy: 0.9575\n",
      "Epoch 1420: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0872 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0948 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1421/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0866 - sparse_categorical_accuracy: 0.9729\n",
      "Epoch 1421: val_loss did not improve from 0.09387\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0838 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.1005 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1422/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0739 - sparse_categorical_accuracy: 0.9792\n",
      "Epoch 1422: val_loss improved from 0.09387 to 0.09383, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0733 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.0938 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1423/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.1248 - sparse_categorical_accuracy: 0.9484\n",
      "Epoch 1423: val_loss did not improve from 0.09383\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1083 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.0965 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1424/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1074 - sparse_categorical_accuracy: 0.9634\n",
      "Epoch 1424: val_loss did not improve from 0.09383\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1127 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0990 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1425/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0919 - sparse_categorical_accuracy: 0.9644\n",
      "Epoch 1425: val_loss did not improve from 0.09383\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0919 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1045 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1426/10000\n",
      "22/34 [==================>...........] - ETA: 0s - loss: 0.0795 - sparse_categorical_accuracy: 0.9716\n",
      "Epoch 1426: val_loss did not improve from 0.09383\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0975 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0965 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1427/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.1017 - sparse_categorical_accuracy: 0.9565\n",
      "Epoch 1427: val_loss did not improve from 0.09383\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0998 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.0965 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1428/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0944 - sparse_categorical_accuracy: 0.9640\n",
      "Epoch 1428: val_loss did not improve from 0.09383\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0938 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0991 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1429/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0840 - sparse_categorical_accuracy: 0.9707\n",
      "Epoch 1429: val_loss did not improve from 0.09383\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0918 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0989 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1430/10000\n",
      "20/34 [================>.............] - ETA: 0s - loss: 0.0919 - sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1430: val_loss improved from 0.09383 to 0.09228, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0902 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0923 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1431/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0859 - sparse_categorical_accuracy: 0.9629\n",
      "Epoch 1431: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0838 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1025 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1432/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1051 - sparse_categorical_accuracy: 0.9576\n",
      "Epoch 1432: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0980 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.0990 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1433/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.0824 - sparse_categorical_accuracy: 0.9732\n",
      "Epoch 1433: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0820 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0936 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1434/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1126 - sparse_categorical_accuracy: 0.9609\n",
      "Epoch 1434: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1060 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0992 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1435/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0991 - sparse_categorical_accuracy: 0.9708\n",
      "Epoch 1435: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0971 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.1083 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1436/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0846 - sparse_categorical_accuracy: 0.9745\n",
      "Epoch 1436: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0817 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0981 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1437/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.0854 - sparse_categorical_accuracy: 0.9792\n",
      "Epoch 1437: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0989 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0974 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1438/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0912 - sparse_categorical_accuracy: 0.9716\n",
      "Epoch 1438: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0906 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0955 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1439/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0860 - sparse_categorical_accuracy: 0.9698\n",
      "Epoch 1439: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0874 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0977 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1440/10000\n",
      "22/34 [==================>...........] - ETA: 0s - loss: 0.0855 - sparse_categorical_accuracy: 0.9773\n",
      "Epoch 1440: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0932 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0968 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1441/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.0767 - sparse_categorical_accuracy: 0.9760\n",
      "Epoch 1441: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0902 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1001 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1442/10000\n",
      "22/34 [==================>...........] - ETA: 0s - loss: 0.1119 - sparse_categorical_accuracy: 0.9517\n",
      "Epoch 1442: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1025 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.0970 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1443/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.0923 - sparse_categorical_accuracy: 0.9725\n",
      "Epoch 1443: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0918 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.1011 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1444/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0871 - sparse_categorical_accuracy: 0.9688\n",
      "Epoch 1444: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0906 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.1066 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1445/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0980 - sparse_categorical_accuracy: 0.9617\n",
      "Epoch 1445: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0935 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0936 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1446/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0794 - sparse_categorical_accuracy: 0.9688\n",
      "Epoch 1446: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0792 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0948 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1447/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.0777 - sparse_categorical_accuracy: 0.9800\n",
      "Epoch 1447: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0909 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0944 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1448/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0977 - sparse_categorical_accuracy: 0.9678\n",
      "Epoch 1448: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0968 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1000 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1449/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1010 - sparse_categorical_accuracy: 0.9682\n",
      "Epoch 1449: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1010 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0986 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1450/10000\n",
      "20/34 [================>.............] - ETA: 0s - loss: 0.0595 - sparse_categorical_accuracy: 0.9875\n",
      "Epoch 1450: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0830 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0976 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1451/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1060 - sparse_categorical_accuracy: 0.9700\n",
      "Epoch 1451: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1060 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0933 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1452/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.0828 - sparse_categorical_accuracy: 0.9783\n",
      "Epoch 1452: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0830 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.1016 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1453/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.0887 - sparse_categorical_accuracy: 0.9714\n",
      "Epoch 1453: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0916 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0979 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1454/10000\n",
      "22/34 [==================>...........] - ETA: 0s - loss: 0.1052 - sparse_categorical_accuracy: 0.9688\n",
      "Epoch 1454: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1118 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.1007 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1455/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.1030 - sparse_categorical_accuracy: 0.9635\n",
      "Epoch 1455: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0989 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0955 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1456/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0724 - sparse_categorical_accuracy: 0.9838\n",
      "Epoch 1456: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0774 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.0975 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1457/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.0924 - sparse_categorical_accuracy: 0.9688\n",
      "Epoch 1457: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0935 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0968 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1458/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0999 - sparse_categorical_accuracy: 0.9653\n",
      "Epoch 1458: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0988 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0998 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1459/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0842 - sparse_categorical_accuracy: 0.9678\n",
      "Epoch 1459: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0893 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0990 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1460/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0770 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 1460: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0839 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0942 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1461/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0886 - sparse_categorical_accuracy: 0.9688\n",
      "Epoch 1461: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0890 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0983 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1462/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0970 - sparse_categorical_accuracy: 0.9551\n",
      "Epoch 1462: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0953 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.0951 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1463/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0826 - sparse_categorical_accuracy: 0.9682\n",
      "Epoch 1463: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0826 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0928 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1464/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0969 - sparse_categorical_accuracy: 0.9716\n",
      "Epoch 1464: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0959 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0923 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1465/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0882 - sparse_categorical_accuracy: 0.9754\n",
      "Epoch 1465: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0877 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0955 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1466/10000\n",
      "21/34 [=================>............] - ETA: 0s - loss: 0.0899 - sparse_categorical_accuracy: 0.9702\n",
      "Epoch 1466: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0834 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0934 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1467/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.0844 - sparse_categorical_accuracy: 0.9643\n",
      "Epoch 1467: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0939 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.1021 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1468/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0998 - sparse_categorical_accuracy: 0.9698\n",
      "Epoch 1468: val_loss did not improve from 0.09228\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0987 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0941 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1469/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0928 - sparse_categorical_accuracy: 0.9769\n",
      "Epoch 1469: val_loss improved from 0.09228 to 0.09155, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0855 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.0915 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1470/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.1004 - sparse_categorical_accuracy: 0.9650\n",
      "Epoch 1470: val_loss did not improve from 0.09155\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0994 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0929 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1471/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.0954 - sparse_categorical_accuracy: 0.9643\n",
      "Epoch 1471: val_loss did not improve from 0.09155\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0919 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0975 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1472/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0874 - sparse_categorical_accuracy: 0.9813\n",
      "Epoch 1472: val_loss did not improve from 0.09155\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0874 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.0935 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1473/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0938 - sparse_categorical_accuracy: 0.9738\n",
      "Epoch 1473: val_loss improved from 0.09155 to 0.09108, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0993 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0911 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1474/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.0629 - sparse_categorical_accuracy: 0.9826\n",
      "Epoch 1474: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0863 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0939 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1475/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.0942 - sparse_categorical_accuracy: 0.9688\n",
      "Epoch 1475: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1002 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0952 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1476/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0915 - sparse_categorical_accuracy: 0.9698\n",
      "Epoch 1476: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0929 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0963 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1477/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0855 - sparse_categorical_accuracy: 0.9688\n",
      "Epoch 1477: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0901 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0968 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1478/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0931 - sparse_categorical_accuracy: 0.9597\n",
      "Epoch 1478: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0916 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.0939 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1479/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0921 - sparse_categorical_accuracy: 0.9678\n",
      "Epoch 1479: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0918 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0950 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1480/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0831 - sparse_categorical_accuracy: 0.9813\n",
      "Epoch 1480: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0831 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.0952 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1481/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0958 - sparse_categorical_accuracy: 0.9640\n",
      "Epoch 1481: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0950 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0995 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1482/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1220 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 1482: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1131 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0941 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1483/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0828 - sparse_categorical_accuracy: 0.9729\n",
      "Epoch 1483: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0856 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.1001 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1484/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1014 - sparse_categorical_accuracy: 0.9604\n",
      "Epoch 1484: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0988 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.0928 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1485/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0903 - sparse_categorical_accuracy: 0.9659\n",
      "Epoch 1485: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0894 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0981 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1486/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.0800 - sparse_categorical_accuracy: 0.9757\n",
      "Epoch 1486: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0864 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0943 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1487/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1045 - sparse_categorical_accuracy: 0.9577\n",
      "Epoch 1487: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0995 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.0969 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1488/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1003 - sparse_categorical_accuracy: 0.9609\n",
      "Epoch 1488: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1011 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.0920 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1489/10000\n",
      "19/34 [===============>..............] - ETA: 0s - loss: 0.1035 - sparse_categorical_accuracy: 0.9572\n",
      "Epoch 1489: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0938 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0941 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1490/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.0977 - sparse_categorical_accuracy: 0.9675\n",
      "Epoch 1490: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1130 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1080 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1491/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0967 - sparse_categorical_accuracy: 0.9718\n",
      "Epoch 1491: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0924 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0920 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1492/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1072 - sparse_categorical_accuracy: 0.9710\n",
      "Epoch 1492: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1064 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0955 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1493/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0957 - sparse_categorical_accuracy: 0.9640\n",
      "Epoch 1493: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0970 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0984 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1494/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0986 - sparse_categorical_accuracy: 0.9640\n",
      "Epoch 1494: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0998 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.1007 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1495/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0880 - sparse_categorical_accuracy: 0.9750\n",
      "Epoch 1495: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0905 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.1005 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1496/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0933 - sparse_categorical_accuracy: 0.9634\n",
      "Epoch 1496: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0930 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0937 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1497/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.0861 - sparse_categorical_accuracy: 0.9712\n",
      "Epoch 1497: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0796 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0926 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1498/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0967 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 1498: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0958 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.0937 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1499/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1022 - sparse_categorical_accuracy: 0.9665\n",
      "Epoch 1499: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1008 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1000 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1500/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0869 - sparse_categorical_accuracy: 0.9769\n",
      "Epoch 1500: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0897 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.1042 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1501/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0994 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 1501: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0950 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0926 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1502/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.1096 - sparse_categorical_accuracy: 0.9516\n",
      "Epoch 1502: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1075 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.0977 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1503/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1024 - sparse_categorical_accuracy: 0.9527\n",
      "Epoch 1503: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1021 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.0957 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1504/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0894 - sparse_categorical_accuracy: 0.9655\n",
      "Epoch 1504: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0866 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0918 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1505/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1041 - sparse_categorical_accuracy: 0.9644\n",
      "Epoch 1505: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1041 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0930 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1506/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0957 - sparse_categorical_accuracy: 0.9698\n",
      "Epoch 1506: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0921 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0913 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1507/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0815 - sparse_categorical_accuracy: 0.9697\n",
      "Epoch 1507: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0822 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1055 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1508/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.0981 - sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1508: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0896 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0958 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1509/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0882 - sparse_categorical_accuracy: 0.9644\n",
      "Epoch 1509: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0882 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0975 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1510/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0937 - sparse_categorical_accuracy: 0.9609\n",
      "Epoch 1510: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0907 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0976 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1511/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0870 - sparse_categorical_accuracy: 0.9699\n",
      "Epoch 1511: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0769 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.1040 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1512/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.0889 - sparse_categorical_accuracy: 0.9754\n",
      "Epoch 1512: val_loss did not improve from 0.09108\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0898 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0948 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1513/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0818 - sparse_categorical_accuracy: 0.9727\n",
      "Epoch 1513: val_loss improved from 0.09108 to 0.09028, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0802 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0903 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1514/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0915 - sparse_categorical_accuracy: 0.9677\n",
      "Epoch 1514: val_loss did not improve from 0.09028\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0869 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0969 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1515/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0939 - sparse_categorical_accuracy: 0.9625\n",
      "Epoch 1515: val_loss did not improve from 0.09028\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0939 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0983 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1516/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.0967 - sparse_categorical_accuracy: 0.9639\n",
      "Epoch 1516: val_loss did not improve from 0.09028\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1004 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.0982 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1517/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1084 - sparse_categorical_accuracy: 0.9554\n",
      "Epoch 1517: val_loss did not improve from 0.09028\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1068 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.0942 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1518/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0920 - sparse_categorical_accuracy: 0.9668\n",
      "Epoch 1518: val_loss did not improve from 0.09028\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0946 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.1075 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1519/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.0968 - sparse_categorical_accuracy: 0.9600\n",
      "Epoch 1519: val_loss did not improve from 0.09028\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0911 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0931 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1520/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0913 - sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1520: val_loss did not improve from 0.09028\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0913 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0997 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1521/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.0946 - sparse_categorical_accuracy: 0.9732\n",
      "Epoch 1521: val_loss did not improve from 0.09028\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0922 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0925 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1522/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0839 - sparse_categorical_accuracy: 0.9718\n",
      "Epoch 1522: val_loss did not improve from 0.09028\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0803 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0950 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1523/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0832 - sparse_categorical_accuracy: 0.9722\n",
      "Epoch 1523: val_loss did not improve from 0.09028\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0863 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0960 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1524/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.0898 - sparse_categorical_accuracy: 0.9700\n",
      "Epoch 1524: val_loss did not improve from 0.09028\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0972 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0974 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1525/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0840 - sparse_categorical_accuracy: 0.9792\n",
      "Epoch 1525: val_loss improved from 0.09028 to 0.09021, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0857 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0902 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1526/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0836 - sparse_categorical_accuracy: 0.9745\n",
      "Epoch 1526: val_loss did not improve from 0.09021\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0833 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0998 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1527/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0931 - sparse_categorical_accuracy: 0.9697\n",
      "Epoch 1527: val_loss did not improve from 0.09021\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0923 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0946 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1528/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0824 - sparse_categorical_accuracy: 0.9621\n",
      "Epoch 1528: val_loss did not improve from 0.09021\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0822 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0947 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1529/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0961 - sparse_categorical_accuracy: 0.9625\n",
      "Epoch 1529: val_loss did not improve from 0.09021\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0961 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.1117 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1530/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.1023 - sparse_categorical_accuracy: 0.9598\n",
      "Epoch 1530: val_loss improved from 0.09021 to 0.08922, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0943 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0892 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1531/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0853 - sparse_categorical_accuracy: 0.9625\n",
      "Epoch 1531: val_loss did not improve from 0.08922\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0853 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0910 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1532/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0972 - sparse_categorical_accuracy: 0.9644\n",
      "Epoch 1532: val_loss did not improve from 0.08922\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0972 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0947 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1533/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0764 - sparse_categorical_accuracy: 0.9769\n",
      "Epoch 1533: val_loss did not improve from 0.08922\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0830 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0921 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1534/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1035 - sparse_categorical_accuracy: 0.9688\n",
      "Epoch 1534: val_loss did not improve from 0.08922\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0997 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1069 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1535/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0805 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 1535: val_loss did not improve from 0.08922\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0804 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0939 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1536/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0881 - sparse_categorical_accuracy: 0.9676\n",
      "Epoch 1536: val_loss did not improve from 0.08922\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0938 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0933 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1537/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0850 - sparse_categorical_accuracy: 0.9697\n",
      "Epoch 1537: val_loss did not improve from 0.08922\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0847 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0908 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1538/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0876 - sparse_categorical_accuracy: 0.9707\n",
      "Epoch 1538: val_loss did not improve from 0.08922\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0853 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.1044 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1539/10000\n",
      "22/34 [==================>...........] - ETA: 0s - loss: 0.1018 - sparse_categorical_accuracy: 0.9744\n",
      "Epoch 1539: val_loss did not improve from 0.08922\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0941 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0918 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1540/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0930 - sparse_categorical_accuracy: 0.9718\n",
      "Epoch 1540: val_loss did not improve from 0.08922\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0946 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0943 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1541/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0980 - sparse_categorical_accuracy: 0.9697\n",
      "Epoch 1541: val_loss did not improve from 0.08922\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0981 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.1045 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1542/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0906 - sparse_categorical_accuracy: 0.9678\n",
      "Epoch 1542: val_loss did not improve from 0.08922\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0908 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0932 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1543/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0805 - sparse_categorical_accuracy: 0.9766\n",
      "Epoch 1543: val_loss did not improve from 0.08922\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0794 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0898 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1544/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0916 - sparse_categorical_accuracy: 0.9738\n",
      "Epoch 1544: val_loss did not improve from 0.08922\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0916 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0979 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1545/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0890 - sparse_categorical_accuracy: 0.9556\n",
      "Epoch 1545: val_loss did not improve from 0.08922\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0881 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1012 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1546/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0927 - sparse_categorical_accuracy: 0.9621\n",
      "Epoch 1546: val_loss did not improve from 0.08922\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0924 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0960 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1547/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0950 - sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1547: val_loss did not improve from 0.08922\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0950 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0927 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1548/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.0776 - sparse_categorical_accuracy: 0.9784\n",
      "Epoch 1548: val_loss did not improve from 0.08922\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0832 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0908 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1549/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0918 - sparse_categorical_accuracy: 0.9678\n",
      "Epoch 1549: val_loss did not improve from 0.08922\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0933 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.1026 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1550/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.0882 - sparse_categorical_accuracy: 0.9712\n",
      "Epoch 1550: val_loss did not improve from 0.08922\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0833 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0924 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1551/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0749 - sparse_categorical_accuracy: 0.9735\n",
      "Epoch 1551: val_loss did not improve from 0.08922\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0741 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0946 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1552/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.1000 - sparse_categorical_accuracy: 0.9590\n",
      "Epoch 1552: val_loss did not improve from 0.08922\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1058 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.0969 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1553/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1025 - sparse_categorical_accuracy: 0.9564\n",
      "Epoch 1553: val_loss did not improve from 0.08922\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1066 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.0930 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1554/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0809 - sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1554: val_loss did not improve from 0.08922\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0809 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0960 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1555/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.0937 - sparse_categorical_accuracy: 0.9688\n",
      "Epoch 1555: val_loss did not improve from 0.08922\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0809 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0911 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1556/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.0743 - sparse_categorical_accuracy: 0.9675\n",
      "Epoch 1556: val_loss improved from 0.08922 to 0.08892, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0869 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0889 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1557/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0837 - sparse_categorical_accuracy: 0.9727\n",
      "Epoch 1557: val_loss did not improve from 0.08892\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0834 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0947 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1558/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1013 - sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1558: val_loss did not improve from 0.08892\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1013 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0915 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1559/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0828 - sparse_categorical_accuracy: 0.9727\n",
      "Epoch 1559: val_loss did not improve from 0.08892\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0823 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0975 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1560/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0843 - sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1560: val_loss did not improve from 0.08892\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0843 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0935 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1561/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0837 - sparse_categorical_accuracy: 0.9773\n",
      "Epoch 1561: val_loss did not improve from 0.08892\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0845 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0924 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1562/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0832 - sparse_categorical_accuracy: 0.9640\n",
      "Epoch 1562: val_loss did not improve from 0.08892\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0834 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0993 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1563/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0916 - sparse_categorical_accuracy: 0.9678\n",
      "Epoch 1563: val_loss did not improve from 0.08892\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0912 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0948 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1564/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0876 - sparse_categorical_accuracy: 0.9727\n",
      "Epoch 1564: val_loss did not improve from 0.08892\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0905 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0904 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1565/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0883 - sparse_categorical_accuracy: 0.9668\n",
      "Epoch 1565: val_loss did not improve from 0.08892\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0873 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0970 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1566/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0893 - sparse_categorical_accuracy: 0.9708\n",
      "Epoch 1566: val_loss did not improve from 0.08892\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0840 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0938 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1567/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0890 - sparse_categorical_accuracy: 0.9707\n",
      "Epoch 1567: val_loss did not improve from 0.08892\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0883 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0998 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1568/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0870 - sparse_categorical_accuracy: 0.9682\n",
      "Epoch 1568: val_loss did not improve from 0.08892\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0870 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0971 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1569/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0951 - sparse_categorical_accuracy: 0.9698\n",
      "Epoch 1569: val_loss did not improve from 0.08892\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0939 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0954 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1570/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0708 - sparse_categorical_accuracy: 0.9805\n",
      "Epoch 1570: val_loss did not improve from 0.08892\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0699 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.0893 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1571/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0870 - sparse_categorical_accuracy: 0.9677\n",
      "Epoch 1571: val_loss did not improve from 0.08892\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0862 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0973 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1572/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0812 - sparse_categorical_accuracy: 0.9720\n",
      "Epoch 1572: val_loss did not improve from 0.08892\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0776 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0948 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1573/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0879 - sparse_categorical_accuracy: 0.9602\n",
      "Epoch 1573: val_loss did not improve from 0.08892\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0870 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.0924 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1574/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0886 - sparse_categorical_accuracy: 0.9716\n",
      "Epoch 1574: val_loss did not improve from 0.08892\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0876 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0931 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1575/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0956 - sparse_categorical_accuracy: 0.9678\n",
      "Epoch 1575: val_loss did not improve from 0.08892\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0966 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0918 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1576/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0971 - sparse_categorical_accuracy: 0.9688\n",
      "Epoch 1576: val_loss did not improve from 0.08892\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0978 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0904 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1577/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0863 - sparse_categorical_accuracy: 0.9771\n",
      "Epoch 1577: val_loss did not improve from 0.08892\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0919 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0914 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1578/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0853 - sparse_categorical_accuracy: 0.9644\n",
      "Epoch 1578: val_loss did not improve from 0.08892\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0853 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1068 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1579/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0923 - sparse_categorical_accuracy: 0.9629\n",
      "Epoch 1579: val_loss did not improve from 0.08892\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0931 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1053 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1580/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0922 - sparse_categorical_accuracy: 0.9640\n",
      "Epoch 1580: val_loss did not improve from 0.08892\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0919 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0917 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1581/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0980 - sparse_categorical_accuracy: 0.9640\n",
      "Epoch 1581: val_loss did not improve from 0.08892\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0972 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0921 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1582/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0781 - sparse_categorical_accuracy: 0.9754\n",
      "Epoch 1582: val_loss did not improve from 0.08892\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0780 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0913 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1583/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0874 - sparse_categorical_accuracy: 0.9682\n",
      "Epoch 1583: val_loss did not improve from 0.08892\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0874 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1025 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1584/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0865 - sparse_categorical_accuracy: 0.9678\n",
      "Epoch 1584: val_loss did not improve from 0.08892\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0867 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0961 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1585/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0961 - sparse_categorical_accuracy: 0.9625\n",
      "Epoch 1585: val_loss did not improve from 0.08892\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0961 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0897 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1586/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1044 - sparse_categorical_accuracy: 0.9697\n",
      "Epoch 1586: val_loss did not improve from 0.08892\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1111 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0925 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1587/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0823 - sparse_categorical_accuracy: 0.9716\n",
      "Epoch 1587: val_loss improved from 0.08892 to 0.08828, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0818 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0883 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1588/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0865 - sparse_categorical_accuracy: 0.9775\n",
      "Epoch 1588: val_loss did not improve from 0.08828\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0865 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0892 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1589/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0927 - sparse_categorical_accuracy: 0.9716\n",
      "Epoch 1589: val_loss improved from 0.08828 to 0.08814, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0925 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0881 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1590/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0815 - sparse_categorical_accuracy: 0.9678\n",
      "Epoch 1590: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0821 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0909 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1591/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0611 - sparse_categorical_accuracy: 0.9824\n",
      "Epoch 1591: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0684 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0924 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1592/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0817 - sparse_categorical_accuracy: 0.9773\n",
      "Epoch 1592: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0841 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0906 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1593/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0959 - sparse_categorical_accuracy: 0.9707\n",
      "Epoch 1593: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0985 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1001 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1594/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0896 - sparse_categorical_accuracy: 0.9716\n",
      "Epoch 1594: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0924 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0894 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1595/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0909 - sparse_categorical_accuracy: 0.9697\n",
      "Epoch 1595: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0915 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0901 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1596/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0824 - sparse_categorical_accuracy: 0.9682\n",
      "Epoch 1596: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0824 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0939 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1597/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0865 - sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1597: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0865 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0883 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1598/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0823 - sparse_categorical_accuracy: 0.9729\n",
      "Epoch 1598: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0793 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0954 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1599/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0818 - sparse_categorical_accuracy: 0.9773\n",
      "Epoch 1599: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0822 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0920 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1600/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0812 - sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1600: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0812 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0943 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1601/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0831 - sparse_categorical_accuracy: 0.9707\n",
      "Epoch 1601: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0820 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0902 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1602/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0849 - sparse_categorical_accuracy: 0.9727\n",
      "Epoch 1602: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0846 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.1002 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1603/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0825 - sparse_categorical_accuracy: 0.9738\n",
      "Epoch 1603: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0825 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0967 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1604/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1018 - sparse_categorical_accuracy: 0.9602\n",
      "Epoch 1604: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1011 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.0953 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1605/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0975 - sparse_categorical_accuracy: 0.9648\n",
      "Epoch 1605: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0962 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0932 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1606/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0981 - sparse_categorical_accuracy: 0.9564\n",
      "Epoch 1606: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0971 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1006 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1607/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0832 - sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1607: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0832 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0902 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1608/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0735 - sparse_categorical_accuracy: 0.9766\n",
      "Epoch 1608: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0755 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0927 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1609/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0919 - sparse_categorical_accuracy: 0.9659\n",
      "Epoch 1609: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0921 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0889 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1610/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0968 - sparse_categorical_accuracy: 0.9621\n",
      "Epoch 1610: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1013 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.0883 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1611/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0829 - sparse_categorical_accuracy: 0.9697\n",
      "Epoch 1611: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0821 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0941 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1612/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1100 - sparse_categorical_accuracy: 0.9659\n",
      "Epoch 1612: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1090 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0930 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1613/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0842 - sparse_categorical_accuracy: 0.9677\n",
      "Epoch 1613: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0807 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0933 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1614/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0667 - sparse_categorical_accuracy: 0.9754\n",
      "Epoch 1614: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0712 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0885 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1615/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0923 - sparse_categorical_accuracy: 0.9682\n",
      "Epoch 1615: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0923 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0945 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1616/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0984 - sparse_categorical_accuracy: 0.9668\n",
      "Epoch 1616: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0992 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0890 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1617/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0696 - sparse_categorical_accuracy: 0.9763\n",
      "Epoch 1617: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0690 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0988 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1618/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0805 - sparse_categorical_accuracy: 0.9697\n",
      "Epoch 1618: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0806 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0888 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1619/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0796 - sparse_categorical_accuracy: 0.9792\n",
      "Epoch 1619: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0797 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.0942 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1620/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0834 - sparse_categorical_accuracy: 0.9754\n",
      "Epoch 1620: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0830 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0911 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1621/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0906 - sparse_categorical_accuracy: 0.9648\n",
      "Epoch 1621: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0883 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0989 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1622/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0857 - sparse_categorical_accuracy: 0.9634\n",
      "Epoch 1622: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0859 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0911 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1623/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0856 - sparse_categorical_accuracy: 0.9688\n",
      "Epoch 1623: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0830 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0883 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1624/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0879 - sparse_categorical_accuracy: 0.9668\n",
      "Epoch 1624: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0859 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0994 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1625/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0838 - sparse_categorical_accuracy: 0.9729\n",
      "Epoch 1625: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0857 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.1021 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1626/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.0927 - sparse_categorical_accuracy: 0.9665\n",
      "Epoch 1626: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0896 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0905 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1627/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0848 - sparse_categorical_accuracy: 0.9766\n",
      "Epoch 1627: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0886 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0965 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1628/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.0808 - sparse_categorical_accuracy: 0.9675\n",
      "Epoch 1628: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0823 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0902 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1629/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0816 - sparse_categorical_accuracy: 0.9727\n",
      "Epoch 1629: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0815 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0908 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1630/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0852 - sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1630: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0852 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0924 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1631/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0779 - sparse_categorical_accuracy: 0.9754\n",
      "Epoch 1631: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0792 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0899 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1632/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0922 - sparse_categorical_accuracy: 0.9625\n",
      "Epoch 1632: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0868 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0949 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1633/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0863 - sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1633: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0863 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0915 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1634/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1024 - sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1634: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1024 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0891 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1635/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0798 - sparse_categorical_accuracy: 0.9700\n",
      "Epoch 1635: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0798 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0954 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1636/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0850 - sparse_categorical_accuracy: 0.9812\n",
      "Epoch 1636: val_loss did not improve from 0.08814\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0823 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.0935 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1637/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0813 - sparse_categorical_accuracy: 0.9766\n",
      "Epoch 1637: val_loss improved from 0.08814 to 0.08739, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0802 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0874 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1638/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0908 - sparse_categorical_accuracy: 0.9735\n",
      "Epoch 1638: val_loss did not improve from 0.08739\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0902 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0907 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1639/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0816 - sparse_categorical_accuracy: 0.9766\n",
      "Epoch 1639: val_loss did not improve from 0.08739\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0787 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0933 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1640/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.0735 - sparse_categorical_accuracy: 0.9740\n",
      "Epoch 1640: val_loss did not improve from 0.08739\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0795 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0913 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1641/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0872 - sparse_categorical_accuracy: 0.9727\n",
      "Epoch 1641: val_loss did not improve from 0.08739\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0853 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0911 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1642/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0730 - sparse_categorical_accuracy: 0.9785\n",
      "Epoch 1642: val_loss did not improve from 0.08739\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0726 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.0915 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1643/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.0965 - sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1643: val_loss did not improve from 0.08739\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0952 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0916 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1644/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.0683 - sparse_categorical_accuracy: 0.9792\n",
      "Epoch 1644: val_loss did not improve from 0.08739\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0696 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.0893 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1645/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.0759 - sparse_categorical_accuracy: 0.9701\n",
      "Epoch 1645: val_loss did not improve from 0.08739\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0874 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0953 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1646/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0936 - sparse_categorical_accuracy: 0.9659\n",
      "Epoch 1646: val_loss improved from 0.08739 to 0.08681, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0927 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0868 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1647/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0946 - sparse_categorical_accuracy: 0.9648\n",
      "Epoch 1647: val_loss did not improve from 0.08681\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0919 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0962 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1648/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0948 - sparse_categorical_accuracy: 0.9668\n",
      "Epoch 1648: val_loss did not improve from 0.08681\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0920 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0933 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1649/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0749 - sparse_categorical_accuracy: 0.9766\n",
      "Epoch 1649: val_loss did not improve from 0.08681\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0737 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0920 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1650/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0819 - sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1650: val_loss did not improve from 0.08681\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0819 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0912 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1651/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0994 - sparse_categorical_accuracy: 0.9677\n",
      "Epoch 1651: val_loss did not improve from 0.08681\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1042 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1092 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1652/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0931 - sparse_categorical_accuracy: 0.9676\n",
      "Epoch 1652: val_loss did not improve from 0.08681\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0955 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0926 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1653/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0799 - sparse_categorical_accuracy: 0.9771\n",
      "Epoch 1653: val_loss improved from 0.08681 to 0.08636, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0783 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0864 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1654/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0928 - sparse_categorical_accuracy: 0.9542\n",
      "Epoch 1654: val_loss did not improve from 0.08636\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0881 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.0970 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1655/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0796 - sparse_categorical_accuracy: 0.9833\n",
      "Epoch 1655: val_loss did not improve from 0.08636\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0751 - sparse_categorical_accuracy: 0.9850 - val_loss: 0.0884 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1656/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.0844 - sparse_categorical_accuracy: 0.9736\n",
      "Epoch 1656: val_loss did not improve from 0.08636\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0839 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0930 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1657/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0679 - sparse_categorical_accuracy: 0.9806\n",
      "Epoch 1657: val_loss did not improve from 0.08636\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0689 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0877 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1658/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0858 - sparse_categorical_accuracy: 0.9708\n",
      "Epoch 1658: val_loss did not improve from 0.08636\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0818 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0883 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1659/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.0780 - sparse_categorical_accuracy: 0.9736\n",
      "Epoch 1659: val_loss did not improve from 0.08636\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0779 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.1047 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1660/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0814 - sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1660: val_loss did not improve from 0.08636\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0814 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0933 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1661/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0900 - sparse_categorical_accuracy: 0.9659\n",
      "Epoch 1661: val_loss did not improve from 0.08636\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0897 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0917 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1662/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0792 - sparse_categorical_accuracy: 0.9698\n",
      "Epoch 1662: val_loss did not improve from 0.08636\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0750 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0882 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1663/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0724 - sparse_categorical_accuracy: 0.9655\n",
      "Epoch 1663: val_loss did not improve from 0.08636\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0812 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.1005 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1664/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.0830 - sparse_categorical_accuracy: 0.9832\n",
      "Epoch 1664: val_loss did not improve from 0.08636\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0787 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.0932 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1665/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.1063 - sparse_categorical_accuracy: 0.9569\n",
      "Epoch 1665: val_loss did not improve from 0.08636\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1000 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.0980 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1666/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0808 - sparse_categorical_accuracy: 0.9792\n",
      "Epoch 1666: val_loss did not improve from 0.08636\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0894 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0933 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1667/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0847 - sparse_categorical_accuracy: 0.9677\n",
      "Epoch 1667: val_loss did not improve from 0.08636\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0804 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0972 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1668/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.0770 - sparse_categorical_accuracy: 0.9808\n",
      "Epoch 1668: val_loss did not improve from 0.08636\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0816 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0911 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1669/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0925 - sparse_categorical_accuracy: 0.9746\n",
      "Epoch 1669: val_loss did not improve from 0.08636\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0894 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0894 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1670/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.0689 - sparse_categorical_accuracy: 0.9784\n",
      "Epoch 1670: val_loss did not improve from 0.08636\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0710 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0912 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1671/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1067 - sparse_categorical_accuracy: 0.9618\n",
      "Epoch 1671: val_loss did not improve from 0.08636\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0880 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0920 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1672/10000\n",
      "21/34 [=================>............] - ETA: 0s - loss: 0.0609 - sparse_categorical_accuracy: 0.9851\n",
      "Epoch 1672: val_loss did not improve from 0.08636\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0781 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0884 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1673/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0743 - sparse_categorical_accuracy: 0.9720\n",
      "Epoch 1673: val_loss did not improve from 0.08636\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0748 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.1035 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1674/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0709 - sparse_categorical_accuracy: 0.9718\n",
      "Epoch 1674: val_loss did not improve from 0.08636\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0728 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0960 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1675/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0814 - sparse_categorical_accuracy: 0.9758\n",
      "Epoch 1675: val_loss did not improve from 0.08636\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0850 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0902 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1676/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0809 - sparse_categorical_accuracy: 0.9757\n",
      "Epoch 1676: val_loss did not improve from 0.08636\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0809 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0938 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1677/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0874 - sparse_categorical_accuracy: 0.9718\n",
      "Epoch 1677: val_loss did not improve from 0.08636\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0895 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0896 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1678/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0856 - sparse_categorical_accuracy: 0.9754\n",
      "Epoch 1678: val_loss improved from 0.08636 to 0.08590, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0848 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0859 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1679/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0767 - sparse_categorical_accuracy: 0.9699\n",
      "Epoch 1679: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0856 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0901 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1680/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.0867 - sparse_categorical_accuracy: 0.9760\n",
      "Epoch 1680: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0763 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.0901 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1681/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0896 - sparse_categorical_accuracy: 0.9769\n",
      "Epoch 1681: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0865 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.1033 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1682/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0821 - sparse_categorical_accuracy: 0.9735\n",
      "Epoch 1682: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0815 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0884 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1683/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0801 - sparse_categorical_accuracy: 0.9741\n",
      "Epoch 1683: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0850 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0892 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1684/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.0760 - sparse_categorical_accuracy: 0.9766\n",
      "Epoch 1684: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0766 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0930 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1685/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0857 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 1685: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0830 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0950 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1686/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0951 - sparse_categorical_accuracy: 0.9646\n",
      "Epoch 1686: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0925 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0913 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1687/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0987 - sparse_categorical_accuracy: 0.9655\n",
      "Epoch 1687: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0944 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0911 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1688/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0826 - sparse_categorical_accuracy: 0.9668\n",
      "Epoch 1688: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0835 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0941 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1689/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0823 - sparse_categorical_accuracy: 0.9707\n",
      "Epoch 1689: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0820 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0879 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1690/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0871 - sparse_categorical_accuracy: 0.9757\n",
      "Epoch 1690: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0871 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0958 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1691/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.0704 - sparse_categorical_accuracy: 0.9750\n",
      "Epoch 1691: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0770 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0902 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1692/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.0788 - sparse_categorical_accuracy: 0.9710\n",
      "Epoch 1692: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0921 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0932 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1693/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.0940 - sparse_categorical_accuracy: 0.9643\n",
      "Epoch 1693: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0920 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0923 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1694/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.0805 - sparse_categorical_accuracy: 0.9639\n",
      "Epoch 1694: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0728 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0921 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1695/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0698 - sparse_categorical_accuracy: 0.9784\n",
      "Epoch 1695: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0677 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.0903 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1696/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0795 - sparse_categorical_accuracy: 0.9830\n",
      "Epoch 1696: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0796 - sparse_categorical_accuracy: 0.9831 - val_loss: 0.0877 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1697/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.0977 - sparse_categorical_accuracy: 0.9732\n",
      "Epoch 1697: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.0979 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0903 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1698/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0866 - sparse_categorical_accuracy: 0.9655\n",
      "Epoch 1698: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0868 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0934 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1699/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0894 - sparse_categorical_accuracy: 0.9700\n",
      "Epoch 1699: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0894 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0874 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1700/10000\n",
      "22/34 [==================>...........] - ETA: 0s - loss: 0.0921 - sparse_categorical_accuracy: 0.9716\n",
      "Epoch 1700: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0881 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0913 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1701/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0699 - sparse_categorical_accuracy: 0.9766\n",
      "Epoch 1701: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0690 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0950 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1702/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.0937 - sparse_categorical_accuracy: 0.9650\n",
      "Epoch 1702: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0942 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0895 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1703/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.1050 - sparse_categorical_accuracy: 0.9567\n",
      "Epoch 1703: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.1005 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.1023 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1704/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0756 - sparse_categorical_accuracy: 0.9688\n",
      "Epoch 1704: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0753 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0997 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1705/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0790 - sparse_categorical_accuracy: 0.9766\n",
      "Epoch 1705: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0781 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.1032 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1706/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0847 - sparse_categorical_accuracy: 0.9708\n",
      "Epoch 1706: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0805 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0903 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1707/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0942 - sparse_categorical_accuracy: 0.9570\n",
      "Epoch 1707: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0941 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.1053 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1708/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0891 - sparse_categorical_accuracy: 0.9771\n",
      "Epoch 1708: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0932 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0997 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1709/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0663 - sparse_categorical_accuracy: 0.9784\n",
      "Epoch 1709: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0710 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0923 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1710/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0835 - sparse_categorical_accuracy: 0.9698\n",
      "Epoch 1710: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0854 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0910 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1711/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0860 - sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1711: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0860 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0999 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1712/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0838 - sparse_categorical_accuracy: 0.9727\n",
      "Epoch 1712: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0814 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0953 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1713/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0620 - sparse_categorical_accuracy: 0.9859\n",
      "Epoch 1713: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0657 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.0876 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1714/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0841 - sparse_categorical_accuracy: 0.9698\n",
      "Epoch 1714: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0804 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0972 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1715/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0809 - sparse_categorical_accuracy: 0.9698\n",
      "Epoch 1715: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0797 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0922 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1716/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.0804 - sparse_categorical_accuracy: 0.9688\n",
      "Epoch 1716: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0848 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0927 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1717/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0813 - sparse_categorical_accuracy: 0.9746\n",
      "Epoch 1717: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0829 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0898 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1718/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0853 - sparse_categorical_accuracy: 0.9754\n",
      "Epoch 1718: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0845 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0958 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1719/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0987 - sparse_categorical_accuracy: 0.9637\n",
      "Epoch 1719: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0937 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0898 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1720/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1149 - sparse_categorical_accuracy: 0.9602\n",
      "Epoch 1720: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.1138 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.0902 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1721/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0823 - sparse_categorical_accuracy: 0.9784\n",
      "Epoch 1721: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0815 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.0933 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1722/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0824 - sparse_categorical_accuracy: 0.9720\n",
      "Epoch 1722: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0809 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0910 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1723/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0856 - sparse_categorical_accuracy: 0.9698\n",
      "Epoch 1723: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0916 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0931 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1724/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0795 - sparse_categorical_accuracy: 0.9798\n",
      "Epoch 1724: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0785 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.0940 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1725/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.0794 - sparse_categorical_accuracy: 0.9821\n",
      "Epoch 1725: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0750 - sparse_categorical_accuracy: 0.9831 - val_loss: 0.0924 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1726/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0786 - sparse_categorical_accuracy: 0.9729\n",
      "Epoch 1726: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0775 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0999 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1727/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0859 - sparse_categorical_accuracy: 0.9746\n",
      "Epoch 1727: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0834 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.1024 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1728/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0758 - sparse_categorical_accuracy: 0.9766\n",
      "Epoch 1728: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0732 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0912 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1729/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.0673 - sparse_categorical_accuracy: 0.9870\n",
      "Epoch 1729: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0844 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0983 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1730/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0869 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 1730: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0846 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0885 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1731/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0737 - sparse_categorical_accuracy: 0.9785\n",
      "Epoch 1731: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0741 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.0945 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1732/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.0795 - sparse_categorical_accuracy: 0.9755\n",
      "Epoch 1732: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0805 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0925 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1733/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.0650 - sparse_categorical_accuracy: 0.9783\n",
      "Epoch 1733: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0704 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0951 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1734/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0771 - sparse_categorical_accuracy: 0.9729\n",
      "Epoch 1734: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0722 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.1028 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1735/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.0680 - sparse_categorical_accuracy: 0.9750\n",
      "Epoch 1735: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0743 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0923 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1736/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.0731 - sparse_categorical_accuracy: 0.9710\n",
      "Epoch 1736: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0857 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0891 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1737/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.0906 - sparse_categorical_accuracy: 0.9621\n",
      "Epoch 1737: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0901 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0875 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1738/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0770 - sparse_categorical_accuracy: 0.9766\n",
      "Epoch 1738: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0744 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0901 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1739/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0759 - sparse_categorical_accuracy: 0.9812\n",
      "Epoch 1739: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0728 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.0895 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1740/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.0644 - sparse_categorical_accuracy: 0.9799\n",
      "Epoch 1740: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0771 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0931 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1741/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.0864 - sparse_categorical_accuracy: 0.9621\n",
      "Epoch 1741: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0829 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0943 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1742/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0803 - sparse_categorical_accuracy: 0.9698\n",
      "Epoch 1742: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0888 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0901 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1743/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.0813 - sparse_categorical_accuracy: 0.9732\n",
      "Epoch 1743: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.0876 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0880 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1744/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.0794 - sparse_categorical_accuracy: 0.9732\n",
      "Epoch 1744: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 0.0792 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.1007 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1745/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0782 - sparse_categorical_accuracy: 0.9677\n",
      "Epoch 1745: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0795 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0872 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1746/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0748 - sparse_categorical_accuracy: 0.9720\n",
      "Epoch 1746: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0816 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.1028 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1747/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.0841 - sparse_categorical_accuracy: 0.9665\n",
      "Epoch 1747: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0777 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0914 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1748/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0738 - sparse_categorical_accuracy: 0.9698\n",
      "Epoch 1748: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0829 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1058 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1749/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0806 - sparse_categorical_accuracy: 0.9738\n",
      "Epoch 1749: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0797 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0885 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1750/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0957 - sparse_categorical_accuracy: 0.9646\n",
      "Epoch 1750: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0899 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0944 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1751/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0713 - sparse_categorical_accuracy: 0.9750\n",
      "Epoch 1751: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0820 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0943 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1752/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0835 - sparse_categorical_accuracy: 0.9778\n",
      "Epoch 1752: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0827 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0892 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1753/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0835 - sparse_categorical_accuracy: 0.9677\n",
      "Epoch 1753: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0901 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0910 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1754/10000\n",
      "22/34 [==================>...........] - ETA: 0s - loss: 0.0772 - sparse_categorical_accuracy: 0.9716\n",
      "Epoch 1754: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0873 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1044 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1755/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.0770 - sparse_categorical_accuracy: 0.9799\n",
      "Epoch 1755: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0754 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.0869 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1756/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0720 - sparse_categorical_accuracy: 0.9735\n",
      "Epoch 1756: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0717 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.1020 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1757/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.0621 - sparse_categorical_accuracy: 0.9725\n",
      "Epoch 1757: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0689 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0929 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1758/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0869 - sparse_categorical_accuracy: 0.9677\n",
      "Epoch 1758: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0867 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0896 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1759/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0920 - sparse_categorical_accuracy: 0.9617\n",
      "Epoch 1759: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0939 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0991 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1760/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0868 - sparse_categorical_accuracy: 0.9722\n",
      "Epoch 1760: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0851 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0923 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1761/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0744 - sparse_categorical_accuracy: 0.9738\n",
      "Epoch 1761: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0725 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0999 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1762/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0865 - sparse_categorical_accuracy: 0.9716\n",
      "Epoch 1762: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0858 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0907 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1763/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0900 - sparse_categorical_accuracy: 0.9707\n",
      "Epoch 1763: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0885 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0909 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1764/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0720 - sparse_categorical_accuracy: 0.9812\n",
      "Epoch 1764: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0672 - sparse_categorical_accuracy: 0.9831 - val_loss: 0.0925 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1765/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0713 - sparse_categorical_accuracy: 0.9729\n",
      "Epoch 1765: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0741 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0992 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1766/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.0712 - sparse_categorical_accuracy: 0.9844\n",
      "Epoch 1766: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0731 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.0925 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1767/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0688 - sparse_categorical_accuracy: 0.9838\n",
      "Epoch 1767: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0739 - sparse_categorical_accuracy: 0.9831 - val_loss: 0.0914 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1768/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0897 - sparse_categorical_accuracy: 0.9707\n",
      "Epoch 1768: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0898 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0893 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1769/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0806 - sparse_categorical_accuracy: 0.9718\n",
      "Epoch 1769: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0785 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0871 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1770/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0835 - sparse_categorical_accuracy: 0.9677\n",
      "Epoch 1770: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0826 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0905 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1771/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0866 - sparse_categorical_accuracy: 0.9653\n",
      "Epoch 1771: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0896 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.0989 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1772/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0925 - sparse_categorical_accuracy: 0.9698\n",
      "Epoch 1772: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0883 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0893 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1773/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0861 - sparse_categorical_accuracy: 0.9727\n",
      "Epoch 1773: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0837 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0943 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1774/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0835 - sparse_categorical_accuracy: 0.9778\n",
      "Epoch 1774: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0818 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.0945 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1775/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0766 - sparse_categorical_accuracy: 0.9727\n",
      "Epoch 1775: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0742 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0908 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1776/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.0825 - sparse_categorical_accuracy: 0.9650\n",
      "Epoch 1776: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0744 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.1016 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1777/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0674 - sparse_categorical_accuracy: 0.9758\n",
      "Epoch 1777: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0687 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0924 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1778/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0736 - sparse_categorical_accuracy: 0.9668\n",
      "Epoch 1778: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0753 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0935 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1779/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.0737 - sparse_categorical_accuracy: 0.9760\n",
      "Epoch 1779: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0775 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0928 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1780/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0741 - sparse_categorical_accuracy: 0.9773\n",
      "Epoch 1780: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0744 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0982 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1781/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0763 - sparse_categorical_accuracy: 0.9644\n",
      "Epoch 1781: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0763 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0914 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1782/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0768 - sparse_categorical_accuracy: 0.9707\n",
      "Epoch 1782: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0748 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0884 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1783/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.0900 - sparse_categorical_accuracy: 0.9665\n",
      "Epoch 1783: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0826 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0910 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1784/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.0772 - sparse_categorical_accuracy: 0.9712\n",
      "Epoch 1784: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0767 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0929 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1785/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0701 - sparse_categorical_accuracy: 0.9763\n",
      "Epoch 1785: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0724 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0926 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1786/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0779 - sparse_categorical_accuracy: 0.9646\n",
      "Epoch 1786: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0757 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0963 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1787/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0805 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 1787: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0763 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0928 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1788/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0723 - sparse_categorical_accuracy: 0.9775\n",
      "Epoch 1788: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0723 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0957 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1789/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0873 - sparse_categorical_accuracy: 0.9757\n",
      "Epoch 1789: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0873 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0927 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1790/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0777 - sparse_categorical_accuracy: 0.9682\n",
      "Epoch 1790: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0777 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0970 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1791/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0755 - sparse_categorical_accuracy: 0.9738\n",
      "Epoch 1791: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0755 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0880 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1792/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0824 - sparse_categorical_accuracy: 0.9750\n",
      "Epoch 1792: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0808 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0876 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1793/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0690 - sparse_categorical_accuracy: 0.9735\n",
      "Epoch 1793: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0695 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0977 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1794/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.0718 - sparse_categorical_accuracy: 0.9653\n",
      "Epoch 1794: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0835 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0940 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1795/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.0821 - sparse_categorical_accuracy: 0.9661\n",
      "Epoch 1795: val_loss did not improve from 0.08590\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0804 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0925 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1796/10000\n",
      "22/34 [==================>...........] - ETA: 0s - loss: 0.1049 - sparse_categorical_accuracy: 0.9688\n",
      "Epoch 1796: val_loss improved from 0.08590 to 0.08471, saving model to ./dataset1_cnn_results/transformer_model\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0992 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0847 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1797/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.0821 - sparse_categorical_accuracy: 0.9755\n",
      "Epoch 1797: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0774 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0884 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1798/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0867 - sparse_categorical_accuracy: 0.9707\n",
      "Epoch 1798: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0894 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0876 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1799/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0641 - sparse_categorical_accuracy: 0.9813\n",
      "Epoch 1799: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0641 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.0895 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1800/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0894 - sparse_categorical_accuracy: 0.9648\n",
      "Epoch 1800: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0873 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0890 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1801/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.1000 - sparse_categorical_accuracy: 0.9583\n",
      "Epoch 1801: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0992 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.0916 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1802/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0763 - sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1802: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0763 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0906 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1803/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0774 - sparse_categorical_accuracy: 0.9784\n",
      "Epoch 1803: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0775 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0881 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1804/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0779 - sparse_categorical_accuracy: 0.9785\n",
      "Epoch 1804: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0788 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.0919 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1805/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0714 - sparse_categorical_accuracy: 0.9778\n",
      "Epoch 1805: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0749 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0918 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1806/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0851 - sparse_categorical_accuracy: 0.9678\n",
      "Epoch 1806: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0845 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0867 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1807/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0789 - sparse_categorical_accuracy: 0.9727\n",
      "Epoch 1807: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0775 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0917 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1808/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.0713 - sparse_categorical_accuracy: 0.9844\n",
      "Epoch 1808: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0718 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.0904 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1809/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0854 - sparse_categorical_accuracy: 0.9700\n",
      "Epoch 1809: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0854 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0917 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1810/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0721 - sparse_categorical_accuracy: 0.9707\n",
      "Epoch 1810: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0727 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0917 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1811/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0730 - sparse_categorical_accuracy: 0.9824\n",
      "Epoch 1811: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0718 - sparse_categorical_accuracy: 0.9831 - val_loss: 0.0898 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1812/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0729 - sparse_categorical_accuracy: 0.9746\n",
      "Epoch 1812: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0735 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0854 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1813/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0916 - sparse_categorical_accuracy: 0.9634\n",
      "Epoch 1813: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0830 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0871 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1814/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.0794 - sparse_categorical_accuracy: 0.9777\n",
      "Epoch 1814: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0870 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0900 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1815/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0595 - sparse_categorical_accuracy: 0.9888\n",
      "Epoch 1815: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0595 - sparse_categorical_accuracy: 0.9888 - val_loss: 0.0894 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1816/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0817 - sparse_categorical_accuracy: 0.9794\n",
      "Epoch 1816: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0817 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.1028 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1817/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0715 - sparse_categorical_accuracy: 0.9778\n",
      "Epoch 1817: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0736 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0899 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1818/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0776 - sparse_categorical_accuracy: 0.9854\n",
      "Epoch 1818: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0739 - sparse_categorical_accuracy: 0.9869 - val_loss: 0.0910 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1819/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0617 - sparse_categorical_accuracy: 0.9805\n",
      "Epoch 1819: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0647 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0935 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1820/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0761 - sparse_categorical_accuracy: 0.9727\n",
      "Epoch 1820: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0754 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0899 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1821/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.1136 - sparse_categorical_accuracy: 0.9521\n",
      "Epoch 1821: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.1081 - sparse_categorical_accuracy: 0.9551 - val_loss: 0.0860 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1822/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.0681 - sparse_categorical_accuracy: 0.9722\n",
      "Epoch 1822: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0785 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0917 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1823/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0760 - sparse_categorical_accuracy: 0.9738\n",
      "Epoch 1823: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0760 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0910 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1824/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.0715 - sparse_categorical_accuracy: 0.9775\n",
      "Epoch 1824: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0699 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.0933 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1825/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.0675 - sparse_categorical_accuracy: 0.9792\n",
      "Epoch 1825: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0724 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0867 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1826/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.0864 - sparse_categorical_accuracy: 0.9688\n",
      "Epoch 1826: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0770 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0919 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1827/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0772 - sparse_categorical_accuracy: 0.9727\n",
      "Epoch 1827: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0777 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0877 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1828/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0998 - sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1828: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0998 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.0909 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1829/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0764 - sparse_categorical_accuracy: 0.9769\n",
      "Epoch 1829: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0808 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0883 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1830/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0620 - sparse_categorical_accuracy: 0.9792\n",
      "Epoch 1830: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0678 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0865 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1831/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0776 - sparse_categorical_accuracy: 0.9735\n",
      "Epoch 1831: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0782 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0943 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1832/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0854 - sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1832: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0854 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0876 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1833/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.0890 - sparse_categorical_accuracy: 0.9722\n",
      "Epoch 1833: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0865 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0967 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1834/10000\n",
      "20/34 [================>.............] - ETA: 0s - loss: 0.0697 - sparse_categorical_accuracy: 0.9781\n",
      "Epoch 1834: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0821 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0925 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1835/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.0724 - sparse_categorical_accuracy: 0.9755\n",
      "Epoch 1835: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0765 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0930 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1836/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0819 - sparse_categorical_accuracy: 0.9653\n",
      "Epoch 1836: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0800 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0980 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1837/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.0821 - sparse_categorical_accuracy: 0.9732\n",
      "Epoch 1837: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0756 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0890 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1838/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0693 - sparse_categorical_accuracy: 0.9785\n",
      "Epoch 1838: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0676 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.0981 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1839/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0688 - sparse_categorical_accuracy: 0.9773\n",
      "Epoch 1839: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0708 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0913 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1840/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.0660 - sparse_categorical_accuracy: 0.9792\n",
      "Epoch 1840: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 0.0800 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0921 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1841/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.0787 - sparse_categorical_accuracy: 0.9736\n",
      "Epoch 1841: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0802 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0908 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1842/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.0701 - sparse_categorical_accuracy: 0.9810\n",
      "Epoch 1842: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0671 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.0927 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1843/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0717 - sparse_categorical_accuracy: 0.9699\n",
      "Epoch 1843: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0766 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1024 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1844/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.0687 - sparse_categorical_accuracy: 0.9766\n",
      "Epoch 1844: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0753 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0875 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1845/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0900 - sparse_categorical_accuracy: 0.9688\n",
      "Epoch 1845: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0901 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0880 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 1846/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0909 - sparse_categorical_accuracy: 0.9688\n",
      "Epoch 1846: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0911 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0970 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1847/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0669 - sparse_categorical_accuracy: 0.9833\n",
      "Epoch 1847: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0672 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.0944 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1848/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0614 - sparse_categorical_accuracy: 0.9833\n",
      "Epoch 1848: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0661 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.1003 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1849/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.0779 - sparse_categorical_accuracy: 0.9783\n",
      "Epoch 1849: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0729 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.0874 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1850/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.0669 - sparse_categorical_accuracy: 0.9783\n",
      "Epoch 1850: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0846 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0906 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1851/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0984 - sparse_categorical_accuracy: 0.9625\n",
      "Epoch 1851: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0940 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0945 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1852/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.0775 - sparse_categorical_accuracy: 0.9700\n",
      "Epoch 1852: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0756 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0888 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1853/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.0789 - sparse_categorical_accuracy: 0.9688\n",
      "Epoch 1853: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0778 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0893 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1854/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0757 - sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1854: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0757 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0875 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1855/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.0615 - sparse_categorical_accuracy: 0.9792\n",
      "Epoch 1855: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0689 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.1010 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1856/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.0726 - sparse_categorical_accuracy: 0.9725\n",
      "Epoch 1856: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0757 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0917 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1857/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0606 - sparse_categorical_accuracy: 0.9819\n",
      "Epoch 1857: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0570 - sparse_categorical_accuracy: 0.9831 - val_loss: 0.0870 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1858/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.0796 - sparse_categorical_accuracy: 0.9700\n",
      "Epoch 1858: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0737 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.1003 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1859/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0730 - sparse_categorical_accuracy: 0.9698\n",
      "Epoch 1859: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0736 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0858 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1860/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0664 - sparse_categorical_accuracy: 0.9815\n",
      "Epoch 1860: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0795 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0924 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1861/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0657 - sparse_categorical_accuracy: 0.9769\n",
      "Epoch 1861: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0764 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0894 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1862/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.0704 - sparse_categorical_accuracy: 0.9808\n",
      "Epoch 1862: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0829 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0916 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1863/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0803 - sparse_categorical_accuracy: 0.9707\n",
      "Epoch 1863: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0825 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0852 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1864/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0833 - sparse_categorical_accuracy: 0.9735\n",
      "Epoch 1864: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0827 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0902 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1865/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0758 - sparse_categorical_accuracy: 0.9738\n",
      "Epoch 1865: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0741 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0882 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1866/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0724 - sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1866: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0724 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0893 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1867/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0769 - sparse_categorical_accuracy: 0.9708\n",
      "Epoch 1867: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0824 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0889 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1868/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0610 - sparse_categorical_accuracy: 0.9806\n",
      "Epoch 1868: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0665 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.0923 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1869/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0650 - sparse_categorical_accuracy: 0.9859\n",
      "Epoch 1869: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0666 - sparse_categorical_accuracy: 0.9831 - val_loss: 0.0905 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1870/10000\n",
      "22/34 [==================>...........] - ETA: 0s - loss: 0.0736 - sparse_categorical_accuracy: 0.9716\n",
      "Epoch 1870: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0650 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.1043 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1871/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.0752 - sparse_categorical_accuracy: 0.9714\n",
      "Epoch 1871: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0793 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0973 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1872/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.0853 - sparse_categorical_accuracy: 0.9736\n",
      "Epoch 1872: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0807 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0899 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1873/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0751 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 1873: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0725 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0952 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1874/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0701 - sparse_categorical_accuracy: 0.9773\n",
      "Epoch 1874: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0701 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0888 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1875/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0601 - sparse_categorical_accuracy: 0.9828\n",
      "Epoch 1875: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0594 - sparse_categorical_accuracy: 0.9831 - val_loss: 0.0972 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1876/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0838 - sparse_categorical_accuracy: 0.9738\n",
      "Epoch 1876: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0838 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0858 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1877/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0765 - sparse_categorical_accuracy: 0.9771\n",
      "Epoch 1877: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0762 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0949 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1878/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0733 - sparse_categorical_accuracy: 0.9727\n",
      "Epoch 1878: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0740 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.1059 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1879/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.0761 - sparse_categorical_accuracy: 0.9760\n",
      "Epoch 1879: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0773 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0900 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1880/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0733 - sparse_categorical_accuracy: 0.9754\n",
      "Epoch 1880: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0728 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0890 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1881/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0938 - sparse_categorical_accuracy: 0.9698\n",
      "Epoch 1881: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0852 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0983 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1882/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0881 - sparse_categorical_accuracy: 0.9667\n",
      "Epoch 1882: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0842 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0925 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1883/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0751 - sparse_categorical_accuracy: 0.9682\n",
      "Epoch 1883: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0751 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0947 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1884/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0706 - sparse_categorical_accuracy: 0.9738\n",
      "Epoch 1884: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0706 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0923 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1885/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0587 - sparse_categorical_accuracy: 0.9812\n",
      "Epoch 1885: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0640 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0914 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1886/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0692 - sparse_categorical_accuracy: 0.9854\n",
      "Epoch 1886: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0722 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.0923 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1887/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0627 - sparse_categorical_accuracy: 0.9811\n",
      "Epoch 1887: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0621 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.0963 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1888/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0781 - sparse_categorical_accuracy: 0.9716\n",
      "Epoch 1888: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0782 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0876 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1889/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0882 - sparse_categorical_accuracy: 0.9655\n",
      "Epoch 1889: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0836 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0928 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1890/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0758 - sparse_categorical_accuracy: 0.9700\n",
      "Epoch 1890: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0758 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0885 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1891/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0636 - sparse_categorical_accuracy: 0.9805\n",
      "Epoch 1891: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0657 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.0979 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1892/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0782 - sparse_categorical_accuracy: 0.9727\n",
      "Epoch 1892: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0765 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0899 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1893/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0738 - sparse_categorical_accuracy: 0.9729\n",
      "Epoch 1893: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0737 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0917 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1894/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0627 - sparse_categorical_accuracy: 0.9775\n",
      "Epoch 1894: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0627 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0881 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1895/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0781 - sparse_categorical_accuracy: 0.9775\n",
      "Epoch 1895: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0781 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0883 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1896/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0831 - sparse_categorical_accuracy: 0.9682\n",
      "Epoch 1896: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0831 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1027 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1897/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0596 - sparse_categorical_accuracy: 0.9844\n",
      "Epoch 1897: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0589 - sparse_categorical_accuracy: 0.9850 - val_loss: 0.0884 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1898/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0711 - sparse_categorical_accuracy: 0.9798\n",
      "Epoch 1898: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0671 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.0877 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1899/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0670 - sparse_categorical_accuracy: 0.9707\n",
      "Epoch 1899: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0650 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0920 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1900/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0692 - sparse_categorical_accuracy: 0.9771\n",
      "Epoch 1900: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0718 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0858 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1901/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0631 - sparse_categorical_accuracy: 0.9778\n",
      "Epoch 1901: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0617 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0891 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1902/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0798 - sparse_categorical_accuracy: 0.9688\n",
      "Epoch 1902: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0837 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0945 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1903/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0601 - sparse_categorical_accuracy: 0.9812\n",
      "Epoch 1903: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0637 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.1005 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1904/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0804 - sparse_categorical_accuracy: 0.9716\n",
      "Epoch 1904: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0800 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0963 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1905/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.0618 - sparse_categorical_accuracy: 0.9775\n",
      "Epoch 1905: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0662 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.0933 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1906/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0730 - sparse_categorical_accuracy: 0.9815\n",
      "Epoch 1906: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0775 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0909 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1907/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.0785 - sparse_categorical_accuracy: 0.9732\n",
      "Epoch 1907: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0779 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0914 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1908/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0757 - sparse_categorical_accuracy: 0.9677\n",
      "Epoch 1908: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0764 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0872 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1909/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0807 - sparse_categorical_accuracy: 0.9697\n",
      "Epoch 1909: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0886 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.0922 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1910/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0707 - sparse_categorical_accuracy: 0.9750\n",
      "Epoch 1910: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0758 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0882 - val_sparse_categorical_accuracy: 0.9775\n",
      "Epoch 1911/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0803 - sparse_categorical_accuracy: 0.9688\n",
      "Epoch 1911: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0765 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0875 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1912/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0679 - sparse_categorical_accuracy: 0.9830\n",
      "Epoch 1912: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0696 - sparse_categorical_accuracy: 0.9831 - val_loss: 0.0887 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1913/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0698 - sparse_categorical_accuracy: 0.9754\n",
      "Epoch 1913: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0699 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0920 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1914/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0637 - sparse_categorical_accuracy: 0.9741\n",
      "Epoch 1914: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0685 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0985 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1915/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0801 - sparse_categorical_accuracy: 0.9738\n",
      "Epoch 1915: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0801 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0888 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1916/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0744 - sparse_categorical_accuracy: 0.9738\n",
      "Epoch 1916: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0744 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0921 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1917/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0800 - sparse_categorical_accuracy: 0.9700\n",
      "Epoch 1917: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0800 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0963 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1918/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0889 - sparse_categorical_accuracy: 0.9699\n",
      "Epoch 1918: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0786 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0852 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1919/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0685 - sparse_categorical_accuracy: 0.9792\n",
      "Epoch 1919: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0695 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0848 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1920/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0772 - sparse_categorical_accuracy: 0.9697\n",
      "Epoch 1920: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0765 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0909 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1921/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.0835 - sparse_categorical_accuracy: 0.9665\n",
      "Epoch 1921: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0793 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0952 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1922/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0711 - sparse_categorical_accuracy: 0.9813\n",
      "Epoch 1922: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0711 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.0861 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1923/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0690 - sparse_categorical_accuracy: 0.9763\n",
      "Epoch 1923: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0678 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0878 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1924/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0667 - sparse_categorical_accuracy: 0.9792\n",
      "Epoch 1924: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0652 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.0936 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1925/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0788 - sparse_categorical_accuracy: 0.9812\n",
      "Epoch 1925: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0760 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.0889 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1926/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0722 - sparse_categorical_accuracy: 0.9805\n",
      "Epoch 1926: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0720 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.1049 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1927/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0754 - sparse_categorical_accuracy: 0.9729\n",
      "Epoch 1927: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0773 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0894 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1928/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0683 - sparse_categorical_accuracy: 0.9792\n",
      "Epoch 1928: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0676 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.0943 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1929/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0757 - sparse_categorical_accuracy: 0.9763\n",
      "Epoch 1929: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0769 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0924 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1930/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0729 - sparse_categorical_accuracy: 0.9727\n",
      "Epoch 1930: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0710 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0955 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1931/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0631 - sparse_categorical_accuracy: 0.9758\n",
      "Epoch 1931: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0624 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0977 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1932/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0808 - sparse_categorical_accuracy: 0.9708\n",
      "Epoch 1932: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0788 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.1016 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1933/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0818 - sparse_categorical_accuracy: 0.9646\n",
      "Epoch 1933: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0759 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0900 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1934/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0658 - sparse_categorical_accuracy: 0.9688\n",
      "Epoch 1934: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0630 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.1000 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1935/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.0663 - sparse_categorical_accuracy: 0.9777\n",
      "Epoch 1935: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0624 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.0940 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1936/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0611 - sparse_categorical_accuracy: 0.9824\n",
      "Epoch 1936: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0647 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.0908 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1937/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0736 - sparse_categorical_accuracy: 0.9746\n",
      "Epoch 1937: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0731 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0880 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1938/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0678 - sparse_categorical_accuracy: 0.9718\n",
      "Epoch 1938: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0654 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.1009 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1939/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0815 - sparse_categorical_accuracy: 0.9646\n",
      "Epoch 1939: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0818 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.0915 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1940/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0679 - sparse_categorical_accuracy: 0.9824\n",
      "Epoch 1940: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0695 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.0947 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1941/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.0925 - sparse_categorical_accuracy: 0.9688\n",
      "Epoch 1941: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0780 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0973 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1942/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0668 - sparse_categorical_accuracy: 0.9792\n",
      "Epoch 1942: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0683 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0893 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1943/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0849 - sparse_categorical_accuracy: 0.9700\n",
      "Epoch 1943: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0849 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0917 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1944/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0732 - sparse_categorical_accuracy: 0.9718\n",
      "Epoch 1944: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0730 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0999 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1945/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0750 - sparse_categorical_accuracy: 0.9811\n",
      "Epoch 1945: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0743 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.0909 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1946/10000\n",
      "21/34 [=================>............] - ETA: 0s - loss: 0.0683 - sparse_categorical_accuracy: 0.9762\n",
      "Epoch 1946: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0758 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0991 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1947/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.0714 - sparse_categorical_accuracy: 0.9750\n",
      "Epoch 1947: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0701 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0948 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1948/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.0574 - sparse_categorical_accuracy: 0.9875\n",
      "Epoch 1948: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0633 - sparse_categorical_accuracy: 0.9831 - val_loss: 0.0917 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1949/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0898 - sparse_categorical_accuracy: 0.9676\n",
      "Epoch 1949: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0890 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0907 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1950/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.0709 - sparse_categorical_accuracy: 0.9777\n",
      "Epoch 1950: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0700 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.1020 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1951/10000\n",
      "28/34 [=======================>......] - ETA: 0s - loss: 0.0693 - sparse_categorical_accuracy: 0.9754\n",
      "Epoch 1951: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0638 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0890 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1952/10000\n",
      "21/34 [=================>............] - ETA: 0s - loss: 0.0610 - sparse_categorical_accuracy: 0.9732\n",
      "Epoch 1952: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0696 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0915 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1953/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0844 - sparse_categorical_accuracy: 0.9708\n",
      "Epoch 1953: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 0.0812 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0905 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1954/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0763 - sparse_categorical_accuracy: 0.9700\n",
      "Epoch 1954: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0763 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0928 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1955/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0779 - sparse_categorical_accuracy: 0.9698\n",
      "Epoch 1955: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0792 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.0910 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1956/10000\n",
      "22/34 [==================>...........] - ETA: 0s - loss: 0.0640 - sparse_categorical_accuracy: 0.9830\n",
      "Epoch 1956: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0633 - sparse_categorical_accuracy: 0.9831 - val_loss: 0.0880 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1957/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.0767 - sparse_categorical_accuracy: 0.9728\n",
      "Epoch 1957: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0714 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0885 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1958/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0642 - sparse_categorical_accuracy: 0.9763\n",
      "Epoch 1958: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0614 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.1031 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1959/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0816 - sparse_categorical_accuracy: 0.9699\n",
      "Epoch 1959: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0745 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0865 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1960/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0695 - sparse_categorical_accuracy: 0.9699\n",
      "Epoch 1960: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0659 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0914 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1961/10000\n",
      "19/34 [===============>..............] - ETA: 0s - loss: 0.0520 - sparse_categorical_accuracy: 0.9901\n",
      "Epoch 1961: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0675 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.0953 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1962/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0691 - sparse_categorical_accuracy: 0.9738\n",
      "Epoch 1962: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0691 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0970 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1963/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.0664 - sparse_categorical_accuracy: 0.9792\n",
      "Epoch 1963: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0718 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0872 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1964/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.0782 - sparse_categorical_accuracy: 0.9818\n",
      "Epoch 1964: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0774 - sparse_categorical_accuracy: 0.9850 - val_loss: 0.0902 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1965/10000\n",
      "23/34 [===================>..........] - ETA: 0s - loss: 0.0557 - sparse_categorical_accuracy: 0.9783\n",
      "Epoch 1965: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0508 - sparse_categorical_accuracy: 0.9831 - val_loss: 0.0915 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1966/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.0908 - sparse_categorical_accuracy: 0.9700\n",
      "Epoch 1966: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0860 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0921 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1967/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.0811 - sparse_categorical_accuracy: 0.9615\n",
      "Epoch 1967: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0759 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0921 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1968/10000\n",
      "24/34 [====================>.........] - ETA: 0s - loss: 0.0559 - sparse_categorical_accuracy: 0.9844\n",
      "Epoch 1968: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0696 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.0893 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1969/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.0752 - sparse_categorical_accuracy: 0.9725\n",
      "Epoch 1969: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0737 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.1001 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1970/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.0670 - sparse_categorical_accuracy: 0.9736\n",
      "Epoch 1970: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0660 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0848 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1971/10000\n",
      "22/34 [==================>...........] - ETA: 0s - loss: 0.0603 - sparse_categorical_accuracy: 0.9830\n",
      "Epoch 1971: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0670 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0899 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1972/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.0717 - sparse_categorical_accuracy: 0.9725\n",
      "Epoch 1972: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0686 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0883 - val_sparse_categorical_accuracy: 0.9775\n",
      "Epoch 1973/10000\n",
      "26/34 [=====================>........] - ETA: 0s - loss: 0.0792 - sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1973: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0755 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0866 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1974/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.1027 - sparse_categorical_accuracy: 0.9560\n",
      "Epoch 1974: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0971 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.1096 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1975/10000\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 0.0891 - sparse_categorical_accuracy: 0.9700\n",
      "Epoch 1975: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0778 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0848 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1976/10000\n",
      "18/34 [==============>...............] - ETA: 0s - loss: 0.1119 - sparse_categorical_accuracy: 0.9514\n",
      "Epoch 1976: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0824 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0877 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1977/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0681 - sparse_categorical_accuracy: 0.9813\n",
      "Epoch 1977: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0681 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.1089 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1978/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0717 - sparse_categorical_accuracy: 0.9775\n",
      "Epoch 1978: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0717 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0952 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1979/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0727 - sparse_categorical_accuracy: 0.9727\n",
      "Epoch 1979: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0706 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0957 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1980/10000\n",
      "31/34 [==========================>...] - ETA: 0s - loss: 0.0816 - sparse_categorical_accuracy: 0.9637\n",
      "Epoch 1980: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0798 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.0953 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1981/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0591 - sparse_categorical_accuracy: 0.9871\n",
      "Epoch 1981: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0691 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.0918 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1982/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0695 - sparse_categorical_accuracy: 0.9700\n",
      "Epoch 1982: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0695 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0891 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1983/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0781 - sparse_categorical_accuracy: 0.9745\n",
      "Epoch 1983: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0834 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0879 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1984/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0739 - sparse_categorical_accuracy: 0.9775\n",
      "Epoch 1984: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0739 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0958 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1985/10000\n",
      "30/34 [=========================>....] - ETA: 0s - loss: 0.0636 - sparse_categorical_accuracy: 0.9812\n",
      "Epoch 1985: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0667 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.0989 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1986/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0730 - sparse_categorical_accuracy: 0.9773\n",
      "Epoch 1986: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0727 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0894 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1987/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0828 - sparse_categorical_accuracy: 0.9698\n",
      "Epoch 1987: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0789 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0869 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1988/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0784 - sparse_categorical_accuracy: 0.9746\n",
      "Epoch 1988: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0764 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0869 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1989/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0760 - sparse_categorical_accuracy: 0.9754\n",
      "Epoch 1989: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0769 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0932 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1990/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0703 - sparse_categorical_accuracy: 0.9735\n",
      "Epoch 1990: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0697 - sparse_categorical_accuracy: 0.9738 - val_loss: 0.0895 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1991/10000\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.0597 - sparse_categorical_accuracy: 0.9792\n",
      "Epoch 1991: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0591 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.0893 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1992/10000\n",
      "32/34 [===========================>..] - ETA: 0s - loss: 0.0748 - sparse_categorical_accuracy: 0.9707\n",
      "Epoch 1992: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0755 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0915 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1993/10000\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0598 - sparse_categorical_accuracy: 0.9813\n",
      "Epoch 1993: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 0.0598 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.0908 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1994/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0655 - sparse_categorical_accuracy: 0.9828\n",
      "Epoch 1994: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 0.0693 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.0921 - val_sparse_categorical_accuracy: 0.9663\n",
      "Epoch 1995/10000\n",
      "27/34 [======================>.......] - ETA: 0s - loss: 0.0758 - sparse_categorical_accuracy: 0.9745\n",
      "Epoch 1995: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0769 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.0999 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 1996/10000\n",
      "29/34 [========================>.....] - ETA: 0s - loss: 0.0546 - sparse_categorical_accuracy: 0.9763\n",
      "Epoch 1996: val_loss did not improve from 0.08471\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 0.0581 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.0880 - val_sparse_categorical_accuracy: 0.9719\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0847 - sparse_categorical_accuracy: 0.9719\n",
      "0.08471023291349411 0.9719101190567017\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.1601 - sparse_categorical_accuracy: 0.9551\n",
      "0.16013477742671967 0.9550561904907227\n"
     ]
    }
   ],
   "source": [
    "input_shape = x.shape[1:]\n",
    "\n",
    "model = create_model(input_shape)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=200, restore_best_weights=True),\n",
    "    keras.callbacks.ModelCheckpoint(\"./dataset1_cnn_results/cnn_model.h5\",\n",
    "        monitor='val_loss',  # Optional: Monitor a specific metric to save the best weights\n",
    "        save_weights_only=False,  # Save the entire model\n",
    "        save_best_only=True,  # Save only the best weights based on the monitored metric\n",
    "        verbose=1  # Optional: Display messages when saving weights\n",
    "    )\n",
    "]\n",
    "\n",
    "results = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val,y_val),\n",
    "    epochs=10000,\n",
    "    batch_size=16,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "l, a = model.evaluate(x_val, y_val, verbose=1)\n",
    "\n",
    "print(l, a)\n",
    "\n",
    "L, A = model.evaluate(x_test, y_test, verbose=1)\n",
    "\n",
    "print(L, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_accuracy_comparison([results.history[\"sparse_categorical_accuracy\"], results.history[\"val_sparse_categorical_accuracy\"]],\n",
    "                        \"Training/Validation Accuracy Comparison\",\n",
    "                        [\"Training Accuracy\", \"Validation Accuracy\"],\n",
    "                        save_path = \"./dataset1_cnn_results/cnn_dataset1_acc_comparison.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_comparison([results.history[\"loss\"], results.history[\"val_loss\"]],\n",
    "                     \"Training/Validation Loss Comparison\",\n",
    "                     [\"Training Loss\", \"Validation Loss\"],\n",
    "                     save_path = \"./dataset1_cnn_results/cnn_dataset1_loss_comparison.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9667    1.0000    0.9831        58\n",
      "           1     1.0000    0.8939    0.9440        66\n",
      "           2     0.8983    0.9815    0.9381        54\n",
      "\n",
      "    accuracy                         0.9551       178\n",
      "   macro avg     0.9550    0.9585    0.9550       178\n",
      "weighted avg     0.9583    0.9551    0.9549       178\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred=np.argmax(model.predict(x_test), axis=-1)\n",
    "print(classification_report(y_pred,y_test, digits=4))\n",
    "plot_confusion_matrix(y_test, y_pred, [\"bottle\", \"cube\", \"long_block\"],\n",
    "                      save_path=\"./dataset1_cnn_results/cnn_dataset1_conf_matrix.svg\")\n",
    "\n",
    "write_results(results.history['sparse_categorical_accuracy'][-200], a, A,\n",
    "              results.history['loss'][-200], l, L,\n",
    "              classification_report(y_pred,y_test, digits=4),\n",
    "              save_path = \"./dataset1_cnn_results/cnn_dataset1_results.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
