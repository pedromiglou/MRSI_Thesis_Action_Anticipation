# [<-](../README.md) Rolling-Unrolling LSTMs for Action Anticipation from First-Person Video

## Keywords

- Action anticipation
- egocentric vision
- recurrent neural networks
- LSTM

## Objective

- predicting what actions the camera wearer will perform in the near future and which objects they will interact with

## Sensors

- spatial observations (RGB frames), motion (optical flow) and object-based features obtained through an object detector
- images from public datasets

## Methods

- Rolling-Unrolling LSTM
- “A Rolling” LSTM (RLSTM) continuously encodes streaming observations and keeps an updated summary of what has been observed so far
- When an anticipation is required, the “Unrolling” LSTM (U-LSTM) is initialized with the current hidden and cell states of the R-LSTM (which encode the summary of the past) and makes predictions about the future

## Critics

- extensive description of the LSTM used
- it was not an industrial environment
