\chapter{Conclusion \textcolor{red}{and Future Work}}
\label{chapter:conclusion}

This document presented the problem of anticipating human actions in collaborative environments with the goal of developing an anticipatory robot controller for an assembly task. Looking at previous work found in the literature, there is a clear predominance of perception using RGB cameras with different ways of preprocessing the captured images. When it comes to the methods, \acl{ml} and, in particular, supervised learning techniques are predominant, given that most work nowadays takes advantage of the progress made in that field. With the continuous evolution of \acs{ml}, it is expected that the algorithms related to the topic in this paper also evolve and, consequently, give rise to even better solutions. 

To complete the study of previous work, some relevant tools were reviewed with a particular emphasis on two libraries that can detect key points in an image, such as skeleton joints which are very important to detect human poses. Regarding the practical side of the dissertation, an inertial sensor was tested in other to evaluate its inclusion as another source of data. Although it was possible to capture data, an additional effort will be required to demonstrate its usefulness for the proposed study. Furthermore, as a result of this work, the tasks for the second semester were delineated and scheduled.

In summary, the results of this study demonstrate that Action Anticipation is still a relatively new concept, but it has much potential to increase the efficiency and safety of collaborative tasks, revolutionizing the world of \acl{hrc}.